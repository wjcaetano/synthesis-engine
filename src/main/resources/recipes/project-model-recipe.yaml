config:
  fresh: true
  neo4j:
    - "${@Utils.getEnvVariable('NEO4J_API_URI')}"
    - "${@Utils.createBasicAuthHeader(@Utils.getEnvVariable('NEO4J_USERNAME'), @Utils.getEnvVariable('NEO4J_PASSWORD'))}"
executor: ProjectModelExecutor.java
executorEvents:
  beforeAll: |-
    @@@groovy("before-all.groovy")
    import com.capco.brsp.synthesisengine.dto.TransformDto
    import com.capco.brsp.synthesisengine.service.IExecutor
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.tools.ToolsFunction
    import com.capco.brsp.synthesisengine.utils.*
    import org.springframework.context.ApplicationContext
    import org.springframework.web.client.HttpServerErrorException
    
    import java.nio.file.Path
    
    class BeforeAll implements IExecutor {
        SuperService superService = null
        ScriptService scriptService = null
        SuperUtils superUtils = SuperUtils.getInstance()
    
        Object execute(ApplicationContext applicationContext, Map<String, Object> projectContext) {
            this.superService = applicationContext.getBean(SuperService.class)
            this.scriptService = applicationContext.getBean(ScriptService.class)
    
            def tempCobolPrograms = Utils.decodeBase64(Objects.requireNonNull(projectContext['$api'].files['legacy_code.json'], "File 'legacy_code.json' is missing!") as String)
            def tempOriginalProjectsContent = Utils.decodeBase64(Objects.requireNonNull(projectContext['$api'].files['monolith_decomposition_report.json'], "File 'monolith_decomposition_report.json' is missing!") as String)
            def tempTables = projectContext['$api'].files.tables
            def tables = tempTables instanceof List ? tempTables : JsonUtils.readAsList(tempTables)
            def tempCobol = (tempCobolPrograms instanceof Map ? tempCobolPrograms : JsonUtils.readAsMap(tempCobolPrograms))
            def cobol = tempCobol.cobolPrograms
            def monolithDecompositionReport = tempOriginalProjectsContent instanceof List ? tempOriginalProjectsContent : JsonUtils.readAsList(tempOriginalProjectsContent)
    
            projectContext['$api'].files.cobolPrograms = tempCobol
            projectContext['$api'].files.clusters = monolithDecompositionReport
    
            if (projectContext.files == null) {
                projectContext.files = new ConcurrentLinkedHashMap<>()
            }
            projectContext.files.cobolPrograms = tempCobol
    
            def output = []
            def port = projectContext.recipe?.vars?.port ?: 8080
    
            monolithDecompositionReport.each { usvc ->
                usvc.paragraph.removeAll { usvcParagraph ->
                    usvcParagraph.name.contains("EXIT")
                }
                usvc.paragraph.each { usvcParagraph ->
                    usvcParagraph.children.removeAll { usvcParagraphChild ->
                        usvcParagraphChild.contains("EXIT")
                    }
                }
            }.removeAll { usvc ->
                usvc.paragraph.isEmpty()
            }
    
            def reportGrouped = monolithDecompositionReport.groupBy { usvc ->
                usvc.paragraph.size() > 1 || usvc.paragraph.count { usvcParagraph ->
                    usvcParagraph.children
                } > 0
            }
    
            def (reportFinal, reportPieces) = [reportGrouped[true], reportGrouped[false]]
    
            reportPieces.each { itPieces ->
                itPieces.paragraph.each { itPiecesParagraph ->
                    reportFinal.findAll { itFinal ->
                        !itFinal.paragraph.collect { itFinalParagraph -> itFinalParagraph.children.contains(itPiecesParagraph.name) }.isEmpty()
                    }.first().paragraph.add(itPiecesParagraph)
                }
            }
    
            reportFinal = [
                    [
                            project_name: "monolith",
                            domain      : [],
                            paragraph   : []
                    ]
            ]
            monolithDecompositionReport.each { obj ->
                reportFinal[0].domain.addAll(obj.domain)
                reportFinal[0].paragraph.addAll(obj.paragraph)
            }
    
            reportFinal[0].domain = reportFinal[0].domain.unique()
    
            def skipped = []
            def sorted = []
            reportFinal[0].paragraph.each { it ->
                def sortedParagraphNames = sorted.collect { it2 -> it2.name }
                if (!it.children.isEmpty() && it.children.any { it3 -> !(it3 in sortedParagraphNames) }) {
                    println "Skipping first time '${it.name}' dependency"
                    skipped.add(it)
                } else {
                    println "The '${it.name}' dependency was already OK"
                    sorted.add(it)
                }
            }
    
            println "Now fixing ${skipped.size()} dependencies"
            def i = 0
            while (!skipped.isEmpty()) {
                if (i > skipped.size()) {
                    println "Unable to solve a sort of '${skipped.size()}' circular dependencies"
                    break
                }
                def skippedItem = skipped.remove(0)
                def sortedParagraphNames = sorted.collect { it2 -> it2.name }
                if (!skippedItem.children.isEmpty() && skippedItem.children.any { it3 -> !(it3 in sortedParagraphNames) }) {
                    println "Skipping again '${skippedItem.name}' depedency"
                    skipped.add(skippedItem)
                    i++
                } else {
                    println "Fixed '${skippedItem.name}' dependency"
                    sorted.add(skippedItem)
                    i = 0
                }
            }
    
            while (!skipped.isEmpty()) {
                def removed = skipped.remove(0)
                println "Including the unsolvable item named '${removed.name}'"
                sorted.add(removed)
            }
    
            reportFinal[0].paragraph = sorted
    
            monolithDecompositionReport = reportFinal
    
            projectContext['$api'].files.projects = Utils.convertToConcurrent(monolithDecompositionReport)
    
            monolithDecompositionReport.eachWithIndex { project, index ->
                def programs = project.paragraph
                        .collect { paragraph -> ((String) paragraph.name).split('\\.')[0] }
                        .unique()
                def transformedProject = [
                        name          : project.project_name,
                        normalizedName: project.project_name.replaceAll("\\s+-\\s+|\\s", "_").toLowerCase(),
                        port          : port + index,
                        dtos          : project.domain
                                .findAll { it.startsWith("call-variable:") }
                                .collect { variable ->
                                    def storageName = variable.replaceFirst("^.*", "")
                                    def storage = cobol.findAll { programs.contains(it.name) }
                                            .collect { cob ->
                                                [
                                                        program: cob.name,
                                                        code   : cob.working_storage.data_entries.find { d -> d.name == storageName }?.raw_code
                                                ]
                                            }
                                            .find { it != null && it.code != null } ?: [program: '<NOT_FOUND>', raw_code: '<NOT_FOUND>']
                                    return [program: storage.program, name: storageName, code: storage.code, file: storageName.findAll(/[a-zA-Z0-9]+/).collect { dto -> dto.toLowerCase().capitalize() }.join('') + 'Dto.java']
                                },
                        files         : project.domain
                                .findAll { it.startsWith("file-") }
                                .collect { variable ->
                                    def storageName = variable.replaceFirst("^.*:", "")
                                    def storage = cobol.findAll { programs.contains(it.name) }
                                            .collect { cob ->
                                                [
                                                        program: cob.name,
                                                        code   : cob.file_section?.data_entries?.find { d -> d.name == storageName }?.raw_code
                                                ]
                                            }
                                            .find { it != null && it.code != null } ?: [program: '<NOT_FOUND>', raw_code: "<NOT_FOUND>"]
                                    return [program: storage.program, name: storageName, code: storage.code, file: storageName.findAll(/[a-zA-Z0-9]+/).collect { dto -> dto.toLowerCase().capitalize() }.join('') + 'Model.java']
                                },
                        tables        : project.domain
                                .findAll { it.startsWith("table-") }
                                .collect { variable ->
                                    def tableName = variable.replaceFirst("^.*:", "")
                                    def table = tables.find { t -> tableName.equalsIgnoreCase(t.table.name) }?.table
                                    return [program: "<NOT_FOUND>", name: table?.name, code: table?.raw_code, file: tableName.findAll(/[a-zA-Z0-9]+/).collect { dto -> dto.toLowerCase().capitalize() }.join('') + 'Model.java']
                                },
                        locals        : project.domain
                                .findAll { !it.startsWith("call-variable") && !it.startsWith("file-") && !it.startsWith("table-") && !it.startsWith("cursor-") }
                                .collect { variable ->
                                    def storageName = variable.replaceFirst("^.*:", "")
                                    def storage = cobol.findAll { programs.contains(it.name) }
                                            .collect { cob ->
                                                [
                                                        program: cob.name,
                                                        code   : cob.working_storage.data_entries.find { d -> d.name == storageName }?.raw_code
                                                ]
                                            }
                                            .find { it != null && it.code != null } ?: [program: '<NOT_FOUND>', raw_code: "<NOT_FOUND>"]
                                    return [program: storage.program, name: storageName, code: storage.code, file: storageName.findAll(/[a-zA-Z0-9]+/).collect { dto -> dto.toLowerCase().capitalize() }.join('') + 'Dto.java']
                                },
                        paragraphs    : project.paragraph.collect { para ->
                            def parts = para.name.split('\\.')
                            def calls = para.children.collect { child ->
                                def childParts = child.split('\\.')
                                def microservice = monolithDecompositionReport.find { it.paragraph.any { p -> p.name == child } }?.project_name
                                if (microservice == project.project_name) {
                                    return null
                                }
                                return [
                                        microservice: microservice,
                                        program     : childParts[0],
                                        paragraph   : childParts[1],
                                        code        : cobol.findAll { it.name == childParts[0] }.collect { source ->
                                            source.procedure_division.paragraphs.find { p -> p.name == childParts[1] }?.raw_code
                                        }.find { it != null } ?: '<NOT_FOUND>',
                                        endpoint    : "/${childParts[0].toLowerCase()}-${childParts[1].toLowerCase()}".toString()
                                ]
                            }.findAll { it != null }
                            [
                                    cobol_path  : para.name,
                                    microservice: "monolith",
                                    program     : parts[0],
                                    name        : parts[1],
                                    code        : cobol.findAll { it.name == parts[0] }.collect { source ->
                                        source.procedure_division.paragraphs.find { p -> p.name == parts[1] }?.raw_code
                                    }.find { it != null } ?: '<NOT_FOUND>',
                                    calls       : calls
                            ]
                        }
                ]
                def clientsMap = [:]
                transformedProject.paragraphs.each { p ->
                    p.calls.each { entry ->
                        if (entry.microservice) {
                            def microserviceClientName = entry.microservice.findAll(/[a-zA-Z0-9]+/).collect { dto -> dto.toLowerCase().capitalize() }.join('') + 'Client.java'
                            if (!clientsMap.containsKey(microserviceClientName)) {
                                clientsMap[microserviceClientName] = [(entry.endpoint): entry.code]
                            } else {
                                def microserviceClientMap = clientsMap[microserviceClientName]
                                if (!microserviceClientMap.containsKey(entry.endpoint)) {
                                    microserviceClientMap[entry.endpoint] = entry.code
                                }
                            }
                        }
                    }
                }
                transformedProject.clients = clientsMap
                output << transformedProject
            }
    
            projectContext.put('blueprint', output)
            def blueprintCache = FileUtils.absolutePathJoin(projectContext.rootFolder, 'cache', 'blueprintContext.json')
            FileUtils.writeFile(blueprintCache, JsonUtils.writeAsJsonString(output, true), false)
    
            def recipe = projectContext.recipe as Map<String, Object>
            def vars = recipe.vars as Map<String, Object>
    
            List<Map<String, Object>> projects = new ConcurrentLinkedList<>()
            projectContext.put("projects", projects)
            monolithDecompositionReport.eachWithIndex { def report, int reportIndex ->
                def programsNames = report.paragraph.collect { paragraph -> ((String) paragraph.name).split('\\.')[0] }.unique()
                def paragraphNames = report.paragraph.collect { paragraph -> ((String) paragraph.name).split('\\.')[1] }.unique()
                println "Paragraph Names: ${paragraphNames.join(', ')}"
                def matchedCobolPrograms = cobol.findAll(cob -> programsNames.contains(cob.name)) as List<Map<String, Object>>
    
                Map<String, Object> project = new ConcurrentLinkedHashMap<>()
                projects.add(project)
                projectContext.put('project', project)
    
                String projectName = report.project_name
                project.put("projectName", projectName)
                project.put("projectNormalizedName", projectName.replaceAll("\\s+-\\s+|\\s", "_").toLowerCase())
                project.put('programsNames', Utils.convertToConcurrent(programsNames))
                project.put('isBatch', true)
                project.put('index', reportIndex)
    
                def categorizedAndCollectNames = { domain, prefixes ->
                    domain.findAll { entry ->
                        prefixes.any { prefix -> entry.matches(prefix + ".*:.*") }
                    }.collect { entry ->
                        def matchingPrefix = prefixes.find { prefix -> entry.matches(prefix + ".*:.*") }
                        return entry.replaceFirst("^.*${matchingPrefix}.*:", "").replaceFirst("\\.\$", "")
                    }
                }
    
                def getStorageEntry = { section, storageName, sourcePrograms ->
                    sourcePrograms.collect { prog ->
                        [program: prog.name, raw_code: prog[section]?.data_entries?.find { d -> d.name == storageName }?.raw_code]
                    }.find { it != null && it.raw_code != null } ?: [program: "<NOT_FOUND>", raw_code: "<NOT_FOUND>"]
                }
    
                def generateStructure = { section, prefixList, fileSuffix ->
                    def names = categorizedAndCollectNames(report.domain, prefixList)
                    names.collect { storageName ->
                        def storage = getStorageEntry(section, storageName, matchedCobolPrograms)
                        [program: storage.program, name: storageName, code: storage.raw_code, file: JavaUtils.normalizeJavaIdentifier(storageName) + fileSuffix]
                    }
                }
    
                def generateTableModel = { domains, prefixList, fileSuffix ->
                    def names = categorizedAndCollectNames(domains, prefixList)
                    names.collect { tableName ->
                        def tableItem = tempCobol.db2Tables.find { tableItem -> tableName.matches("(.+\\.)?" + tableItem.name) }
                        [program: "<DOESNT_MATTER>", name: tableItem?.name, code: tableItem?.rawCode ?: tableItem?.raw_code, file: JavaUtils.normalizeJavaIdentifier(tableItem?.name ?: "") + fileSuffix]
                    }.findAll { it != null && it.code != null } ?: []
                }
    
                def cypherJolt = { String cypherQuery, String joltSpec ->
                    def toolsFunction = applicationContext.getBean(ToolsFunction.class)
    
                    def url = vars.neo4jURL as String
                    def method = "POST"
                    def headers = [
                            "Authorization": vars.neo4jEncodedAuth,
                            "Content-Type" : "application/json"
                    ] as Map<String, String>
    
                    def body = [
                            statements: [
                                    [statement: cypherQuery]
                            ]
                    ]
    
                    def neo4jResult = toolsFunction.apiCall(url, method, body, headers)
                    def neo4jResultString = JsonUtils.writeAsJsonString(neo4jResult, true)
    
                    def neo4jResultSize = (neo4jResult["results"]["data"][0]).size()
                    if (neo4jResultSize == 0){
                       return null
                    }
    
                    def joltResult = toolsFunction.jolt(neo4jResultString, joltSpec)
    
                    return JsonUtils.readAsList(joltResult)
                }
    
                def prompts = projectContext.recipe.prompts as Map<String, String>
                boolean pending = true
                while (pending) {
                    try {
                        def sqlSummaryCache = FileUtils.pathJoin(project.projectNormalizedName, 'cache', 'sqlSummary.json')
                        def sqlSummarizationString = summaryEvaluation(projectContext, prompts.sqlSummarization, sqlSummaryCache)
                        sqlSummarizationString = (Utils.extractMarkdownCode(sqlSummarizationString) as String).trim().replaceAll(/^["'`"]+|["'`"]+$/, '')
                        def sqlSummary = JsonUtils.readAsList(sqlSummarizationString)
                        sqlSummary.collect {
                            [
                                    "tableName"                            : it.tableName.replace("^.*\\.", ""),
                                    "originalQuery"                        : it.originalQuery,
                                    "springQueryAnnnotatedRepositoryMethod": it.springQueryAnnnotatedRepositoryMethod
                            ]
                        }
                        project.put('sqlSummary', Utils.convertToConcurrent(sqlSummary))
                        println "SQL Summary: ${sqlSummary}"
                        pending = false
                    } catch (Exception ex) {
                        println "Failed to generate a SQL Summary: ${ex.getMessage()}"
                        project.put('sqlSummary', Utils.convertToConcurrent([]))
                    }
                }
    
                String serviceSummarizationString = ""
                pending = true
                while (pending) {
                    try {
                        def serviceSummaryCache = FileUtils.pathJoin(project.projectNormalizedName, 'cache', 'serviceSummary.json')
                        serviceSummarizationString = summaryEvaluation(projectContext, prompts.serviceSummarizationSimple, serviceSummaryCache)
                        def serviceSummary = JsonUtils.readAsList(serviceSummarizationString)
                        project.put('serviceSummary', Utils.convertToConcurrent(serviceSummary))
                        println "Service Summary: ${serviceSummary}"
                        pending = false
                    } catch (Exception ex) {
                        println "Failed to generate a Service Summary: ${ex.getMessage()}"
                        project.put('serviceSummary', Utils.convertToConcurrent([]))
                    }
                }
    
                println "Creating jclProfile"
                def jclProfileCache = FileUtils.pathJoin(project.projectNormalizedName, 'cache', 'jclProfile.json')
                def jclProfileString = summaryEvaluation(projectContext, prompts.jclSummarization, jclProfileCache) as String
                def jclProfile = JsonUtils.readAsMap(jclProfileString)
                project.jclProfile = jclProfile
                println "Completed jclProfile"
    
                def summarization = recipe.summarization as Map<String, Object>
                def classifiedCobolVariables = cypherJolt(summarization.cobolVariablesClassificationCypherQuery as String, summarization.joltNeo4jTableToJson as String)
    
                def classifiedCobolVariablesGroup = classifiedCobolVariables.groupBy { it.label.contains("COBOLLinkage") }
                def dtos = classifiedCobolVariablesGroup.get(true)
                def locals = classifiedCobolVariablesGroup.get(false)
    
                def cobolFullVariables = cypherJolt(summarization.cobolFullVariablesCypherQuery as String, summarization.joltNeo4jTableToJson as String)
                project.put('cobolFullVariables', Utils.convertToConcurrent(cobolFullVariables))
    
                def cobolVariables = cypherJolt(summarization.cobolVariablesCypherQuery as String, summarization.joltNeo4jTableToJson as String)
                project.put('cobolVariables', Utils.convertToConcurrent(cobolVariables))
    
                //def fileVariables = cypherJolt(summarization.fileVariablesCypherQuery as String, summarization.joltNeo4jTableToJson as String)
                //project.put('fileVariables', Utils.convertToConcurrent(fileVariables))
    
                def fileComprehensiveDetails = cypherJolt(summarization.fileComprehensiveDetailsCypherQuery as String, summarization.joltNeo4jTableToJson as String)
                project.put('fileComprehensiveDetails', Utils.convertToConcurrent(fileComprehensiveDetails))
    
                def domains = fileComprehensiveDetails.collect{ it ->
                    return [
                            program: it.program,
                            name: it.domainJavaName,
                            code: it.fullRawCode,
                            file: it.domainJavaName + ".java",
                            label: it.label,
                            fields: it.recordStorageLowestLevel,
                            pks: it.recordKeyLowestLevel
                    ]
                }.groupBy { item -> item.label == "COBOLFileControl" }
    
                def pojos = domains.get(true)
                def models = domains.get(false)
    
    //            def models = generateTableModel(report.domain, ["table", "cursor"], ".java")?.unique()
    //            fileVariables.findAll { it -> it.label == "COBOLVsamFile" }.eachWithIndex { itVsamFile, idx ->
    //                def vsamJavaIdentifier = JavaUtils.normalizeJavaIdentifier(itVsamFile.fileName)
    //                def rawCode = cobolFullVariables.find { itFullVar -> itFullVar.program == itVsamFile.program && itFullVar.name == itVsamFile.fileVariable }?.code
    //                def vsamModel = [
    //                        program: itVsamFile.program,
    //                        name   : vsamJavaIdentifier,
    //                        code   : rawCode,
    //                        file   : vsamJavaIdentifier + ".java"
    //                ]
    //                models.add(vsamModel)
    //            }
                println "TableModels: ${models.collect { tableModel -> tableModel.name }}"
    
                def dtosFiles = dtos.collect { it.file }?.unique()
                def modelsFiles = models.collect { it.file }?.unique()
                def pojosFiles = pojos.collect { it.file }?.unique()
    
                def paragraphsFlow = cypherJolt(summarization.cobolParagraphsFlowCypherQuery as String, summarization.joltNeo4jSingleObjectsToJson as String)
                project.put('paragraphsFlow', Utils.convertToConcurrent(paragraphsFlow))
    
                def paragraphs = report.paragraph.collect { it ->
                    String programName = ((String) it.name).split("\\.")[0]
                    String paragraph = ((String) it.name).split("\\.")[1]
                    def paragraphCode = matchedCobolPrograms.collect { prog ->
                        prog.procedure_division.paragraphs.find { p -> p.name == paragraph }?.raw_code
                    }.find { it != null } ?: '<NOT_FOUND>'
    
                    def children = it.children.collect { entry ->
                        def parts = entry.split(/\./)
                        return [
                                program  : parts[0],
                                paragraph: parts[1]
                        ]
                    }
    
                    return [program: programName, paragraph: paragraph, code: paragraphCode, children: children]
                }
    
                project.put('dtos', Utils.convertToConcurrent(dtos))
                project.put('dtosFiles', Utils.convertToConcurrent(dtosFiles))
                project.put('models', Utils.convertToConcurrent(models))
                project.put('modelsFiles', Utils.convertToConcurrent(modelsFiles))
                project.put('pojos', Utils.convertToConcurrent(pojos))
                project.put('pojosFiles', Utils.convertToConcurrent(pojosFiles))
                project.put('locals', Utils.convertToConcurrent(locals.findAll { itLocal -> itLocal.code != null && itLocal.code != '<NOT_FOUND>' }))
    
                project.put('paragraphs', Utils.convertToConcurrent(paragraphs))
    
                projectContext.remove('project')
            }
    
            return output
        }
    
        Object summaryEvaluation(Map<String, Object> projectContext, String content, Path relativePath) {
            def attempts = 0
            def result = ""
            def recipe = projectContext.recipe
            while (attempts++ < 3) {
                try {
                    List<TransformDto> history = new ConcurrentLinkedList<>()
                    def filePath = FileUtils.absolutePathJoin(projectContext.rootFolder, relativePath)
                    if (false && recipe.cacheMap?.containsKey(filePath.toString())) {
                        println "CACHE - Retrieving from cache: ${filePath.toString()}"
                        result = recipe.cacheMap.get(filePath.toString())
                        println "CACHE - Retrieving from cache: ${filePath.toString()}"
                    } else {
                        result = scriptService.autoEval(content, history) as String
                        result = Utils.extractMarkdownCode(result) as String
                    }
                    FileUtils.writeFile(filePath, result, false)
                    projectContext.putIfAbsent("files_metadata", new ConcurrentLinkedHashMap<>())
                    def filesMetadata = projectContext.get("files_metadata") as ConcurrentLinkedHashMap<String, Object>
                    filesMetadata.put(relativePath.toString(), [history: history])
                    break
                } catch (HttpServerErrorException ignored) {
                    println "HttpServerErrorException during the attempt ${attempts} of 3. Waiting 1 minute before retrying!"
                    Thread.sleep(60000)
                } catch (Exception ex) {
                    println "beforeEachMicroserviceEval Exception: ${ex.getMessage()}"
                    throw ex
                }
            }
    
            return result
        }
    }
  #beforeProjects: |-
  #  @@@gitSync("${#recipe['config']['gitRepositories']}")
  #beforeEachProject: |- ServiceSummary, SqlSummary (JCL?)
  #  @@@groovy("beforeEachProject.groovy")
  #beforeEachFile:
  afterEachFile: |-
    @@@extractMarkdownCode
    @@@accumulateImportsAndJava
  #afterEachFileSaved: |-
  #  @@@freemarker
  #  @@@gitCommit("${#project['projectNormalizedName']}")
  #  Improvements made by Synthesis Engine: <#list fileHistory as history>${history.name}, </#list>
  #afterEachProject: |-
  #  @@@gitPush("${#project['projectNormalizedName']}", "${#recipe['config']['gitRepositories'][#project['projectNormalizedName']]}")
projectsReference: ${#$api['files']['monolith_decomposition_report.json']}
projectSuperModel:
  pom.xml: ${#recipe['fileTemplates']['superPom']}
projectModel:
  src:
    main:
      java:
        com:
          capco:
            ${#project['projectNormalizedName']}:
              #fakes: "${#recipe['prompts']['fakeDiagram']}"
              annotation:
                FlatFileItemField.java: "${#recipe['prompts']['flatFileItemField']}"
              utils:
                FileUtils.java: "${#recipe['prompts']['fileUtils']}"
              domain:
                db: "${@Utils.createWithAListOfKeys(#project['modelsFiles'], #recipe['prompts']['modelFile'])}"
                file: "${@Utils.createWithAListOfKeys(#project['pojosFiles'], #recipe['prompts']['pojoFile'])}"
                dto: "${@Utils.createWithAListOfKeys(#project['dtosFiles'], #recipe['prompts']['dtoFile'])}"
              repository: "${@Utils.createWithAListOfKeys(#project['modelsFiles'].![#this.replace('.java', 'Repository.java')], #recipe['prompts']['repository'])}"
              #model: "${@Utils.createWithAListOfKeys(#project['modelsFiles'], #recipe['prompts']['model'])}"
              #dto: "${@Utils.createWithAListOfKeys(#blueprint[#project['index']]['dtos'].![#this['file']], #recipe['prompts']['dto'])}"
              exception:
                GlobalExceptionsHandler.java: ${#recipe['prompts']['exception']}
              client: "${@Utils.createWithAListOfKeys(#blueprint[#project['index']]['clients'].keySet().![#this], #recipe['prompts']['client'])}"
              #kafka:
              #  KafkaProducer.java: ${#recipe['prompts']['kafkaProducer']}
              service:
                ignore: "${#recipe['prompts']['service']}"
                #cache:
                #  methodsSummary.json: "${#recipe['prompts']['methodsSummarization']}"
                #  DataMeshService.java: ${#recipe['prompts']['dataMeshService']}
                #business: "${@Utils.createWithAListOfKeys(#project['NewClasses'].keySet().![#this + '.java'], #recipe['prompts']['serviceWriter'])}"
                #MainService.java: "${#recipe['prompts']['serviceSummarized']}"
                #TaskletService.java: "${#recipe['prompts']['taskletService']}"
              config:
                #  DataSourceConfig.java: ${#recipe['prompts']['dataSourceConfig']}
                BatchConfig.java: ${#recipe['prompts']['batchConfig']}
                BatchStepsConfig.java: ${#recipe['prompts']['batchStepsConfig']}
              #controller:
              #  BatchController.java: "${#recipe['prompts']['batchController']}"
              #  Controller.java: "${#recipe['prompts']['controller']}"
              shell:
                ShellCommands.java: "${#recipe['prompts']['shellCommands']}"
              Application.java: ${#recipe['vars']['application']}
              diagrams:
                classDiagram.uml: ${#recipe['prompts']['classDiagram']}
                flowDiagram.uml: ${#recipe['prompts']['flowDiagram']}
      resources:
        application.yaml: ${#recipe['vars']['applicationYaml']}
  test:
    java:
      com:
        capco:
          ${#project['projectNormalizedName']}:
            #service:
            test: "${@Utils.createWithAListOfKeys(#project['serviceSummary'].![#this['serviceName'] + 'Test.java'], #recipe['prompts']['serviceTest'])}"
            #MainServiceTest.java: ${#recipe['prompts']['serviceTest']}
  infra:
    deployments.yaml: ${#recipe['vars']['infraDeployments']}
    services.yaml: ${#recipe['vars']['infraServices']}
  .mvn:
    wrapper:
      maven-wrapper.properties: ${#recipe['vars']['mvnWrapperProperties']}
  .dockerignore: ${#recipe['vars']['dockerignore']}
  .gitattributes: ${#recipe['vars']['gitattributes']}
  .gitignore: ${#recipe['vars']['gitignore']}
  Dockerfile: ${#recipe['vars']['Dockerfile']}
  mvnw: ${#recipe['vars']['mvnw']}
  mvnw.cmd: ${#recipe['vars']['mvnwCmd']}
  pom.xml: ${#recipe['vars']['pom']}
  README.md: ${#recipe['vars']['readme']}
vars:
  #neo4jURL: "http://10.239.6.85:8090/db/neo4j/tx/commit"
  #neo4jURL: "http://34.239.119.125:7474/db/neo4j/tx/commit"
  assemblies:
    AA002V02
    PWJCABND
  logFramework: Slf4j
  repositoryPath: MY_AZURE_REPOSITORY
  podk8sreplicas: 3
  groupId: com.capco
  appVersion: 1.0.0
  jdkVersion: 21
  springBootVersion: 3.3.4
  springShellVersion: 3.4.0
  port: 8080
  dtoExpression: "${#recipe['prompts']['dto']}"
  serviceExpression: "${#recipe['prompts']['service']}"
  controllerExpression: "${#recipe['prompts']['controller']}"
  controllerName: MainController
  application: |-
    @@@freemarker
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName};
    
    import org.springframework.boot.SpringApplication;
    import org.springframework.boot.autoconfigure.SpringBootApplication;
    import org.springframework.data.jpa.repository.EnableJpaRepositories;
    
    @SpringBootApplication
    @EnableJpaRepositories
    public class Application {
        public static void main(String[] args) {
            SpringApplication.run(Application.class, args);
        }
    }
  applicationYaml: |-
    @@@freemarker
    server:
      port: ${(recipe.vars.port + project.index)?string["0"]}
    spring:
      batch:
        jdbc:
          initialize-schema: always
      datasource:
        url: jdbc:h2:mem:test;DB_CLOSE_DELAY=-1;MODE=PostgreSQL
        driverClassName: org.h2.Driver
        username: sa
        password: password
      h2:
        console:
          enabled: true
          path: /h2-console
      jpa:
        database-platform: org.Hibernate.dialect.H2Dialect
        defer-datasource-initialization: true
        hibernate:
          ddl-auto: update
        properties:
          hibernate:
            format_sql: true
        show-sql: true
      shell:
        interactive:
          enabled: true
      sql:
        init:
          platform: h2
    mesh:
      target: database
      topic: ubs-topic
    resilience4j:
      retry:
        instances:
          myService:
            maxAttempts: 3
            waitDuration: 1000ms
      circuitbreaker:
        instances:
          myService:
            registerHealthIndicator: true
            slidingWindowSize: 10
            failureRateThreshold: 50
  mvnWrapperProperties: |-
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #   http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing,
    # software distributed under the License is distributed on an
    # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    # KIND, either express or implied.  See the License for the
    # specific language governing permissions and limitations
    # under the License.
    wrapperVersion=3.3.2
    distributionType=only-script
    distributionUrl=https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/3.9.9/apache-maven-3.9.9-bin.zip
    distributionSha256Sum=4ec3f26fb1a692473aea0235c300bd20f0f9fe741947c82c1234cefd76ac3a3c
  gitattributes: |-
    /mvnw text eol=lf
    *.cmd text eol=crlf
  gitignore: |-
    HELP.md
    target/
    !.mvn/wrapper/maven-wrapper.jar
    !**/src/main/**/target/
    !**/src/test/**/target/
    
    ### STS ###
    .apt_generated
    .classpath
    .factorypath
    .project
    .settings
    .springBeans
    .sts4-cache
    
    ### IntelliJ IDEA ###
    .idea
    *.iws
    *.iml
    *.ipr
    
    ### NetBeans ###
    /nbproject/private/
    /nbbuild/
    /dist/
    /nbdist/
    /.nb-gradle/
    build/
    !**/src/main/**/build/
    !**/src/test/**/build/
    
    ### VS Code ###
    .vscode/
  gitlabCi: |-
    stages:
    - test
    - build
    - deploy
    
    cache:
    paths:
      - .m2/repository
    
    variables:
    MY_ACR_NAME: $MY_ACR_NAME_REPOSITORY
    MY_ACR_USERNAME: $MY_ACR_USERNAME
    MY_ACR_PASSWORD: $MY_ACR_PASSWORD
    MY_ACR_TENANT: $MY_ACR_TENANT
    
    # Continuous Integration Stage: Unit Tests
    test:
    stage: test
    image: maven:3.9.8-eclipse-temurin-21
    script:
      - mvn clean test
    only:
      - develop
      -
    # Continuous Deployment Stage 1: Build the Docker image and push it to Azure Container Registry (ACR)
    build-and-push-image:
    stage: build
    image: docker:24.0.5
    services:
      - docker:dind
    before_script:
      - echo "$AZURE_ACR_PASSWORD" | docker login "$MY_ACR_NAME.azurecr.io" -u $MY_ACR_USERNAME -p $MY_ACR_PASSWORD -t $MY_ACR_TENANT
    script:
      - mvn clean package -DskipTests
      - docker build -t "MY_ACR_NAME.azurecr.io/${project.projectNormalizedName}:latest" -f Dockerfile .
      - docker push "MY_ACR_NAME.azurecr.io/${project.projectNormalizedName}:latest"
    only:
      - main
    
    # Continuous Deployment Stage 2: Deploy image to AKS
    deploy-to-aks
    stage: deploy
    image: bitnami/kubectl:latest
    before_script:
      - echo "$KUBE_CONFIG" > kubeconfig.yaml
      - export KUBECONFIG=kubeconfig.yaml
    script:
      - kubectl set image deployment/my-aks-deployment my-container-name="$MY_ACR_NAME.azurecr.io/${project.projectNormalizedName}:latest" --namespace=default
      - kubectl rollout status deployment/my-aks-deployment --namespace=default
    only:
      - main
  infraDeployments: |-
    @@@freemarker
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${project.projectNormalizedName}
    spec:
    selector:
      matchedLabels:
      app: ${project.projectNormalizedName}
    replicas: ${recipe.vars.podk8sreplicas}
    template:
      metadata:
      labels:
        app: ${project.projectNormalizedName}
      spec:
    containers:
    - name: ${project.projectNormalizedName}
        image: ${recipe.vars.repositoryPath}/${project.projectNormalizedName}:latest
        ports:
        - containerPort: 80
  infraServices: |-
    @@@freemarker
    # Service to expose the k8s app
    apiVersion: v1
    kind: Service
    metadata:
    name: ${project.projectNormalizedName}
    spec:
    selector:
      app: ${project.projectNormalizedName}
    ports:
      - protocol: TCP
      port: 80
      targetPort: ${(recipe.vars.port + project.index)?string["0"]}
    type: LoadBalancer
  Dockerfile: |-
    @@@freemarker
    #### Build Stage
    FROM maven:3.9.8-eclipse-temurin-21 AS build
    COPY src /home/app/src
    COPY pom.xml /home/app
    COPY .env /home/app
    WORKDIR /home/app
    RUN mvn -f pom.xml clean package
    
    #### Execution Stage
    FROM openjdk:${recipe.vars.jdkVersion}-jdk-slim
    WORKDIR /app
    
    COPY --from=build /home/app/target/${project.projectNormalizedName + recipe.vars.appVersion + '.jar'} /app/${project.projectNormalizedName + recipe.vars.appVersion}.jar
    
    VOLUME /app
    VOLUME /data
    
    EXPOSE ${(recipe.vars.port + project.index)?string["0"]}
    
    CMD ["java", "-jar", "${project.projectNormalizedName + recipe.vars.appVersion + '.jar'}"]
  pom: |-
    @@@freemarker
    @@@newPrompt
    [CONTEXT]
    ${project.imports?join("\n")}
    [/CONTEXT]
    
    Using the pom.xml content below as a template, retrieve a complete version of the pom.xml content replacing the !!imports!! with the needed java dependencies for the actual context. DON'T INCLUDE ANYTHING ELSE, JUST THE POM.XML CONTENT!
    Also include the most recent Spring Sleuth dependency to improve the loggin system.
    Keep the dependencies already included as it is.
    
    <project xmlns="http://maven.apache.org/POM/4.0.0"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
        <modelVersion>4.0.0</modelVersion>
    
        <parent>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-parent</artifactId>
            <version>${recipe.vars.springBootVersion}</version>
            <relativePath/>
        </parent>
    
        <groupId>${recipe.vars.groupId}</groupId>
        <artifactId>${project.projectNormalizedName}</artifactId>
        <version>${recipe.vars.appVersion}</version>
        <packaging>jar</packaging>
    
        <name>${project.projectNormalizedName}</name>
        <description>${project.projectNormalizedName} for Spring Boot</description>
    
        <properties>
            <java.version>${recipe.vars.jdkVersion}</java.version>
            <spring-boot.version>${recipe.vars.springBootVersion}</spring-boot.version>
            <spring-shell.version>${recipe.vars.springShellVersion}</spring-shell.version>
        </properties>
    
        <#noparse>
        <dependencyManagement>
            <dependencies>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-dependencies</artifactId>
                    <version>${spring-boot.version}</version>
                    <type>pom</type>
                    <scope>import</scope>
                </dependency>
            </dependencies>
        </dependencyManagement>
        </#noparse>
    
        <dependencies>
            <dependency>
                <groupId>org.springframework.kafka</groupId>
                <artifactId>spring-kafka</artifactId>
                <version>3.2.4</version>
            </dependency>
            <dependency>
                <groupId>io.github.resilience4j</groupId>
                <artifactId>resilience4j-spring-boot2</artifactId>
            </dependency>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-starter-aop</artifactId>
            </dependency>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-starter-web</artifactId>
            </dependency>
            <dependency>
                <#noparse>
                <groupId>org.springframework.shell</groupId>
                <artifactId>spring-shell-starter</artifactId>
                <version>${spring-shell.version}</version>
                </#noparse>
            </dependency>
            <dependency>
                <groupId>org.projectlombok</groupId>
                <artifactId>lombok</artifactId>
                <scope>provided</provided>
            </dependency>
            <dependency>
                <groupId>com.h2databsase</groupId>
                <artifactId>h2</artifactId>
            </dependency>
            <dependency>
                <groupId>org.hsqldb</groupId>
                <artifactId>hsqldb</artifactId>
                <version>2.7.4</version>
                <scope>runtime</scope>
            </dependency>            
            !!imports!!
        </dependencies>
    
        <#noparse>
        <build>
            <plugins>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-compiler-plugin</artifactId>
                    <version>3.13.0</version>
                    <configuration>
                        <source>${java.version}</source>
                        <target>${java.version}</target>
                    </configuration>
                </plugin>
                <plugin>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-maven-plugin</artifactId>
                    <version>3.4.1</version>
                </plugin>
            </plugins>
        </build>
        </#noparse>
    
    </project>
  readme: |-
    @@@freemarker
    # README #
    
    Microservice created based on ${project.projectNormalizedName} Cobol Application
    
    ### Docker run local
    ```bash
    ./mvnw clean package
    docker-compose up -d
    ```
    
    ### Run Install dependencies
    ```bash
    ./mvnw clean package
    ```
    
    ### Run spring tests and package
    ```bash
    ./mvnw clean package
    ```
    
    ### Run spring local
    ```bash
    ./mvnw spring-boot:run
    ```
  mvnw: |-
    #!/bin/sh
    # ----------------------------------------------------------------------------
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #    http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing,
    # software distributed under the License is distributed on an
    # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    # KIND, either express or implied.  See the License for the
    # specific language governing permissions and limitations
    # under the License.
    # ----------------------------------------------------------------------------
    
    # ----------------------------------------------------------------------------
    # Apache Maven Wrapper startup batch script, version 3.3.2
    #
    # Optional ENV vars
    # -----------------
    #   JAVA_HOME - location of a JDK home dir, required when download maven via java source
    #   MVNW_REPOURL - repo url base for downloading maven distribution
    #   MVNW_USERNAME/MVNW_PASSWORD - user and password for downloading maven
    #   MVNW_VERBOSE - true: enable verbose log; debug: trace the mvnw script; others: silence the output
    # ----------------------------------------------------------------------------
    
    set -euf
    [ "${MVNW_VERBOSE-}" != debug ] || set -x
    
    # OS specific support.
    native_path() { printf %s\\n "$1"; }
    case "$(uname)" in
    CYGWIN* | MINGW*)
      [ -z "${JAVA_HOME-}" ] || JAVA_HOME="$(cygpath --unix "$JAVA_HOME")"
      native_path() { cygpath --path --windows "$1"; }
      ;;
    esac
    
    # set JAVACMD and JAVACCMD
    set_java_home() {
      # For Cygwin and MinGW, ensure paths are in Unix format before anything is touched
      if [ -n "${JAVA_HOME-}" ]; then
        if [ -x "$JAVA_HOME/jre/sh/java" ]; then
          # IBM's JDK on AIX uses strange locations for the executables
          JAVACMD="$JAVA_HOME/jre/sh/java"
          JAVACCMD="$JAVA_HOME/jre/sh/javac"
        else
          JAVACMD="$JAVA_HOME/bin/java"
          JAVACCMD="$JAVA_HOME/bin/javac"
    
          if [ ! -x "$JAVACMD" ] || [ ! -x "$JAVACCMD" ]; then
            echo "The JAVA_HOME environment variable is not defined correctly, so mvnw cannot run." >&2
            echo "JAVA_HOME is set to \"$JAVA_HOME\", but \"\$JAVA_HOME/bin/java\" or \"\$JAVA_HOME/bin/javac\" does not exist." >&2
            return 1
          fi
        fi
      else
        JAVACMD="$(
          'set' +e
          'unset' -f command 2>/dev/null
          'command' -v java
        )" || :
        JAVACCMD="$(
          'set' +e
          'unset' -f command 2>/dev/null
          'command' -v javac
        )" || :

        if [ ! -x "${JAVACMD-}" ] || [ ! -x "${JAVACCMD-}" ]; then
          echo "The java/javac command does not exist in PATH nor is JAVA_HOME set, so mvnw cannot run." >&2
          return 1
        fi
      fi
    }
    
    # hash string like Java String::hashCode
    hash_string() {
      str="${1:-}" h=0
      while [ -n "$str" ]; do
        char="${str%"${str#?}"}"
        h=$(((h * 31 + $(LC_CTYPE=C printf %d "'$char")) % 4294967296))
        str="${str#?}"
      done
      printf %x\\n $h
    }
    
    verbose() { :; }
    [ "${MVNW_VERBOSE-}" != true ] || verbose() { printf %s\\n "${1-}"; }

    die() {
      printf %s\\n "$1" >&2
      exit 1
    }
    
    trim() {
      # MWRAPPER-139:
      #   Trims trailing and leading whitespace, carriage returns, tabs, and linefeeds.
      #   Needed for removing poorly interpreted newline sequences when running in more
      #   exotic environments such as mingw bash on Windows.
      printf "%s" "${1}" | tr -d '[:space:]'
    }
    
    # parse distributionUrl and optional distributionSha256Sum, requires .mvn/wrapper/maven-wrapper.properties
    while IFS="=" read -r key value; do
      case "${key-}" in
      distributionUrl) distributionUrl=$(trim "${value-}") ;;
      distributionSha256Sum) distributionSha256Sum=$(trim "${value-}") ;;
      esac
    done <"${0%/*}/.mvn/wrapper/maven-wrapper.properties"
    [ -n "${distributionUrl-}" ] || die "cannot read distributionUrl property in ${0%/*}/.mvn/wrapper/maven-wrapper.properties"
    
    case "${distributionUrl##*/}" in
    maven-mvnd-*bin.*)
      MVN_CMD=mvnd.sh _MVNW_REPO_PATTERN=/maven/mvnd/
      case "${PROCESSOR_ARCHITECTURE-}${PROCESSOR_ARCHITEW6432-}:$(uname -a)" in
      *AMD64:CYGWIN* | *AMD64:MINGW*) distributionPlatform=windows-amd64 ;;
      :Darwin*x86_64) distributionPlatform=darwin-amd64 ;;
      :Darwin*arm64) distributionPlatform=darwin-aarch64 ;;
      :Linux*x86_64*) distributionPlatform=linux-amd64 ;;
      *)
        echo "Cannot detect native platform for mvnd on $(uname)-$(uname -m), use pure java version" >&2
        distributionPlatform=linux-amd64
        ;;
      esac
      distributionUrl="${distributionUrl%-bin.*}-$distributionPlatform.zip"
      ;;
    maven-mvnd-*) MVN_CMD=mvnd.sh _MVNW_REPO_PATTERN=/maven/mvnd/ ;;
    *) MVN_CMD="mvn${0##*/mvnw}" _MVNW_REPO_PATTERN=/org/apache/maven/ ;;
    esac
    
    # apply MVNW_REPOURL and calculate MAVEN_HOME
    # maven home pattern: ~/.m2/wrapper/dists/{apache-maven-<version>,maven-mvnd-<version>-<platform>}/<hash>
    [ -z "${MVNW_REPOURL-}" ] || distributionUrl="$MVNW_REPOURL$_MVNW_REPO_PATTERN${distributionUrl#*"$_MVNW_REPO_PATTERN"}"
    distributionUrlName="${distributionUrl##*/}"
    distributionUrlNameMain="${distributionUrlName%.*}"
    distributionUrlNameMain="${distributionUrlNameMain%-bin}"
    MAVEN_USER_HOME="${MAVEN_USER_HOME:-${HOME}/.m2}"
    MAVEN_HOME="${MAVEN_USER_HOME}/wrapper/dists/${distributionUrlNameMain-}/$(hash_string "$distributionUrl")"
    
    exec_maven() {
      unset MVNW_VERBOSE MVNW_USERNAME MVNW_PASSWORD MVNW_REPOURL || :
      exec "$MAVEN_HOME/bin/$MVN_CMD" "$@" || die "cannot exec $MAVEN_HOME/bin/$MVN_CMD"
    }
    
    if [ -d "$MAVEN_HOME" ]; then
      verbose "found existing MAVEN_HOME at $MAVEN_HOME"
      exec_maven "$@"
    fi
    
    case "${distributionUrl-}" in
    *?-bin.zip | *?maven-mvnd-?*-?*.zip) ;;
    *) die "distributionUrl is not valid, must match *-bin.zip or maven-mvnd-*.zip, but found '${distributionUrl-}'" ;;
    esac
    
    # prepare tmp dir
    if TMP_DOWNLOAD_DIR="$(mktemp -d)" && [ -d "$TMP_DOWNLOAD_DIR" ]; then
      clean() { rm -rf -- "$TMP_DOWNLOAD_DIR"; }
      trap clean HUP INT TERM EXIT
    else
      die "cannot create temp dir"
    fi
    
    mkdir -p -- "${MAVEN_HOME%/*}"
    
    # Download and Install Apache Maven
    verbose "Couldn't find MAVEN_HOME, downloading and installing it ..."
    verbose "Downloading from: $distributionUrl"
    verbose "Downloading to: $TMP_DOWNLOAD_DIR/$distributionUrlName"
    
    # select .zip or .tar.gz
    if ! command -v unzip >/dev/null; then
      distributionUrl="${distributionUrl%.zip}.tar.gz"
      distributionUrlName="${distributionUrl##*/}"
    fi
    
    # verbose opt
    __MVNW_QUIET_WGET=--quiet __MVNW_QUIET_CURL=--silent __MVNW_QUIET_UNZIP=-q __MVNW_QUIET_TAR=''
    [ "${MVNW_VERBOSE-}" != true ] || __MVNW_QUIET_WGET='' __MVNW_QUIET_CURL='' __MVNW_QUIET_UNZIP='' __MVNW_QUIET_TAR=v
    
    # normalize http auth
    case "${MVNW_PASSWORD:+has-password}" in
    '') MVNW_USERNAME='' MVNW_PASSWORD='' ;;
    has-password) [ -n "${MVNW_USERNAME-}" ] || MVNW_USERNAME='' MVNW_PASSWORD='' ;;
    esac
    
    if [ -z "${MVNW_USERNAME-}" ] && command -v wget >/dev/null; then
      verbose "Found wget ... using wget"
      wget ${__MVNW_QUIET_WGET:+"$__MVNW_QUIET_WGET"} "$distributionUrl" -O "$TMP_DOWNLOAD_DIR/$distributionUrlName" || die "wget: Failed to fetch $distributionUrl"
    elif [ -z "${MVNW_USERNAME-}" ] && command -v curl >/dev/null; then
      verbose "Found curl ... using curl"
      curl ${__MVNW_QUIET_CURL:+"$__MVNW_QUIET_CURL"} -f -L -o "$TMP_DOWNLOAD_DIR/$distributionUrlName" "$distributionUrl" || die "curl: Failed to fetch $distributionUrl"
    elif set_java_home; then
      verbose "Falling back to use Java to download"
      javaSource="$TMP_DOWNLOAD_DIR/Downloader.java"
      targetZip="$TMP_DOWNLOAD_DIR/$distributionUrlName"
      cat >"$javaSource" <<-END
        public class Downloader extends java.net.Authenticator
        {
          protected java.net.PasswordAuthentication getPasswordAuthentication()
          {
            return new java.net.PasswordAuthentication( System.getenv( "MVNW_USERNAME" ), System.getenv( "MVNW_PASSWORD" ).toCharArray() );
          }
          public static void main( String[] args ) throws Exception
          {
            setDefault( new Downloader() );
            java.nio.file.Files.copy( java.net.URI.create( args[0] ).toURL().openStream(), java.nio.file.Paths.get( args[1] ).toAbsolutePath().normalize() );
          }
        }
        END
      # For Cygwin/MinGW, switch paths to Windows format before running javac and java
      verbose " - Compiling Downloader.java ..."
      "$(native_path "$JAVACCMD")" "$(native_path "$javaSource")" || die "Failed to compile Downloader.java"
      verbose " - Running Downloader.java ..."
      "$(native_path "$JAVACMD")" -cp "$(native_path "$TMP_DOWNLOAD_DIR")" Downloader "$distributionUrl" "$(native_path "$targetZip")"
    fi
    
    # If specified, validate the SHA-256 sum of the Maven distribution zip file
    if [ -n "${distributionSha256Sum-}" ]; then
      distributionSha256Result=false
      if [ "$MVN_CMD" = mvnd.sh ]; then
        echo "Checksum validation is not supported for maven-mvnd." >&2
        echo "Please disable validation by removing 'distributionSha256Sum' from your maven-wrapper.properties." >&2
        exit 1
      elif command -v sha256sum >/dev/null; then
        if echo "$distributionSha256Sum  $TMP_DOWNLOAD_DIR/$distributionUrlName" | sha256sum -c >/dev/null 2>&1; then
          distributionSha256Result=true
        fi
      elif command -v shasum >/dev/null; then
        if echo "$distributionSha256Sum  $TMP_DOWNLOAD_DIR/$distributionUrlName" | shasum -a 256 -c >/dev/null 2>&1; then
          distributionSha256Result=true
        fi
      else
        echo "Checksum validation was requested but neither 'sha256sum' or 'shasum' are available." >&2
        echo "Please install either command, or disable validation by removing 'distributionSha256Sum' from your maven-wrapper.properties." >&2
        exit 1
      fi
      if [ $distributionSha256Result = false ]; then
        echo "Error: Failed to validate Maven distribution SHA-256, your Maven distribution might be compromised." >&2
        echo "If you updated your Maven version, you need to update the specified distributionSha256Sum property." >&2
        exit 1
      fi
    fi
    
    # unzip and move
    if command -v unzip >/dev/null; then
      unzip ${__MVNW_QUIET_UNZIP:+"$__MVNW_QUIET_UNZIP"} "$TMP_DOWNLOAD_DIR/$distributionUrlName" -d "$TMP_DOWNLOAD_DIR" || die "failed to unzip"
    else
      tar xzf${__MVNW_QUIET_TAR:+"$__MVNW_QUIET_TAR"} "$TMP_DOWNLOAD_DIR/$distributionUrlName" -C "$TMP_DOWNLOAD_DIR" || die "failed to untar"
    fi
    printf %s\\n "$distributionUrl" >"$TMP_DOWNLOAD_DIR/$distributionUrlNameMain/mvnw.url"
    mv -- "$TMP_DOWNLOAD_DIR/$distributionUrlNameMain" "$MAVEN_HOME" || [ -d "$MAVEN_HOME" ] || die "fail to move MAVEN_HOME"
    
    clean || :
    exec_maven "$@"
  mvnwCmd: |-
    <# : batch portion
    @REM ----------------------------------------------------------------------------
    @REM Licensed to the Apache Software Foundation (ASF) under one
    @REM or more contributor license agreements.  See the NOTICE file
    @REM distributed with this work for additional information
    @REM regarding copyright ownership.  The ASF licenses this file
    @REM to you under the Apache License, Version 2.0 (the
    @REM "License"); you may not use this file except in compliance
    @REM with the License.  You may obtain a copy of the License at
    @REM
    @REM    http://www.apache.org/licenses/LICENSE-2.0
    @REM
    @REM Unless required by applicable law or agreed to in writing,
    @REM software distributed under the License is distributed on an
    @REM "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    @REM KIND, either express or implied.  See the License for the
    @REM specific language governing permissions and limitations
    @REM under the License.
    @REM ----------------------------------------------------------------------------
    
    @REM ----------------------------------------------------------------------------
    @REM Apache Maven Wrapper startup batch script, version 3.3.2
    @REM
    @REM Optional ENV vars
    @REM   MVNW_REPOURL - repo url base for downloading maven distribution
    @REM   MVNW_USERNAME/MVNW_PASSWORD - user and password for downloading maven
    @REM   MVNW_VERBOSE - true: enable verbose log; others: silence the output
    @REM ----------------------------------------------------------------------------
    
    @IF "%__MVNW_ARG0_NAME__%"=="" (SET __MVNW_ARG0_NAME__=%~nx0)
    @SET __MVNW_CMD__=
    @SET __MVNW_ERROR__=
    @SET __MVNW_PSMODULEP_SAVE=%PSModulePath%
    @SET PSModulePath=
    @FOR /F "usebackq tokens=1* delims==" %%A IN (`powershell -noprofile "& {$scriptDir='%~dp0'; $script='%__MVNW_ARG0_NAME__%'; icm -ScriptBlock ([Scriptblock]::Create((Get-Content -Raw '%~f0'))) -NoNewScope}"`) DO @(
      IF "%%A"=="MVN_CMD" (set __MVNW_CMD__=%%B) ELSE IF "%%B"=="" (echo %%A) ELSE (echo %%A=%%B)
    )
    @SET PSModulePath=%__MVNW_PSMODULEP_SAVE%
    @SET __MVNW_PSMODULEP_SAVE=
    @SET __MVNW_ARG0_NAME__=
    @SET MVNW_USERNAME=
    @SET MVNW_PASSWORD=
    @IF NOT "%__MVNW_CMD__%"=="" (%__MVNW_CMD__% %*)
    @echo Cannot start maven from wrapper >&2 && exit /b 1
    @GOTO :EOF
    : end batch / begin powershell #>
    
    $ErrorActionPreference = "Stop"
    if ($env:MVNW_VERBOSE -eq "true") {
      $VerbosePreference = "Continue"
    }
    
    # calculate distributionUrl, requires .mvn/wrapper/maven-wrapper.properties
    $distributionUrl = (Get-Content -Raw "$scriptDir/.mvn/wrapper/maven-wrapper.properties" | ConvertFrom-StringData).distributionUrl
    if (!$distributionUrl) {
      Write-Error "cannot read distributionUrl property in $scriptDir/.mvn/wrapper/maven-wrapper.properties"
    }
    
    switch -wildcard -casesensitive ( $($distributionUrl -replace '^.*/','') ) {
      "maven-mvnd-*" {
        $USE_MVND = $true
        $distributionUrl = $distributionUrl -replace '-bin\.[^.]*$',"-windows-amd64.zip"
        $MVN_CMD = "mvnd.cmd"
        break
      }
      default {
        $USE_MVND = $false
        $MVN_CMD = $script -replace '^mvnw','mvn'
        break
      }
    }
    
    # apply MVNW_REPOURL and calculate MAVEN_HOME
    # maven home pattern: ~/.m2/wrapper/dists/{apache-maven-<version>,maven-mvnd-<version>-<platform>}/<hash>
    if ($env:MVNW_REPOURL) {
      $MVNW_REPO_PATTERN = if ($USE_MVND) { "/org/apache/maven/" } else { "/maven/mvnd/" }
      $distributionUrl = "$env:MVNW_REPOURL$MVNW_REPO_PATTERN$($distributionUrl -replace '^.*'+$MVNW_REPO_PATTERN,'')"
    }
    $distributionUrlName = $distributionUrl -replace '^.*/',''
    $distributionUrlNameMain = $distributionUrlName -replace '\.[^.]*$','' -replace '-bin$',''
    $MAVEN_HOME_PARENT = "$HOME/.m2/wrapper/dists/$distributionUrlNameMain"
    if ($env:MAVEN_USER_HOME) {
      $MAVEN_HOME_PARENT = "$env:MAVEN_USER_HOME/wrapper/dists/$distributionUrlNameMain"
    }
    $MAVEN_HOME_NAME = ([System.Security.Cryptography.MD5]::Create().ComputeHash([byte[]][char[]]$distributionUrl) | ForEach-Object {$_.ToString("x2")}) -join ''
    $MAVEN_HOME = "$MAVEN_HOME_PARENT/$MAVEN_HOME_NAME"
    
    if (Test-Path -Path "$MAVEN_HOME" -PathType Container) {
      Write-Verbose "found existing MAVEN_HOME at $MAVEN_HOME"
      Write-Output "MVN_CMD=$MAVEN_HOME/bin/$MVN_CMD"
      exit $?
    }
    
    if (! $distributionUrlNameMain -or ($distributionUrlName -eq $distributionUrlNameMain)) {
      Write-Error "distributionUrl is not valid, must end with *-bin.zip, but found $distributionUrl"
    }
    
    # prepare tmp dir
    $TMP_DOWNLOAD_DIR_HOLDER = New-TemporaryFile
    $TMP_DOWNLOAD_DIR = New-Item -Itemtype Directory -Path "$TMP_DOWNLOAD_DIR_HOLDER.dir"
    $TMP_DOWNLOAD_DIR_HOLDER.Delete() | Out-Null
    trap {
      if ($TMP_DOWNLOAD_DIR.Exists) {
        try { Remove-Item $TMP_DOWNLOAD_DIR -Recurse -Force | Out-Null }
        catch { Write-Warning "Cannot remove $TMP_DOWNLOAD_DIR" }
      }
    }
    
    New-Item -Itemtype Directory -Path "$MAVEN_HOME_PARENT" -Force | Out-Null
    
    # Download and Install Apache Maven
    Write-Verbose "Couldn't find MAVEN_HOME, downloading and installing it ..."
    Write-Verbose "Downloading from: $distributionUrl"
    Write-Verbose "Downloading to: $TMP_DOWNLOAD_DIR/$distributionUrlName"
    
    $webclient = New-Object System.Net.WebClient
    if ($env:MVNW_USERNAME -and $env:MVNW_PASSWORD) {
      $webclient.Credentials = New-Object System.Net.NetworkCredential($env:MVNW_USERNAME, $env:MVNW_PASSWORD)
    }
    [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
    $webclient.DownloadFile($distributionUrl, "$TMP_DOWNLOAD_DIR/$distributionUrlName") | Out-Null
    
    # If specified, validate the SHA-256 sum of the Maven distribution zip file
    $distributionSha256Sum = (Get-Content -Raw "$scriptDir/.mvn/wrapper/maven-wrapper.properties" | ConvertFrom-StringData).distributionSha256Sum
    if ($distributionSha256Sum) {
      if ($USE_MVND) {
        Write-Error "Checksum validation is not supported for maven-mvnd. `nPlease disable validation by removing 'distributionSha256Sum' from your maven-wrapper.properties."
      }
      Import-Module $PSHOME\Modules\Microsoft.PowerShell.Utility -Function Get-FileHash
      if ((Get-FileHash "$TMP_DOWNLOAD_DIR/$distributionUrlName" -Algorithm SHA256).Hash.ToLower() -ne $distributionSha256Sum) {
        Write-Error "Error: Failed to validate Maven distribution SHA-256, your Maven distribution might be compromised. If you updated your Maven version, you need to update the specified distributionSha256Sum property."
      }
    }
    
    # unzip and move
    Expand-Archive "$TMP_DOWNLOAD_DIR/$distributionUrlName" -DestinationPath "$TMP_DOWNLOAD_DIR" | Out-Null
    Rename-Item -Path "$TMP_DOWNLOAD_DIR/$distributionUrlNameMain" -NewName $MAVEN_HOME_NAME | Out-Null
    try {
      Move-Item -Path "$TMP_DOWNLOAD_DIR/$MAVEN_HOME_NAME" -Destination $MAVEN_HOME_PARENT | Out-Null
    } catch {
      if (! (Test-Path -Path "$MAVEN_HOME" -PathType Container)) {
        Write-Error "fail to move MAVEN_HOME"
      }
    } finally {
      try { Remove-Item $TMP_DOWNLOAD_DIR -Recurse -Force | Out-Null }
      catch { Write-Warning "Cannot remove $TMP_DOWNLOAD_DIR" }
    }
    
    Write-Output "MVN_CMD=$MAVEN_HOME/bin/$MVN_CMD"
summarization:
  cobolParagraphsFlowCypherQuery: |-
    MATCH (p:COBOLParagraph)
    OPTIONAL MATCH (p)-[:CONTAINS]-(c)
    WHERE c:COBOLPerform OR c:COBOLCall
    WITH
      p,
      c,
      CASE
            WHEN 'COBOLPerform' in labels(c) THEN {name: c.name, type: "perform", rawCode: c.rawCode}
            WHEN 'COBOLCall' in labels(c) THEN {name: c.name, type: "call", rawCode: c.rawCode}
            ELSE null
          END AS perform,
      apoc.text.replace(apoc.text.join(
         [line IN apoc.text.split(replace(p.rawCode, p.name, ""), '\n') 
          WHERE size(line) >= 7 AND substring(line, 6, 1) <> '*'], '\n'
       ), '[^A-Z]', '') AS cleanedCode        
      ORDER BY id(p), id(c)
    WITH
      p,
      cleanedCode,
      CASE WHEN cleanedCode in ['EXIT','ABEND'] THEN true ELSE false END AS exitParagraph,
      CASE WHEN '' = cleanedCode THEN true ELSE false END AS emptyParagraph,
      COLLECT(perform) AS children
      RETURN {
        paragraph: p.name,
        program: p.programName,
        rawCode: p.rawCode,
        exitParagraph: exitParagraph,
        emptyParagraph: emptyParagraph,
        children: children
      } AS result
  cobolVariablesClassificationCypherQuery: |-
    MATCH (it)
    WHERE it:COBOLStorage OR it:COBOLLinkage OR it:COBOLFileRecordStorage
    OPTIONAL MATCH (it)-[:CONTAINS]->(child)
    WHERE child:COBOLStorage OR child:COBOLLinkage OR child:COBOLFileRecordStorage
    WITH it, COUNT(child) AS child_count
    WHERE child_count > 0 OR it.level = 1
    
    OPTIONAL MATCH (parent)-[:CONTAINS]->(it)
    WHERE parent:COBOLStorage OR parent:COBOLLinkage OR parent:COBOLFileRecordStorage
    OPTIONAL MATCH (prg:COBOLProgram)-[*]->(it)
    WITH it, parent, prg
    
    OPTIONAL MATCH (it)-[:CONTAINS]->(descendant)
    WHERE descendant:COBOLStorage OR descendant:COBOLLinkage OR descendant:COBOLFileRecordStorage
    WITH  it,
    replace(apoc.text.capitalizeAll(replace(toLower(it.name), "-", " ")), " ", "") AS itPascalCaseName,
    parent,
    prg,
    COLLECT(DISTINCT descendant.rawCode) AS descendantCodes
    
    OPTIONAL MATCH (it)-[:CONTAINS]->(child)
    WHERE child:COBOLStorage OR child:COBOLLinkage OR child:COBOLFileRecordStorage
    OPTIONAL MATCH (child)-[:CONTAINS]->(grandChild)
    WHERE grandChild:COBOLStorage OR grandChild:COBOLLinkage OR grandChild:COBOLFileRecordStorage
    
    WITH it,
    itPascalCaseName,
    parent,
    prg,
    descendantCodes,
    COLLECT(DISTINCT CASE WHEN grandChild IS NOT NULL THEN child.name  ELSE NULL END) AS childrenWithDescendants,
    it.rawCode +
      CASE
      WHEN SIZE(descendantCodes) > 0 THEN '\n' + apoc.text.join(descendantCodes, '\n')
      ELSE ''
      END AS code
    
    ORDER BY it.level DESC
    
    RETURN
    CASE 
    WHEN SIZE(SPLIT(code, "\n"))>1 THEN true
    ELSE false
    END                            AS complexVariable,
    id(it)                         AS id,
    prg.name                       AS program,
    it.name                        AS name,
    labels(it)                     AS label,
    itPascalCaseName + 'Dto'       AS javaName,
    itPascalCaseName + 'Dto.java'  AS file,
    it.level                       AS level,
    id(parent)                     AS parentId,
    parent.name                    AS parentName,
    code,
    [childName IN childrenWithDescendants WHERE childName IS NOT NULL] AS dependencies,
    [childName IN childrenWithDescendants WHERE childName IS NOT NULL | replace(apoc.text.capitalizeAll(replace(toLower(childName), "-", " ")), " ", "")] AS dependenciesJava
  cobolFullVariablesCypherQuery: |-
    MATCH (ws)
    WHERE (ws:COBOLWorkingStorageSection) OR (ws:COBOLLinkageSection)
    MATCH (ws)-[:CONTAINS]->(s)
    OPTIONAL MATCH (s)-[*]->(child)
    WHERE (child:COBOLStorage) OR (child:COBOLLinkage)
    WITH
    	s
    	, child
    ORDER BY id(child)
    WITH
    	s
    	, COLLECT(DISTINCT child.name) AS children
    	, COLLECT(child.rawCode) AS children_code
    RETURN
       s.name AS name
       , replace(split(s.filePath, '/')[-1], '.cbl', '') AS program
       , labels(s) AS labels
       , children
       , s.fullRawCode AS code
  cobolVariablesCypherQuery: |-
    MATCH (it)
    WHERE it:COBOLStorage OR it:COBOLLinkage OR it:COBOLFileRecordStorage

    OPTIONAL MATCH (it)-[:CONTAINS]->(child)
    WHERE child:COBOLStorage OR child:COBOLLinkage OR child:COBOLFileRecordStorage
    WITH it, COUNT(child) AS child_count

    OPTIONAL MATCH (parent)-[:CONTAINS]->(it)
    WHERE parent:COBOLStorage OR parent:COBOLLinkage OR parent:COBOLFileRecordStorage
    WITH it, parent, child_count
    RETURN
      it.name as name,
      it.rawCode AS rawCode,
      labels(it)[0] AS label,
      replace(split(it.filePath, '/')[-1], '.cbl', '') AS program,
      parent.name AS parentName,
      child_count AS childCount,
      CASE WHEN child_count=0 AND parent.name is null THEN false ELSE true END AS complex
  fileVariablesCypherQuery: |-
    MATCH (n:COBOLFileRecord)
    OPTIONAL MATCH (n)-[:CONTAINS]->(child)
    WITH n, child
    OPTIONAL MATCH (c)
    WHERE (c:COBOLVsamFile OR c:COBOLFileControl) AND c.name = n.name
    OPTIONAL MATCH (j:COBOLJcl)
    WHERE j.rawCode CONTAINS '//' + c.assignTo + ' '
    OPTIONAL MATCH (a:COBOLFileOperation) 
    WHERE (a.name = n.name OR a.name = child.name) AND a.name <> a.rawCode
    OPTIONAL MATCH (cc:COBOLStorage)
    WHERE apoc.text.regexGroups(a.rawCode, '(WRITE|READ)\s+([A-Z0-9\-]+)\s+(FROM|TO)\s+([A-Z0-9\-]+)')[0][4] = cc.name
    RETURN 
        COLLECT(DISTINCT cc.name) AS fileOperationVariables,
        n.name AS fileName, 
        child.name AS fileVariable, 
        labels(c)[0] AS label,
        replace(split(apoc.text.replace(n.filePath, '\\\\', '/'), '/')[-1], '.cbl', '') AS program,
        c.assignTo AS fileNameJCL,
        apoc.text.regexGroups(j.rawCode, '(?m)^\/\/' + c.assignTo + '\s+DD\s+DSN=(.+)?,')[0][1] AS filePathJCL
  fileComprehensiveDetailsCypherQuery: |-
    // extractCobolFileAndStorageMetadataForJavaModelGenerationCypherQuery
    MATCH (fc)
    WHERE (fc:COBOLFileControl OR fc:COBOLVsamFile)
    OPTIONAL MATCH (fr:COBOLFileRecord) WHERE fr.name = fc.name
    OPTIONAL MATCH (fr)-[CONTAINS]->(frs:COBOLFileRecordStorage)
    OPTIONAL MATCH (fo:COBOLFileOperation) WHERE fo.name IN [fr.name, frs.name]
    OPTIONAL MATCH (s:COBOLStorage) WHERE s.name IN [fo.name, fo.target]
    OPTIONAL MATCH (jcl:COBOLJcl) WHERE jcl.rawCode CONTAINS '//' + fc.assignTo + ' '
    WITH DISTINCT 
        fc,
        fc.assignTo AS jclFileName,
        fc.name AS name,
        frs.name AS frsName,
        apoc.text.regexGroups(jcl.rawCode, '(?m)^\/\/' + fc.assignTo + '\s+DD\s+DSN=(.+)?,')[0][1] AS filePathJCL,
        COLLECT([fc.name, fr.name, fo.name, frs.name, s.name, fc.assignTo]) AS allListOfNames,
        COALESCE(COLLECT(DISTINCT COALESCE(frs.fullRawCode, frs.rawCode))[0], '') AS fileRawCode,
        COALESCE(COLLECT(DISTINCT s.fullRawCode)[0], '') AS storageRawCode,
        CASE WHEN frs.fullRawCode = "" THEN frs.rawCode ELSE frs.fullRawCode END AS fullRawCode,
        fc.recordKey AS recordKey,
        COLLECT(DISTINCT s) AS wsNodes,
        COLLECT(DISTINCT frs) AS frsNodes
    UNWIND allListOfNames AS allListOfGroups
    UNWIND allListOfGroups AS allNames
    WITH
        fc,
        REPLACE(SPLIT(apoc.text.replace(fc.filePath, '\\\\', '/'), '/')[-1], '.cbl', '') AS program,
        HEAD([label IN labels(fc) WHERE label STARTS WITH "COBOL"]) AS label,
        name AS fileControlName,
        frsName AS recordStorageName,
        jclFileName,
        filePathJCL,
        CASE
        WHEN SIZE(apoc.text.split(fileRawCode, ' PIC ')) > SIZE(apoc.text.split(storageRawCode, ' PIC '))
            THEN fileRawCode
            ELSE storageRawCode
            END AS mostComplexRawCode,
        COLLECT(DISTINCT allNames) AS allRelatedVariables,
        fullRawCode,
        recordKey,
        SIZE(wsNodes) AS wsCount,
        SIZE(frsNodes) AS frsCount,
        fileRawCode,
        storageRawCode,
        CASE
            WHEN SIZE(wsNodes)=1 AND SIZE(frsNodes)=1 THEN storageRawCode
            ELSE fullRawCode
        END AS rawCode,
        CASE
            WHEN SIZE(wsNodes)=1 AND SIZE(frsNodes)=1 THEN 'WS'
            ELSE 'FD'
        END AS eligibleVariable     
    
    MATCH (fc)
    WHERE fc:COBOLFileControl OR fc:COBOLVsamFile
    OPTIONAL MATCH (fr:COBOLFileRecord) WHERE fr.name = fc.name
    OPTIONAL MATCH (fr)-[:CONTAINS]->(frs:COBOLFileRecordStorage)
    OPTIONAL MATCH (frs)-[:CONTAINS*0..]->(leaf)
    WHERE NOT (leaf)-[:CONTAINS]->()
    WITH  fc, 
          program, 
          label,
          fileControlName,
          recordStorageName,
          jclFileName,
          filePathJCL,
          mostComplexRawCode,
          allRelatedVariables,
          fullRawCode,
          recordKey,
          rawCode,
          COLLECT(DISTINCT leaf) AS recordStorageLowestLevel,
          eligibleVariable
  
    OPTIONAL MATCH (keyNode:COBOLFileRecordStorage {name: recordKey})
    OPTIONAL MATCH (keyNode)-[:CONTAINS*0..]->(leafKey)
    WHERE NOT (leafKey)-[:CONTAINS]->()
    WITH  fc,
          program,
          label,
          fileControlName,
          recordStorageName,
          jclFileName,
          filePathJCL,
          mostComplexRawCode,
          allRelatedVariables,
          fullRawCode,
          rawCode,
          apoc.text.regexGroups(rawCode, '\s*01\s+([A-Z0-9\-]+)\s*\.?')[0][1] AS domainCobolName,
          recordStorageLowestLevel,
          COLLECT(DISTINCT leafKey) AS recordKeyLowestLevel,
          eligibleVariable
    
    RETURN
        program,
        label,
        fileControlName,
        recordStorageName,
        jclFileName,
        filePathJCL,
        mostComplexRawCode,
        fullRawCode,
        rawCode,
        domainCobolName,
        // replace(apoc.text.capitalizeAll(replace(toLower(apoc.text.regexGroups(mostComplexRawCode, '\s*01\s+([A-Z0-9\-]+)\s*\.?')[0][1]), "-", " ")), " ", "") 
        replace(apoc.text.capitalizeAll(replace(toLower(domainCobolName), "-", " ")), " ", "") 
        + CASE 
            WHEN label = 'COBOLVsamFile' 
            THEN 'Model'
            ELSE 'Dto'
          END AS domainJavaName,
        allRelatedVariables,
        apoc.coll.sortMaps([rs IN recordStorageLowestLevel | { 
         id: id(rs),
         name: rs.name, 
         type: CASE 
                 WHEN toLower(rs.type) = 'integer' THEN 'Integer'
                 WHEN toLower(rs.type) = 'decimal' THEN 'BigDecimal'
                 WHEN toLower(rs.type) = 'text' THEN 'String'
                 ELSE rs.type
               END, 
         precision: rs.precision, 
         scale: rs.scale 
    }], "^id") AS recordStorageLowestLevel,
    apoc.coll.sortMaps([rs IN recordKeyLowestLevel | { 
         id: id(rs),
         name: rs.name, 
         type: CASE 
                 WHEN toLower(rs.type) = 'integer' THEN 'Integer'
                 WHEN toLower(rs.type) = 'decimal' THEN 'BigDecimal'
                 WHEN toLower(rs.type) = 'text' THEN 'String'
                 ELSE rs.type
               END, 
         precision: rs.precision, 
         scale: rs.scale 
    }], "^id") AS recordKeyLowestLevel,
    eligibleVariable
  joltNeo4jTableToJson: |-
    [
      {
        "operation": "shift",
        "spec": {
          "results": {
            "*": {
              "data": {
                "*": {
                  "row": {
                    "*": "[&2].@(4,columns[&0])"
                  }
                }
              }
            }
          }
        }
      }
    ]
  joltNeo4jSingleObjectsToJson: |-
    [
      {
        "operation": "shift",
        "spec": {
          "results": {
            "*": {
              "data": {
                "*": {
                  "row": {
                    "*": "[&2]"
                  }
                }
              }
            }
          }
        }
      }
    ]
fileTemplates:
  superPom: |-
    @@@freemarker
    <project xmlns="http://maven.apache.org/POM/4.0.0"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
      <modelVersion>4.0.0</modelVersion>

      <groupId>${recipe.vars.groupId}</groupId>
      <artifactId>coboltojava</artifactId>
      <version>${recipe.vars.appVersion}</version>
      <packaging>pom</packaging>
          <properties>              
              <java.version>21</java.version>
              <quarkus.version>3.16.2</quarkus.version>
              <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>

              <maven.compiler.source>\${java.version}</maven.compiler.source>
              <maven.compiler.target>\${java.version}</maven.compiler.target>

          </properties>

      <modules>
          <#list projects as project><module>${project.projectNormalizedName}</module>
      </modules>

      <dependencyManagement>
          <dependencies>
              <dependency>
                  <groupId>io.quarkus.platform</groupId>
                  <artifactId>quarkus-bom</artifactId>
                  <version>\${quarkus.version}</version>
                  <type>pom</type>
                  <scope>import</scope>
              </dependency>
          </dependencies>
      </dependencyManagement>

      <build>
          <plugins>
              <plugin>
                  <groupId>\${quarkus.platform.group-id}</groupId>
                  <artifactId>quarkus-maven-plugin</artifactId>
                  <version>\${quarkus.platform.version}</version>
                  <extensions>true</extensions>
                  <executions>
                      <execution>
                          <goals>
                              <goal>build</goal>
                              <goal>generate-code</goal>
                              <goal>generate-code-tests</goal>
                              <goal>native-image-agent</goal>
                          </goals>
                      </execution>
                  </executions>
              </plugin>
              <plugin>
                  <artifactId>maven-compiler-plugin</artifactId>
                  <version>\${compiler-plugin.version}</version>
                  <configuration>
                      <parameters>true</parameters>
                  </configuration>
              </plugin>
          </plugins>
      </build>
    </project>
prompts:
  serviceWriter: |-
    @@@freemarker
    ${projects.NewClasses[fileName+'.java']}
  flatFileItemField: |-
    @@@freemarker
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.annotation;
    
    import java.lang.annotation.ElementType;
    import java.lang.annotation.Retention;
    import java.lang.annotation.RetentionPolicy;
    import java.lang.annotation.Target;
    
    @Target(ElementType.FIELD)
    @Retention(RetentionPolicy.RUNTIME)
    public @interface FlatFileItemField {
        int order();
        int length();
    }
  fileUtils: |-
    @@@freemarker
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.utils;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.annotation.FlatFileItemField;
    import lombok.*;
    
    import java.io.*;
    import java.lang.reflect.Field;
    import java.nio.file.FileSystemException;
    import java.lang.reflect.Field;
    import java.nio.file.Files;
    import java.nio.file.Path;
    import java.nio.file.Paths;
    import java.util.ArrayList;
    import java.util.Arrays;
    import java.util.Comparator;
    import java.util.List;
    import java.util.stream.Stream;
    
    import java.time.format.DateTimeFormatter;
    import java.time.temporal.ChronoField;
    import ch.qos.logback.core.util.StringUtil;
    
    public class FileUtils {
        @Data
        @AllArgsConstructor
        public static class LinePosition {
            int position;
    
            public void add(int value) {
                this.position += value;
            }
        }
    
        public static final Path USER_TEMP_FOLDER_PATH = FileUtils.pathJoin(System.getProperty("user.dir"), "target", "classes");
    
        private FileUtils() {
        }

        public static String paddedContent(String field, int maxLength, String dataType) {
            String paddedContent = null;
            if (StringUtil.isNullOrEmpty(field)) {
                paddedContent = String.format("%-" + maxLength + "s", "");
                return paddedContent;
            }
            int diffLength = maxLength - field.length();
            if (diffLength == 0) {
                return field;
            }
            if (dataType.equals("String")) {
                paddedContent = String.format("%-" + maxLength + "s", field);
                return paddedContent;
            } else if (dataType.equals("Integer")) {
                paddedContent = String.format("%0" + maxLength + "d", Integer.parseInt(field));
                return paddedContent;
            }
            return paddedContent;
        }

        public static String localDateToStringConverter(LocalDate date, String formatStyle) {
            String paddedDate = null;
            if (date != null) {
                DateTimeFormatter formatter = DateTimeFormatter.ofPattern(formatStyle);
                String dateInString = date.format(formatter);
                paddedDate = paddedContent(dateInString, 8, "String");
            } else {
                paddedDate = paddedContent("", 8, "String");
            }
            return paddedDate;
        }

        public static String getDataFromPosition(String data, int beginIndex, int endIndex) {
            if (!StringUtil.isNullOrEmpty(data) && (data.length() >= beginIndex && data.length() >= endIndex)) {
                return data.substring(beginIndex, endIndex);
            } else {
                return "";
            }
        }

        public static long yyyymmddToJulian(String yyyymmdd) {
            if (!StringUtil.isNullOrEmpty(yyyymmdd)) {
                int date = Integer.parseInt(yyyymmdd.trim());
                try {
                    int year = date / 10000;
                    int month = (date % 10000) / 100;
                    int day = date % 100;
                    LocalDate localdate = LocalDate.of(year, month, day);
                    long julianDay = localdate.getLong(ChronoField.EPOCH_DAY) + 2440588L;
                    return julianDay;
                } catch (Exception e) {
                    log.error("Error occured while parsing the date", e);
                    return 0;
                }
            } else {
                return 0;
            }
        }
    
        public static Path pathJoin(Object path, Object... paths) {
            return Paths.get(path.toString(), Arrays.stream(paths).map(Object::toString).toList().toArray(new String[]{})).toAbsolutePath();
        }
    
        public static <T> List<T> readResourceFile(Class<T> clazz, String fileName) throws Exception {
            var path = pathJoin(USER_TEMP_FOLDER_PATH, fileName);
    
            return readAll(clazz, path);
        }
    
        public static <T> void writeResourceFile(List<T> items, String fileName) throws Exception {
            var path = pathJoin(USER_TEMP_FOLDER_PATH, fileName);
    
            if (!Files.exists(path)) {
                Files.createDirectories(path.getParent());
            }
    
            writeAll(items, path);
        }
    
        public static <T> List<T> readAll(Class<T> clazz, Path path) throws Exception {
            List<T> items = new ArrayList<>();
            try (BufferedReader reader = new BufferedReader(new FileReader(path.toString()))) {
                String line;
                while ((line = reader.readLine()) != null) {
                    T item = parseLineIntoObject(clazz, new LinePosition(0), line);
                    items.add(item);
                }
            }
            return items;
        }
    
        private static <T> void assignFieldValue(T itemInstance, Field field, String value)
                throws IllegalAccessException, IllegalArgumentException {
            Class<?> fieldType = field.getType();
    
            if (fieldType == String.class) {
                field.set(itemInstance, value);
            } else if (fieldType == int.class || fieldType == Integer.class) {
                field.set(itemInstance, Integer.parseInt(value));
            } else if (fieldType == long.class || fieldType == Long.class) {
                field.set(itemInstance, Long.parseLong(value));
            } else if (fieldType == double.class || fieldType == Double.class) {
                field.set(itemInstance, Double.parseDouble(value));
            } else if (fieldType == float.class || fieldType == Float.class) {
                field.set(itemInstance, Float.parseFloat(value));
            } else if (fieldType == boolean.class || fieldType == Boolean.class) {
                field.set(itemInstance, Boolean.parseBoolean(value));
            } else if (fieldType == byte.class || fieldType == Byte.class) {
                field.set(itemInstance, Byte.parseByte(value));
            } else if (fieldType == short.class || fieldType == Short.class) {
                field.set(itemInstance, Short.parseShort(value));
            } else if (fieldType == char.class || fieldType == Character.class) {
                if (value.length() == 1) {
                    field.set(itemInstance, value.charAt(0));
                } else {
                    throw new IllegalArgumentException("Char field must contain a single character.");
                }
            } else {
                throw new IllegalArgumentException("Unsupported field type: " + fieldType);
            }
        }
    
        private static <T> T parseLineIntoObject(Class<T> clazz, LinePosition pos, String line) throws Exception {
            T itemInstance = clazz.getDeclaredConstructor().newInstance();
            processField(itemInstance, clazz, pos, line);
            return itemInstance;
        }
    
        private static <T> void processField(T itemInstance, Class<?> clazz, LinePosition pos, String line) throws Exception {
            List<Field> fields = Stream.of(clazz.getDeclaredFields())
                    .filter(field -> field.isAnnotationPresent(FlatFileItemField.class))
                    .sorted(Comparator.comparingInt(field -> field.getAnnotation(FlatFileItemField.class).order()))
                    .toList();
    
            for (Field field : fields) {
                FlatFileItemField annotation = field.getAnnotation(FlatFileItemField.class);
                field.setAccessible(true);
                if (isSimpleFieldType(field.getType())) {
                    int length = annotation.length();
                    var position = pos.getPosition();
                    String fieldValue = line.substring(position, position + length).trim();
                    pos.add(length);
                    assignFieldValue(itemInstance, field, fieldValue);
                } else {
                    Object nestedObject = parseLineIntoObject(field.getType(), pos, line);
                    field.set(itemInstance, nestedObject);
                }
            }
        }
    
        public static <T> void writeAll(List<T> items, Path path) throws Exception {
            StringBuilder fileContentBuilder = new StringBuilder();
            for (T item : items) {
                fileContentBuilder.append(convertToFlatLine(item)).append("\n");
            }
    
            String fileContent = fileContentBuilder.toString();
            try (Writer writer = new FileWriter(path.toString())) {
                writer.write(fileContent);
            }
        }
    
        private static <T> String convertToFlatLine(T item) throws IllegalAccessException {
            StringBuilder lineBuilder = new StringBuilder();
            processObject(item, lineBuilder);
            return lineBuilder.toString();
        }
    
        private static <T> void processObject(T item, StringBuilder lineBuilder) throws IllegalAccessException {
            List<Field> fields = List.of(item.getClass().getDeclaredFields());
            fields = fields.stream()
                    .filter(field -> field.isAnnotationPresent(FlatFileItemField.class))
                    .sorted(Comparator.comparingInt(field -> field.getAnnotation(FlatFileItemField.class).order()))
                    .toList();
    
            for (Field field : fields) {
                field.setAccessible(true);
                if (isSimpleFieldType(field.getType())) {
                    FlatFileItemField annotation = field.getAnnotation(FlatFileItemField.class);
                    String formattedValue = String.format("%-" + annotation.length() + "s", field.get(item).toString());
                    lineBuilder.append(formattedValue);
                } else {
                    processObject(field.get(item), lineBuilder);
                }
            }
        }
    
        private static boolean isSimpleFieldType(Class<?> fieldType) {
            return fieldType.isPrimitive() || fieldType == String.class || Number.class.isAssignableFrom(fieldType)
                    || fieldType == Boolean.class;
        }

        public static <T> T readLineByFilter(Class<T> clazz, Path path, String filter) {
            try (BufferedReader reader = new BufferedReader(new FileReader(path.toString()))) {
                String line;
                T lineResult = null;
                while ((line = reader.readLine()) != null) {
                    if (line.contains(filter)) {
                        LinePosition linePosition = new LinePosition(line.lastIndexOf(filter));
                        T item = parseLineIntoObject(clazz, linePosition, line);
                        lineResult = item;
                        break;
                    }
                }
                return lineResult;
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
    
        }
    
        public static String readNextLine(BufferedReader reader, String lastLine) {
            try (reader) {
                String line;
                String lineResult = null;
                boolean nextLine = false;
                while ((line = reader.readLine()) != null) {
                    if (nextLine) {
                        lineResult = line;
                        break;
                    }
    
                    if (reader.readLine().equals(lastLine)) {
                        nextLine = true;
                    }
                }
                return lineResult;
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
    
        }
    
        private static <T> String convertObjectToLine(Class<T> clazz, T item) {
            try {
                StringBuilder lineBuilder = new StringBuilder();
                processObject(item, lineBuilder);
                return lineBuilder.toString();
            } catch (IllegalAccessException e) {
                System.out.println(e.getMessage());
                return null;
            }
        }
    
        public static BufferedReader openReader(String fileName, String pathVariable) {
            Path path = null;
            if (pathVariable != null) {
                path = pathJoin(pathVariable, fileName);
            } else {
                path = pathJoin(USER_TEMP_FOLDER_PATH, fileName);
            }
            BufferedReader reader = null;
            try {
                reader = new BufferedReader(new FileReader(path.toString()));
            } catch (FileNotFoundException e) {
                throw new RuntimeException(e);
            }
    
            return reader;
        }
    
        public static void closeReader(BufferedReader reader) throws IOException {
            reader.close();
        }
    
        // Mtodos para leitura e escrita linha a linha
        public static <T> void readLineByLine(Class<T> clazz, BufferedReader reader, Context context) throws IOException {
            String line;
            while ((line = reader.readLine()) != null) {
                T item = parseLineIntoObjectWithContext(clazz, context, line);
            }
        }
    
        public static BufferedWriter openWriter(String fileName, String pathVariable) throws IOException {
            Path path = null;
            if (pathVariable != null) {
                path = pathJoin(pathVariable, fileName);
            } else {
                path = pathJoin(USER_TEMP_FOLDER_PATH, fileName);
            }
            BufferedWriter writer = null;
            try {
                writer = new BufferedWriter(new FileWriter(path.toString(), true));
            } catch (FileNotFoundException e) {
                throw new RuntimeException(e);
            }
    
            return writer;
        }
    
        public static void closeWriter(BufferedWriter writer) throws IOException {
            writer.close();
        }
    
        public static <T> void writeItem(Class<T> clazz, BufferedWriter writer, T item) throws IOException {
            String line = null;
            try {
                line = convertObjectToLine(clazz, item);
                if (line != null) {
                    writer.write(line);
                    writer.newLine();
                }
            } catch (Exception ignored) {
            }
        }
    
        private static <T> T parseLineIntoObjectWithContext(Class<T> clazz, Context context, String line) {
            try {
                LinePosition pos = new LinePosition(0);
                T object = parseLineIntoObject(clazz, pos, line);
                context.processItem(object);
                return object;
            } catch (Exception e) {
                e.printStackTrace();
                return null;
            }
        }
    
        @Getter
        @Setter
        @NoArgsConstructor
        public static class Context {
            private int lineCount = 0;
            private final List<Object> items = new ArrayList<>();
    
            public <T> void processItem(T item) {
                lineCount++;
                items.add(item);
            }
        }
    }
  .gitlab-ci.yml: |-
    stages:          # List of stages for jobs, and their order of execution
      - test
      - build
      - deploy
    
    variables:
      IMAGE_NAME: java-sprint-cicd-tests
      IMAGE_TAG: latest
    include:
      - template: Security/Dependency-Scanning.gitlab-ci.yml
    
    
    docker-lint-job:       # This job runs in the build stage, which runs first.
      stage: test
      image: hadolint/hadolint:latest-debian
      script:
        - hadolint Dockerfile
    
    unit-test-job:   # This job runs in the test stage.
      stage: test    # It only starts when the job in the build stage completes successfully.
      image: maven:3.9.8-eclipse-temurin-21
      script:
        - echo "Running unit tests..."
        - mvn clean install
        - mvn clean test
    
    build-job:       # This job runs in the build stage, which runs first.
      stage: build
      image: docker:24.0.5
      services:
        - docker:24.0.5-dind
      before_script:
        - docker login $AZURE_ACR_NAME -u $AZURE_ACR_USERNAME -p $AZURE_ACR_PASSWORD
      script:
        - echo "Building the code..."
        - docker build -t $AZURE_ACR_NAME/$IMAGE_NAME:$IMAGE_TAG -f Dockerfile .
        - docker push $AZURE_ACR_NAME/$IMAGE_NAME:$IMAGE_TAG
    
    deploy-job:      # This job runs in the deploy stage.
      environment: production 
      stage: deploy  # It only runs when *both* jobs in the test stage complete successfully.
      script:
        - echo "Deploying application..."
        - echo "Application successfully deployed."
  README2.md: |-
    Testing Integration with Gitlab - Part 2
    Now including one more file to activate the CI/CD and deploy the image to our azure repository
  controllerTest: |-
    @@@freemarker
    @@@prompt
    
    ${project.controller}
    
    Given the Java Spring Boot Controller class above do:
        1. Generate a Java Spring Boot test class to assert most of the content of the Controller as possible.
  controller: |-
    @@@skip("${#project['isBatch']}")
    @@@freemarker
    @@@prompt@set:project.controller@set:endpoints[]
    [CONTROLLER_TEMPLATE]
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.controller;
    
    !!imports!!

    @RestController
    public class ${fileName?replace(".java", "")} {
        !!classContent!!
    }    
    [/CONTROLLER_TEMPLATE]

    Task:
    As a senior Java engineer, create a RESTful controller method for a Spring Boot MVC application that represents a line-by-line translation of the original COBOL source code. 
    Utilize the existing DTOs and Service methods provided. 
    The method should adhere to enterprise-quality standards and be free of placeholders or incomplete code. JavaDoc must be included.
    
    Imports:
    
    USE those imports below and all necessary dependencies and any others required.
    <imports>
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service.*;
    <imports>
    
    Consider the following list of DTOs: <#list project.dtos as _dto>${_dto.name} as ${_dto.file}, </#list>
    
    These DTOs already exist in the project.
    Use one of these DTOs or primitive types as the return type for the method.
    
    Method Creation:
    
    Create a method named <insert method name> {{methodName}}.
    Based on the method name, determine the appropriate RESTful HTTP method/verb (e.g., GET, POST).
    The method should use the equivalent method from the MainService class for its implementation.

    Endpoints Names:

    <#list blueprint as bp>
    <#list bp.paragraphs as bpp>
    <#list bpp.calls as c>
    For microservice ${c.microservice}, program ${c.program} and paragraph ${c.paragraph} use the endpoint name ${c.endpoint}
    </#list>
    </#list>
    </#list>
    
    Service Method Integration:
    
    Use whatever services that makes sense bellow to connect the endpoints:
    [SERVICES]
    <#if project.services?has_content>
    <#list project.services  as service>
    [SERVICE]
    ${service}
    [/SERVICE]
    </#list>
    </#if>
    [/SERVICES]
    
    Code Generation:
    
    Generate only the method's code suitable for inclusion in a controller class.
    Do not create any classes or main Spring Boot classes.
    Ensure the method is correctly annotated and follows RESTful patterns.
    
    RESTful Patterns:
    
    Use appropriate RESTful annotations (e.g., @GetMapping, @PostMapping) based on the determined HTTP verb.
    Ensure the method handles HTTP requests correctly.
    Do not attempt to enhance the code or implement general best practices unless explicitly instructed.
    The goal is to create a faithful representation of the original code in a RESTful context, not to improve upon it.
    JavaDoc inclusion
    I need the detailed JavaDoc to be generated with the ENGLISH text of the entire method. Remember to document the builders.
    Create the JavaDoc header on the first line and define a detailed description of the method.
    Create the JavaDoc for each field of the class
    Code Author is Capco LLM Automation
    
    Naming and Preservation:
    
    Preserve all names of variables and methods as they appear in the original COBOL code and existing Java code.
    Do not add any logic, data manipulation, or functionality that isn't present in the original service method.
    The controller method should act as a thin wrapper around the service method, primarily handling HTTP-specific concerns.
    Unless explicitly specified in the original service method, the controller should return only HTTP status codes, not data objects.
    If the service method doesn't return a value, the controller should return a ResponseEntity<Void>.
    Maintain compatibility for easy interpretation and maintainability.
    
    Comments and Documentation:
    
    Place any necessary text within Java comment blocks.
    Do not include any additional comments or explanations outside of the code.
    
    Output Format:
    
    Provide only the Java code of the method.
    Do not include introductions, explanations, or any additional text.
    Exclude any extra brackets or unnecessary formatting.
    
    Quality Assurance:
    
    Ensure the code is complete and represents a line-by-line translation of the original COBOL source code.
    Do not include placeholders, straw-man code, or skeleton code.
    Double-check the code for any mistakes or errors before finalizing.
    
    Error Handling:
    
    Do not catch generic exceptions; specify the exception types if necessary.
    Do not swallow exceptions; handle them appropriately.
    Avoid returning commented exceptions.
    
    Internal Checklist:
    
    Before finalizing, verify that all instructions have been followed precisely.
    Use an internal checklist to ensure compliance with all steps.
    
    Consistency and Standards:
    
    Follow standard Java coding conventions and best practices.
    Maintain consistent indentation and formatting throughout the code.
    
    No Placeholders:
    
    Ensure the method contains full implementation code.
    Do not include TODO comments or any unimplemented sections.
    
    Final Notes:
    
    Do not create any classes; only the method code should be returned.
    Remember to omit any documentation or explanations in the output.

    Output:

    After all, replace the !!imports!! placeholder with the import statements required to use whole class/methods you created.
    And replace the !!classContent!! with the endpoints and any fields or properties needed for the whole class.
  serviceContextualize: |-
    @@@freemarker
    [COBOL_PARAGRAPHS]
    <#list project.paragraphs as para>
    <#if (project.serviceSummary?filter(f -> f.serviceName == fileNameWithoutExtension && f.paragraphs?seq_contains(para.paragraph)))?has_content >
    ${para.code}
    </#if>
    </#list>
    [/COBOL_PARAGRAPHS]
    
    [ENDPOINT_CLIENTS_AVAILABLE]
    <#if project.clients?has_content>
    ${project.clients?join("\n\n#############\n\n")}
    </#if>
    [/ENDPOINT_CLIENTS_AVAILABLE]
    
    The current code already include a FileUtils helper class on the classpath that include a sort of different methods to be used replacing tasks for Opening, Closing, Reading and Writing files.
    For any needs on that, please take advantage of the methods below:
    - To OPEN a file and keep it open: 
      public static BufferedReader openReader(String fileName, String pathVariable)
      public static BufferedWriter openWriter(String fileName, String pathVariable)
    - To CLOSE a file:
      public static void closeReader(BufferedReader reader)
      public static void closeWriter(BufferedWriter writer)
    - To READ the whole content of a File to a List
      public static <T> List<T> FileUtils.readResourceFile(Class<T> clazz, String fileName)
    - To READ a single line of content an parse it to a specific Model/DTO class:
      public static <T> void readLineByLine(Class<T> clazz, BufferedReader reader, Context context)
    - To WRITE the whole content of a List<T> of objects to a File:
      public static <T> void FileUtils.writeResourceFile(Class<T> clazz, String fileName)
    - To WRITE a single Model/DTO object to a line in the File:
      public static <T> void writeItem(Class<T> clazz, BufferedWriter writer, T item)
    
    T is a reference to a generic class in Java, in this case it is expecting a Model/DTO class that should hold a single line of content of a file.
    Any BufferReader or BufferWriter that you need to translate a paragraph into a Java Method that will not be closed at the end of it, should declare a variable
    outside of the method scope following the convention:
      readBuffer{PascalCaseNameOfFileName}
      writeBuffer{PascalCaseNameOFileName}
    
    Example:
      To a OPEN INPUT for the file named TRANSACTION-FILE -> readBufferTransactionFile
    
    Also, any paragraph that is reading/writing/closing the content without taking care of the opening of that should consider that already exist on the class scope some buffer declared following the example above. 
    
    [CONSTRAINTS]
      1. Consider the equivalency map of Storage Name and Java Dto below:
        [CONTEXT]
        <#if project.dtoClasses?has_content>
        <#list project.dtoClasses as _cobolStorageName, _dtoCode>
          [DTO_CODE: ${_cobolStorageName}]
          ${_dtoCode}
          [/DTO_CODE: ${_cobolStorageName}]
        </#list>
        </#if>
    
        [MODELS]
        <#if project.modelsClasses?has_content>
        <#list project.modelsClasses as modelName, modelCode>
        ${modelCode}
        </#list>
        </#if>
        [/MODELS]
    
          [LOCAL_VARIABLES]
          <#if project.locals?has_content>
          <#list project.locals as local>
          [VARIABLE]
          ${local.code}
          [/VARIABLE]
          </#list>
          </#if>
          [/LOCAL_VARIABLES]
    
        <#if project.customExceptionClasses?has_content>
        [EXCEPTIONS_CLASS_REFERENCE]
        ${project.customExceptionClasses?join("\n\n#######################\n\n")}
        [/EXCEPTIONS_CLASS_REFERENCE]
        </#if>
    
        [REPOSITORIES]
        <#if project.repositories?has_content>
        <#list project.repositories as repo, repoCode>
        ${repoCode}
        </#list>
        </#if>
        [/REPOSITORIES]
    
        [/CONTEXT]
  dtoFile: |-
    @@@freemarker
    @@@prompt
    @@@mapPut("project.dtosClasses", "${#project['dtos'].?[#this['file'] == #fileName].![#this['name']][0]}")
    <#assign currentDto = project.dtos ? filter(dto -> dto.file == fileName) ? first>
    [TASK]
    Given the [DTO_COBOL_RAW_CODE] follow the [CONSTRAINTS] below to create a Java DTO class and CustomItemProcessor to be used with
    FlatItemReader and FlatItemWriter on a Spring Batch solution.
    
    [DTO_COBOL_RAW_CODE]
    ${currentDto.code}
    [/DTO_COBOL_RAW_CODE]
    
    [CONSTRAINTS]
      0. Leave a comment at the top of the file with the COBOL ORIGINAL VARIABLE NAME
      1. Use Lombok annotation at the class level to generate the Setters and Getters
      2. Use @NoArgsConstructor annotation
      3. Return only the code, nothing more
      4. Don't change the names, only normalize to remove characters different from [a-zA-Z0-9] and use the camelCase approach
      5. The name of the class needs to match the name of the file: ${fileName}
      6. Use the package: ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.dto;
      7. You must use as fields all the last level items of the equivalent COBOL structure.
      8. Ensure that the variables take up the smallest memory footprint possible (i.e. use primitive Java types wherever possible), but at the same time do not sacrifice accuracy, particularly where decimals are involved
      9. Ensure to solve any placeholders or TODO comments
      10. No syntax errors or logical mistakes
      11. Remember to include all the import statements needed within the class
  dto: |-
    @@@freemarker
    @@@prompt
    @@@mapPut("project.dtosClasses", "${#project['dtos'].?[#this['file'] == #fileName].![#this['name']][0]}")
    <#assign currentDto = project.dtos ? filter(dto -> dto.file == fileName) ? first>
    [TASK]
    Given the [DTO_COBOL_RAW_CODE] follow the [CONSTRAINTS] below to create a Java DTO class,
    following the [DTO TEMPLATE].
    
    [DTO_COBOL_RAW_CODE]
    ${currentDto.code}
    [/DTO_COBOL_RAW_CODE]
    
    [DTO TEMPLATE]
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.dto;
    
    import lombok.Data;
    import com.capco.monolith.annotation.FlatFileItemField;
    
    @Data
    public class ${currentDto.javaName} {
        @FlatFileItemField(order = 0, length = 10)
        private String field1;
    
        @FlatFileItemField(order = 1, length = 2)
        private Integer field2;
    
        @FlatFileItemField(order = 2, length = 15)
        private AnotherDto childDto;
    }
    
    
    [CONSTRAINTS]
      0. Leave a comment at the top of the file with the COBOL ORIGINAL VARIABLE NAME
      1. Use Lombok annotation at the class level to generate the Setters and Getters
      2. Use @NoArgsConstructor annotation
      3. Return only the code, nothing more
      4. Don't change the names, only normalize to remove characters different from [a-zA-Z0-9] and use the camelCase approach
      5. The name of the class needs to match the name of the file: ${fileName}
      6. Use the package: ${recipe.vars.groupId + '.' + project.projectNormalizedName}.dto
    <#if (currentDto.dependenciesJava?size > 0) == true>
      7. You must use as field the DTOs below: 
      <#list currentDto.dependenciesJava as dep>
      ${'private ' + dep + 'Dto ' + dep + '; in place of the complex variable ' + currentDto.dependencies[dep_index]}
      </#list>
    </#if>    
      8. Ensure that the variables take up the smallest memory footprint possible (i.e. use primitive Java types wherever possible), but at the same time do not sacrifice accuracy, particularly where decimals are involved
      9. Ensure to solve any placeholders or TODO comments
      10. No syntax errors or logical mistakes
      11. Remember to include all the import statements needed within the class
  pojoFile: |-
    @@@freemarker
    @@@prompt
    @@@mapPut("project.pojosClasses", "${#project['pojos'].?[#this['file'] == #fileName].![#this['name']][0]}")
    <#assign currentPojo = project.pojos ? filter(pojo -> pojo.file == fileName) ? first>
    [TASK]
    Given the [POJO_COBOL_RAW_CODE] follow the [CONSTRAINTS] below to create a Java DTO class,
    following the [DTO TEMPLATE].
    
    [POJO_COBOL_RAW_CODE]
    ${currentPojo.code}
    [/POJO_COBOL_RAW_CODE]
    
    [POJO TEMPLATE]
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.file;
    
    import lombok.Data;
    import com.capco.monolith.annotation.FlatFileItemField;
    
    @Data
    public class ${currentPojo.name} {
        @FlatFileItemField(order = 0, length = 10)
        private String field1;
    
        @FlatFileItemField(order = 1, length = 2)
        private Integer field2;
    
        @FlatFileItemField(order = 2, length = 15)
        private AnotherDto childPojo;
    }
    
    [CONSTRAINTS]
      0. Leave a comment at the top of the file with the COBOL ORIGINAL VARIABLE NAME
      1. Use Lombok annotation at the class level to generate the Setters and Getters
      2. Use @NoArgsConstructor annotation
      3. Return only the code, nothing more
      4. Don't change the names, only normalize to remove characters different from [a-zA-Z0-9] and use the camelCase approach
      5. The name of the class needs to match the name of the file: ${fileName}
      6. Use the package: ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.file
      7. Ensure that the variables take up the smallest memory footprint possible (i.e. use primitive Java types wherever possible), but at the same time do not sacrifice accuracy, particularly where decimals are involved
      8. Ensure to solve any placeholders or TODO comments
      9. No syntax errors or logical mistakes
      10. Remember to include all the import statements needed within the class
      11. Whenever I use ${fileName} after this, remember the content you returned here as the value of this placeholder
      12. Include the necessary annotations for Spring Boot Data ONLY WHEN the Dto relates to a Data Storage you already classified as one of which needs to be persisted/attached to a file/database.
  client: |-
    @@@skip("${#blueprint[#project['index']]['paragraphs'].?[!#this['calls'].isEmpty()].isEmpty()}")
    @@@freemarker
    @@@prompt@set:project.clients[]
    Generate a RestClient interface for endpoints below:
    
    <#list blueprint[project.index].paragraphs as paragraph>
       ${paragraph.calls?map(bp -> 'For CALL ' + bp.paragraph + ' use the microservice ' + bp.microservice + ' endpoints ' + bp.endpoint + ' [CODE_REFERENCE]\n' + bp.code + '\n[/CODE_REFERENCE]')?join("\n")}
    </#list>

    Also be aware that already exist controllers with some endpoints for other microservices. They are listed below. Please use the same name and signature whenever you find a match!
    <#if endpoints?has_content>
    ${endpoints?join("\n\n\n\n")}
    </#if>
    
    [CONSTRAINTS]
      0. The class/interface name needs to be: ${fileName}
      1. Consider the equivalency map of Storage Name and Java Dto below:
        ```
        <#list project.dtos as _dto>
          ${_dto.name} is the same of ${recipe.vars.groupId + '.' + project.projectNormalizedName}.dto.${_dto.file?replace(".java", "")} with the COBOL code below:
          [DTO_CODE]
          ${_dto.code}
          [/DTO_CODE]
        </#list>
        ```
      2. Do not include straw-man code, skeleton code, or any placeholders.
      3. Do not leave any methods without implementation or with TODO comments.
      4. Include any import needed.
      5. Use a standard class/primitive type as return type or any of the DTOs listed.
      6. Return only the code, nothing more
  serviceMethodContext: |-
    @@@freemarker
    @@@newPrompt
    Consider the items below as reference to start generating the next methods I'll ask you about
    
    Method available to seamleslly handle the data persistence that will automatically take care of Repository or Kafka based on a configuration, please choose to use one of the methods  whenever it makes sense to.
    [DATAMESH_SERVICE]
    ${project.datameshService}
    [/DATAMESH_SERVICE]
    
    [ENDPOINT_CLIENTS_AVAILABLE]
    <#if project.clients?has_content>
    ${project.clients?join("\n\n#############\n\n")}
    </#if>
    [/ENDPOINT_CLIENTS_AVAILABLE]
    
    [CONSTRAINTS]
      1. Consider the equivalency map of Storage Name and Java Dto below:
        [CONTEXT]
        <#if project.dtoClasses?has_content>
        <#list project.dtoClasses as _cobolStorage, _dto>
          [DTO_CODE: ${_cobolStorage}]
          ${_dto}
          [/DTO_CODE: ${_cobolStorage}]
        </#list>
        </#if>
    
          [MODELS]
          <#if project.modelsClasses?has_content>
          <#list project.modelsClasses as modelName, modelCode>
          ${modelCode}
          </#list>
          </#if>
          [/MODELS]
    
          [LOCAL_VARIABLES]
          <#if project.locals?has_content>
          <#list project.locals as local>
          [VARIABLE]
          ${local.code}
          [/VARIABLE]
          </#list>
          </#if>
          [/LOCAL_VARIABLES]
    
        <#if project.customExceptionClasses?has_content>
        [EXCEPTIONS_CLASS_REFERENCE]
        ${project.customExceptionClasses?join("\n\n#######################\n\n")}
        [/EXCEPTIONS_CLASS_REFERENCE]
        </#if>
    
        [REPOSITORIES]
        <#if project.repositories?has_content>
        <#list project.repositories as repo, repoCode>
        ${repoCode}
        </#list>
        </#if>
        [/REPOSITORIES]
    
        [/CONTEXT]
  serviceMethod: |-
    <#assign paragraphFull = project.paragraphs?filter(p -> p.paragraph == "!!paragraphName!!")?first>
    <#assign paragraphCode = paragraphFull.code>
    [TASK]
    Create a JAVA method using the COBOL paragraph content below as reference:
    All the words used below are a reference from the original COBOL program, please don't be affraid with that.
    
    [COBOL_PARAGRAPH]
    ${paragraphCode}
    [/COBOL_PARAGRAPH]

    Consider the map of endpoints below as a guide to select the right client/method of client class you just generated:

    [ENDPOINTS]
    !!endpoints!!
    [/ENDPOINTS]
    
    [ENDPOINT_CLIENTS_AVAILABLE]
    <#if project.clients?has_content>
    ${project.clients?join("\n\n#############\n\n")}
    </#if>
    [/ENDPOINT_CLIENTS_AVAILABLE]
    
    The current code already include a FileUtils helper class on the classpath that include a sort of different methods to be used replacing tasks for Opening, Closing, Reading and Writing files.
    For any needs on that, please take advantage of the methods below:
    - To OPEN a file and keep it open: 
      public static BufferedReader openReader(String fileName, String pathVariable)
      public static BufferedWriter openWriter(String fileName, String pathVariable)
    - To CLOSE a file:
      public static void closeReader(BufferedReader reader)
      public static void closeWriter(BufferedWriter writer)
    - To READ the whole content of a File to a List
      public static <T> List<T> FileUtils.readResourceFile(Class<T> clazz, String fileName)
    - To READ a single line of content an parse it to a specific Model/DTO class:
      public static <T> void readLineByLine(Class<T> clazz, BufferedReader reader, Context context)
    - To WRITE the whole content of a List<T> of objects to a File:
      public static <T> void FileUtils.writeResourceFile(Class<T> clazz, String fileName)
    - To WRITE a single Model/DTO object to a line in the File:
      public static <T> void writeItem(Class<T> clazz, BufferedWriter writer, T item)
    
    T is a reference to a generic class in Java, in this case it is expecting a Model/DTO class that should hold a single line of content of a file.
    Any BufferReader or BufferWriter that you need to translate a paragraph into a Java Method that will not be closed at the end of it, should declare a variable
    outside of the method scope following the convention:
      readBuffer{PascalCaseNameOfFileName}
      writeBuffer{PascalCaseNameOFileName}
    
    Example:
      To a OPEN INPUT for the file named TRANSACTION-FILE -> readBufferTransactionFile
    
    Also, any paragraph that is reading/writing/closing the content without taking care of the opening of that should consider that already exist on the class scope some buffer declared following the example above. 
    
    Consider these methods performed by !!paragraphName!!:
    [METHODS]
    <#list paragraphFull.children as child>
    <#if project.myMethods?keys?seq_contains(child.paragraph)>
    ${project.myMethods[child.paragraph]}
    </#if>
    </#list>    
    [/METHODS]
    
    [CONSTRAINTS]
      1. Consider the equivalency map of Storage Name and Java Dto below:
        [CONTEXT]
        <#if project.dtoClasses?has_content>
        <#list project.dtoClasses as _cobolStorageName, _dtoCode>
          <#if paragraphCode?contains(_cobolStorageName)>
          [DTO_CODE: ${_cobolStorageName}]
          ${_dtoCode}
          [/DTO_CODE: ${_cobolStorageName}]
          </#if>
        </#list>
        </#if>
    
        [MODELS]
        <#if project.modelsClasses?has_content>
        <#list project.modelsClasses as modelName, modelCode>
        ${modelCode}
        </#list>
        </#if>
        [/MODELS]
    
          [LOCAL_VARIABLES]
          <#if project.locals?has_content>
          <#list project.locals as local>
          [VARIABLE]
          ${local.code}
          [/VARIABLE]
          </#list>
          </#if>
          [/LOCAL_VARIABLES]
    
        <#if project.customExceptionClasses?has_content>
        [EXCEPTIONS_CLASS_REFERENCE]
        ${project.customExceptionClasses?join("\n\n#######################\n\n")}
        [/EXCEPTIONS_CLASS_REFERENCE]
        </#if>
    
        [REPOSITORIES]
        <#if project.repositories?has_content>
        <#list project.repositories as repo, repoCode>
        ${repoCode}
        </#list>
        </#if>
        [/REPOSITORIES]
    
        [/CONTEXT]
    
      2. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete methods!!!
      3. Do not include staw-man code, skeleton code, or any placeholders.
      4. Do not leave any methods without a complete logic implementation.
      5. Encapsulate all code within a try-catch block.
      6. Do not include anything else except the code logic.
      7. Any variable should be created outside of the method (but don't include the class declaration, consider that you are already inside of a class).
      8. Return only the code, in one single block, nothing more
      9. Never create more than one single method to address the code logic you are asked for.
      10. Remove any comments inside the method! They are not allowed!
      11. Every method that is supposed to change a value from another scope needs to return a value or save it on the respective repository/file already been used by the service.
      12. Consider that already exist an @Slf4j log annotation on the class that the method will be included, so you can address any logging message using log instance
      13. Don't create methods just to handle File read, File Write of File Close operations, use ready Java solutions to address that stuff like reading file as a String, bytes, or even deserialization with Jackson if it makes sense.
      14. Don't translate the code literally, be clever and choose better approach taking advantage of well known and used libraries from Java/Spring boot world.
      15. Leave a comment at the beginning of the method specifying the original paragraph name and if it is
      16. You should NEVER leave a piece of logic without of being addressed by the equivalent Java Code you are creating, otherwise you will be penalized! But, if there's something that you consider impossible to be done without some additional context, you should write it as a comment inside the method right above of the original piece of code you will not translate also as a comment.
  fixClassVariables: |-
    @@@freemarker
    @@@prompt
    Com base na lista de nomes de variveis abaixo, retorne as declaraes necessrias com seus devidos valores iniciais;
    
    !!undeclaredVariables!!
    
    [CURRENT CLASS]
    !!currentClass!!
    [/CURRENT CLASS]
    
    [COBOL CONTEXT]
    ${$api.files.cobolPrograms.cobolPrograms?map(it -> it.raw_code)?join('\n')}
    [/COBOL CONTEXT]
  service: |-
    @@@openllmthread
    @@@groovy("CreateServices.groovy")
    @@@optimizeImports
    @@@closellmthread
    import com.capco.brsp.synthesisengine.service.IExecutor
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedList
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.FileUtils
    import com.capco.brsp.synthesisengine.utils.JavaUtils
    import com.github.javaparser.ParseProblemException
    import org.springframework.context.ApplicationContext
    
    class CreateServices implements IExecutor {
    
        SuperService superService = null
        ScriptService scriptService = null
        SuperUtils superUtils = SuperUtils.getInstance()
        List<String> originalContexts = new ConcurrentLinkedList<>()
    
        String handlePrompt(Map<String, Object> projectContext, String prompt) {
            println "CreateServicePrompt - Prompt size: ${prompt.length()}".toString()
            try {
                return scriptService.handlePrompt(projectContext, prompt)
            } catch (Exception ignored) {
                println "CreateServicePrompt - Failed - Probably due to a stuck thread - Trying to restart a new one".toString()
                scriptService.autoEval("@@@closellmthread")
                scriptService.autoEval("@@@openllmthread")
                println "CreateServicePrompt - New Thread - Contextualizing with scaffold data".toString()
                scriptService.handlePrompt(projectContext, "Consider the content below as part of your context to be aware of\n\n:" + originalContexts.join("\n\n"))
    
                StringBuilder NewMethodsContext = new StringBuilder("Consider also the methods that was previously created below:\n\n")
                def newMethods = projectContext.project?.NewMethods as Map<String, Map<String, Object>>
                newMethods?.eachWithIndex { Map.Entry<String, Map<String, Object>> programs, int programIndex ->
                    programs.eachWithIndex{ Map.Entry<String, String> programMethodEntry, int programMethodsIndex ->
                        def methodName = programMethodEntry.getKey()
                        def methodContent = programMethodEntry.getValue()
                        NewMethodsContext.append(methodContent).append("\n\n")
                    }
                }
    
                println "CreateServicePrompt - New Thread - Contextualizing with methods already created before".toString()
                scriptService.handlePrompt(projectContext, NewMethodsContext.toString())
    
                println "CreateServicePrompt - New Thread - Successfully contextualized! Now continuing from where it stopped!".toString()
                return scriptService.handlePrompt(projectContext, prompt)
            }
        }
    
        Object execute(ApplicationContext applicationContext, Map<String, Object> projectContext) {
    
            println "Creating class Services"
            this.superService = applicationContext.getBean(SuperService.class)
            this.scriptService = applicationContext.getBean(ScriptService.class)
    
    //        def program = "CUSTTRN2"
    //        def program = "CUSTVSAM"
    //        def className = normalizeClassName(program)
    //        def classCode = createClass(program, className, projectContext)
    
    
            def project = projectContext.project as Map<String, Object>
            project.programsNames.each { String program ->
                //            println program
                def totalParagraphs = project.paragraphsFlow.findAll{
                    it.program == program &&
                    it.exitParagraph != true &&
                    it.emptyParagraph != true
                }.size()
    
                project.put("currentMethodCount", 0)
                project.put("totalMethods", totalParagraphs)
    
                def className = normalizeClassName(program)
                def classCode = createClass(program, className, projectContext)
            }
    
            return ""
        }
    
        def createClass(String program, String className, Map<String, Object> projectContext){
    
            def classScaffold = createScaffoldClass(program, className, projectContext)
    
            createContext(program, classScaffold, projectContext)
    
            def project = projectContext.project as Map<String, Object>
            def mainParagraph = project.paragraphsFlow.find{it.program==program}
            //        def mainParagraph = project.paragraphsFlow.find{it.paragraph=="721-COPY-RECORDS"}
    
            createMethods(program, className, mainParagraph, projectContext)
    
            def classCode = replaceMethodsInScaffold(program, className, classScaffold, projectContext)
    
            Utils.anyCollectionSet(project, 'NewClasses.'+program, classCode)
            def filePath = FileUtils.absolutePathJoin(
                    projectContext.rootFolder,
                    project.projectNormalizedName,
                    "src/main/java/com/capco/",
                    project.projectNormalizedName,
                    "service", className + "Service.java")
            FileUtils.writeFile(filePath, classCode, false)
            Utils.anyCollectionSet(projectContext.project, "services[]", classCode)
    
    //        println project.NewClasses['CUSTVSAM']
            println "[FINAL_CLASS]"
            println classCode
            println "[/FINAL_CLASS]"
    
            return classCode
        }
    
        def createMethods(String program, String className, paragraph, Map<String, Object> projectContext){
    
            def mainMethodName = normalizeMethodName(paragraph.paragraph)
            def paragraphCode = paragraph.rawCode as String
            println "Creating main method: "+mainMethodName
    
            def linkageDtos = getLinkageDtoMainParagraph(program, projectContext)
            def linkageDtosStr = ""
            if (linkageDtos) {
                linkageDtosStr = """2. Consider the equivalency map of Linkage variables to Java DTO below:${linkageDtos}      
       a. Consider these DTOs are received as parameter by ${mainMethodName} method, even if they do not appear in the cobol code I provided.
       b. They MUST BE initialized by ${mainMethodName} in order to be used by other methods.
       c. I provided this DTOs as context before.
       d. Consider these DTOs are imported.     
       e. Use the keywork *this* when deal with them."""
            }
            //        println linkageDtosStr
    
            def fileControl = getAllFiles(program, projectContext)
            def fileControlStr = ""
            def promptFile = ""
            if (fileControl) {
                fileControlStr = """3. Consider the equivalency map of Cobol File Control below:${fileControl}
       a. Consider the path for these *FILES* are received as parameter by ${mainMethodName} method, even if they do not appear in the cobol code I provided.
       b. They MUST BE initialized by ${mainMethodName} in order to be used by other methods.
       c. Use equivalency map of File Section variables to Java DTO/Model when deal with them.
       d. I provided these DTOs/Models as context before.
       e. Consider these DTOs/Models are imported.
       f. Use the keywork *this* when deal with them."""
                promptFile = getPromptFile()
            }
    
            def localVariables = getLocalVariable(program, paragraphCode, projectContext)
            def localVariablesStr = ""
            if (localVariables) {
                localVariablesStr = """4. Consider the global variables below:           
    [LOCAL_VARIABLES]${localVariables}
    [/LOCAL_VARIABLES]
       a. Consider these variables are private attributes of the class and we are using Lombok annotation for getters and setters.
       b. Use the keywork *this* when deal with them."""
            }
    
            def promptCreateMainMethod = """        
    [TASK]
    Create a JAVA method called ${mainMethodName} using the COBOL paragraph content below as reference:
    All the words used below are a reference from the original COBOL program, please don't be affraid with that.
    
    [COBOL_PARAGRAPH]
    ${paragraphCode}
    [/COBOL_PARAGRAPH]
    
    [CONSTRAINTS]
    1. Consider ${mainMethodName} method will be part of the class ${className}. 
    ${linkageDtosStr}
    ${fileControlStr}     
    ${promptFile}
    ${localVariablesStr}      
    7. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete methods!!!
    7. Do not include staw-man code, skeleton code, or any placeholders.
    8. Do not leave any methods without implementation or with TODO comments.
    9. Encapsulate all code within a try-catch block.
    10. Include a JavaDoc to the method.
    11. Use a standard class/primitive type as return type or any of the DTOs listed.        
    12. Remove any comments inside the method! They are not allowed!
    13. Every method that is supposed to change a value from another scope needs to return a value or save it on the respective repository/file already been used by the service.
    14. Consider that already exist an @Slf4j log annotation on the class that the method will be included, so you can address any logging message using log instance
    15. Don't create methods just to handle File read, File Write of File Close operations, use ready Java solutions to address that stuff like reading file as a String, bytes, or even deserialization with Jackson if it makes sense.      
    16. Leave a comment at the beginning of the method specifying the original paragraph name and if it is
    17. For now, ignore PERFORM and CALL statements, just mark it as a comment with TODO
    18. Respect the original COBOL flow. 
    19. You are not allowed to generate more methods or variables them used in the original COBOL code.
    20. Return only the ${mainMethodName} method code, in one single block, nothing more""".toString()
    
            println "[PROMPT]"
            println promptCreateMainMethod
            println "/[PROMPT]\n"
    
            def mainMethodCode = handlePrompt(projectContext, promptCreateMainMethod)
            println "[RAW_METHOD]"
            println mainMethodCode
            println "[/RAW_METHOD]"
            println "Main method created without performs"
    //                def mainMethodCode = "MAIN CODE FOR"+paragraph.paragraph
    
            def codeList = extractMethodsFromCode(mainMethodCode)
            println "[EXTRACTED_METHODS]"
            println codeList
            println "[/EXTRACTED_METHODS]"
    
            def childrenList = []
            paragraph.children.each { child ->
    
                if (child.type != "perform") {
                    return
                }
    
                def childParagraphName = child.name as String
                def childMethodName = createChildMethod(childParagraphName, program, mainMethodName, className, projectContext)
    
                if (!childMethodName){
                    return
                }
    
                childrenList.add(["paragraphName": childParagraphName, "performRawCode": child.rawCode, "methodName": childMethodName])
    
            }
    
            mainMethodCode = codeList[mainMethodName]
            mainMethodCode = replaceAllPerformToMethod(mainMethodName, mainMethodCode, childrenList, projectContext)
            mainMethodCode = Utils.extractMarkdownCode(mainMethodCode) as String
            codeList[mainMethodName] = mainMethodCode
    
            println "[METHOD_FINAL]"
            println codeList[mainMethodName]
            println "[/METHOD_FINAL]"
            println "Main method completed"
    
            saveMethods(program, mainMethodName, codeList, projectContext)
    
        }
    
        def createChildMethod(String paragraphName, String program, String mainMethodName, String className, Map<String, Object> projectContext) {
            def methodName = normalizeMethodName(paragraphName)
            def project = projectContext.project as Map<String, Object>
            def currentCount = project.currentMethodCount + 1
            project.put("currentMethodCount", currentCount)
    
            println "*******************************************************************************"
            println "Creating method [${currentCount}/${project.totalMethods}] for paragraph ${paragraphName} from program ${program}"
            println "New method name: " + methodName
            println "*******************************************************************************"
    
            if (project.NewMethods){
                //            println "achei NewMethods"
                if (project.NewMethods[program]) {
                    //                println "achei program"
                    //                println "buscando "+methodName
                    def exists = project.NewMethods[program].find{key, value -> key == methodName}
                    if (exists) {
                        println "${methodName} Already exisits - returning it"
                        return methodName
                    }
                }
            }
    
            def paragraphFull = project.paragraphsFlow.find{it.paragraph==paragraphName && it.program==program}
            if (!paragraphFull) {
                println "Failed to find a paragraph named ${paragraphName} at the program ${program}".toString()
                return null
            }
    
            if ( paragraphFull.exitParagraph == true){
                println "Ignoring EXIT paragraph"
                return null
            } else if ( paragraphFull.emptyParagraph == true){
                println "Ignoring EMPTY paragraph"
                return null
            }
    
            def paragraphCode = paragraphFull.rawCode as String
    
            //        println paragraphName
            //        println program
            //        println paragraphFull
    
            def localVariables = getLocalVariable(program, paragraphCode, projectContext)
            def localVariablesStr = ""
            if (localVariables) {
                localVariablesStr = """2. Consider the variables below:             
    [LOCAL_VARIABLES]${localVariables}
    [/LOCAL_VARIABLES]
       a. Consider these variables are private attributes of the class and we are using Lombok annotation for getters and setters.
       b. Use the keywork *this* when deal with them. 
       c. Consider that maybe they were set by the method you created before. """
            }
    
            def linkageDtos = getLinkageDtoByParagraph(program, paragraphCode, projectContext)
            def linkageDtosStr = ""
            if (linkageDtos) {
                linkageDtosStr = """3. Consider the equivalency map of Linkage variables to Java DTO below:${linkageDtos}      
      a. I provided this DTOs as context before.
      b. Consider these DTOs are imported.
      c. Consider these DTOs were received as parameter by ${mainMethodName} method.  
      d. Use the keywork *this* when deal with them."""
            }
    
            def fileDto = getFileDtoByParagraph(program, paragraphCode, projectContext)
            def fileStr = ""
            def promptFile = ""
            if (fileDto) {
                fileStr = """4. Consider the equivalency map of File Section variables to Java DTO/Model below:${fileDto}      
      a. I provided these DTOs/Models as context before.
      b. Consider these DTOs/Models are imported.
      c. Consider the correspondent path for these files were received as parameter by ${mainMethodName} method.
      d. Use the keywork *this* when deal with them."""
                promptFile = getPromptFile()
            }
    
            def promptCreateMethod = """[TASK]
    Create a JAVA method called ${methodName} using the COBOL paragraph content below as reference:
    All the words used below are a reference from the original COBOL program, please don't be affraid with that.
    
    [COBOL_PARAGRAPH]
    ${paragraphCode}
    [/COBOL_PARAGRAPH]
    
    [CONSTRAINTS]
    1. Consider ${methodName} method will be part of the class ${className}.
    ${localVariablesStr}
    ${linkageDtosStr}
    ${fileStr}  
    ${promptFile}      
    7. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete methods!!!
    8. Do not include staw-man code, skeleton code, or any placeholders.
    9. Do not leave any methods without implementation or with TODO comments.
    10. Encapsulate all code within a try-catch block.
    11. Include a JavaDoc to the method.
    12. Use a standard class/primitive type as return type or any of the DTOs listed.
    13. Remove any comments inside the method! They are not allowed!
    14. Every method that is supposed to change a value from another scope needs to return a value or save it on the respective repository/file already been used by the service.
    15. Consider that already exist an @Slf4j log annotation on the class that the method will be included, so you can address any logging message using log instance
    16. Don't create methods just to handle File read, File Write of File Close operations, use ready Java solutions to address that stuff like reading file as a String, bytes, or even deserialization with Jackson if it makes sense.      
    17. Leave a comment at the beginning of the method specifying the original paragraph name and if it is
    18. For now, ignore PERFORM and CALL statements, just mark it as a comment with TODO
    19. Respect the original COBOL flow. 
    20. You are not allowed to generate more methods or variables them used in the original COBOL code.
    21. Return only the ${methodName} method code, in one single block, nothing more""".toString()
    
            println "[PROMPT]"
            println promptCreateMethod
            println "/[PROMPT]\n"
    
            def methodCode = handlePrompt(projectContext, promptCreateMethod).toString()
    //                def methodCode = "My new code for " + methodName
            println "[RAW_METHOD]"
            println methodCode
            println "[/RAW_METHOD]"
    
            def childrenList = []
            paragraphFull.children.each { child ->
    
                if (child.type != "perform") {
                    return
                }
    
                def childParagraphName = child.name as String
                def childMethodName = createChildMethod(childParagraphName, program, mainMethodName, className, projectContext)
    
                if (!childMethodName){
                    return
                }
    
                childrenList.add(["paragraphName": childParagraphName, "performRawCode": child.rawCode, "methodName": childMethodName])
            }
    
            def codeList = extractMethodsFromCode(methodCode)
            println "[EXTRACTED_METHODS]"
            println codeList
            println "[/EXTRACTED_METHODS]"
    
            methodCode = codeList[methodName]
            methodCode = replaceAllPerformToMethod(methodName, methodCode, childrenList, projectContext)
            methodCode = Utils.extractMarkdownCode(methodCode) as String
            codeList[methodName] = methodCode
    
            println "[METHOD_FINAL]"
            println codeList[methodName]
            println "[/METHOD_FINAL]"
    
            println methodName + " method completed"
    
            saveMethods(program, methodName, codeList, projectContext)
    
            return methodName
    
        }
    
        def replaceAllPerformToMethod(String parentMethodName, String parentMethodCode, childrenList, Map<String, Object> projectContext) {
            // Sometimes the llm generates methods with parameters in the signature
            // reason why Im still sending the performs replacement to LLM do
    
            childrenList.unique()
    
            if (childrenList.size() == 0) {
                return parentMethodCode
            }
    
            def replaceList = ""
            childrenList.each { child ->
    
                if (child.performRawCode.contains('THRU')){
                    replaceList += "Add call to ${child.methodName} method.\n"
                } else {
                    replaceList += "Replace PERFORM ${child.paragraphName} to call ${child.methodName} method.\n"
                }
            }
    
            def prompt = """
    [TASK]
    Update the method *${parentMethodName}* adding call to new methods or replacing the *PERFORMs* statements/comments according to the perform list bellow.
    
    [${parentMethodName}_CODE]
    ${parentMethodCode}
    [/${parentMethodName}_CODE]
    
    [PERFORM_LIST]
    ${replaceList}
    [/PERFORM_LIST]
    
    Detailed Instructions:
    1. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete method!!!
    2. Do not include staw-man code, skeleton code, or any placeholders.
    3. Consider all methods are part of the same class, so use the keywork *this* when deal with them.
    4. Return only the updated ${parentMethodName} code, in one single block, nothing more.""".toString()
    
            parentMethodCode = handlePrompt(projectContext, prompt)
    
            return parentMethodCode
        }
    
        def replacePerformToMethodOneByOne(String parentMethodName, String parentMethodCode, String childMethodName, String childParagraphName, String childMethodCode, Map<String, Object> projectContext) {
            // Doesnt work well when parent method has many performs
    
    
            if (!parentMethodCode.toLowerCase().contains("perform ${childParagraphName}")){
                println "PERFORM ${childParagraphName} already replaced in ${parentMethodName}"
                return parentMethodCode
            }
    
            def prompt = """
                [TASK]
                Update the method *${parentMethodName}* replacing the *PERFORM ${childParagraphName}* statement/comment for call the method ${childMethodName}.
                
                [${parentMethodName}_CODE]
                ${parentMethodCode}
                [/${parentMethodName}_CODE]
                
                [${childMethodName}_CODE]
                ${childMethodCode}
                [/${childMethodName}_CODE]
                
                Detailed Instructions:
                1. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete method!!!
                2. Do not include staw-man code, skeleton code, or any placeholders.
                3. Replace only the PERFORM ${childParagraphName}, keep other performs untouched
                4. Consider both methods are part of the same class, so use the keywork *this* when deal with them.
                5. Return only the updated ${parentMethodName} code, in one single block, nothing more.""".toString()
    
    
            parentMethodCode = handlePrompt(projectContext, prompt)
            //println "MAIN COM PERFORM"
            //        println parentMethodName
            //println "******************************"
    
            return parentMethodCode
        }
    
        def replaceMethodsInScaffold(String program, String className, String classCode, Map<String, Object> projectContext, deterministic=true){
    
            def project = projectContext.project as Map<String, Object>
            if (!project.NewMethods) {
                println "NewMethods not found"
                return
            }
    
            def methods = project.NewMethods[program]
            if (!methods) {
                println program + " not found in NewMethods"
                return
            }
    
            if (deterministic == true){
                println "Adding methods to ${className} class"
                classCode = replaceMethodsInScaffoldUsingReplace(program, methods, classCode, projectContext)
            } else {
                classCode = replaceMethodsInScaffoldUsingLLM(methods, className, classCode, projectContext)
            }
    
            return classCode
        }
    
        def replaceMethodsInScaffoldUsingReplace(String program, methods, String classCode, projectContext){
    
            def project = projectContext.project as Map<String, Object>
    
            project.paragraphsFlow.findAll{it.program == program}.each { paragraphs ->
    
                if ( paragraphs.exitParagraph == true ||  paragraphs.emptyParagraph == true){
                    return
                }
    
                def methodName = normalizeMethodName(paragraphs.paragraph as String)
    
                // main code from method
                def methodCode = methods[methodName]
    
                // auxiliar methods
                methods.each { name, code ->
                    if (name.contains("aux" + methodName)){
                        methodCode += "\n" + code
                    }
                }
    
                classCode = classCode.replace("//TODO method " + methodName, "\n" + methodCode + "\n")
            }
    
            return classCode
        }
    
        def replaceMethodsInScaffoldUsingLLM(methods, String className, String classCode, Map<String, Object> projectContext){
    
            methods.each { method, methodCode ->
    
                println "Adding ${method} to ${className}"
    
                //            println method
                //            println methodCode
                def prompt = """
                    [TASK]
                    Update the class ${className} replacing the commented *TODO method ${method}*.
                    
                    [${className}_CODE]
                    ${classCode}
                    [/${className}_CODE]
                    
                    [${method}_CODE]
                    ${methodCode}
                    [/${method}_CODE]
                    
                    Detailed Instructions:
                    1. NEVER generate incomplete code, like including TODOs or similar placeholders, ALWAYS return complete class
                    2. Do not include staw-man code, skeleton code, or any placeholders.
                    3. Replace only the method ${method}, keep others untouched
                    4. Return only the updated ${className} class code, in one single block, nothing more.""".toString()
    
                //            print prompt
    
                classCode = handlePrompt(projectContext, prompt)
                //            print classCode
            }
    
            return classCode
        }
    
        def createContext(String program, String classScaffold, Map<String, Object> projectContext){
    
            println "Creating context for program " + program
            def dtos = getAllDtoClasses(program, projectContext)
            def pojos = getAllPojoClasses(program, projectContext)
            def models = getAllModelClasses(program, projectContext)
    
            def promptDtos = ""
            if (dtos) {
                promptDtos = """
    Consider these DTOs bellow:${dtos}"""
            }
    
            def promptPojos = ""
            if (pojos){
                promptPojos = """
    Consider these Pojos bellow:${pojos}"""
            }
    
            def promptModels = ""
            if (models){
                promptModels = """
    Consider these Models and Repositories bellow:${models}"""
            }
    
            def prompt = """Consider my class scaffold: 
    ```java${classScaffold}
    ```
    ${promptDtos}
    ${promptPojos}
    ${promptModels}
    All these assests you will use as context for the next iterations.
    For now just answer yes meaning that you are aware.""".toString()
            //        println prompt
    
    //        println "[CONTEXT]"
    //        println prompt
    //        println "[/CONTEXT]"
    
            def answer = handlePrompt(projectContext, prompt)
            originalContexts.add(prompt)
            println "Context created: " + answer
        }
    
        def createScaffoldClass(program, className, Map<String, Object> projectContext){
    
            def groupId = projectContext.recipe.vars.groupId
            def project = projectContext.project as Map<String, Object>
            def projectNormalizedName = project.projectNormalizedName
    
    
            def paragraphsStr = ""
            project.paragraphsFlow.findAll{it.program == program}.each { paragraphs ->
    
                if ( paragraphs.exitParagraph == true ){
                    println "Ignoring EXIT paragraph when creating scaffold " + paragraphs.paragraph
                    return
                } else if ( paragraphs.emptyParagraph == true ) {
                    println "Ignoring EMPTY paragraph when creating scaffold " + paragraphs.paragraph
                    return
                }
    
                def methodName = normalizeMethodName(paragraphs.paragraph as String)
                paragraphsStr += "\n        //TODO method " + methodName
            }
    
            def dtos = project.dtos.findAll{
                it.program == program
            }
            def dtosImport = ""
            dtos.each { dto ->
                dtosImport += """
            import ${groupId}.${projectNormalizedName}.domain.dto.${dto.javaName};"""
            }
    
            def pojos = project.pojos.findAll{
                it.program == program
            }
            def pojosImport = ""
            pojos.each { pojo ->
                pojosImport += """
            import ${groupId}.${projectNormalizedName}.domain.file.${pojo.name};"""
            }
    
            def models = project.models.findAll{
                it.program == program
            }
            def modelsImport = ""
            models.each { model ->
                modelsImport += """
            import ${groupId}.${projectNormalizedName}.domain.db.${model.name};
            import ${groupId}.${projectNormalizedName}.repository.${model.name}Repository;"""
            }
    
            def scaffold = """
            package ${groupId}.${projectNormalizedName}.service;        
            import ${groupId}.${projectNormalizedName}.exception.*;
            import ${groupId}.${projectNormalizedName}.service.*;
            import ${groupId}.${projectNormalizedName}.utils.*;
            ${dtosImport}
            ${pojosImport}
            ${modelsImport}
            import lombok.Getter;
            import lombok.Setter;
    
            @Service
            @Getter
            @Setter    
            public class ${className} {
                ${paragraphsStr}
            }"""
    
    //        println "[SCAFOLDING]"
    //        println scaffold
    //        println "[/SCAFOLDING]"
    
            return scaffold
        }
    
        def getLocalVariable(String program, String paragraphCode, Map<String, Object> projectContext){
            // find Working Storage variables used in a paragraph
    
            def variables = []
    
            def project = projectContext.project as Map<String, Object>
            def cobolVariables = project.cobolVariables.findAll{
                it.program == program && it.label == "COBOLStorage"
            }
            cobolVariables.each { variable ->
    
                if (!paragraphCode.contains(variable.name as String)) {
                    return
                }
    
                if (variable.name=='FILLER') {
                    return
                }
    
                if (variable.parentName) {
                    def completa = project.cobolFullVariables.find{
                        it.program == program &&
                        "COBOLStorage" in it.labels &&
                        (it.name==variable.parentName || variable.parentName in it.children)
                    }
                    variables.add(completa.code)
                } else if (variable.childCount>0) {
                    def completa = project.cobolFullVariables.find{
                        it.program == program &&
                        "COBOLStorage" in it.labels &&
                        (it.name==variable.name || variable.name in it.children)
                    }
                    variables.add(completa.code)
                } else {
                    variables.add(variable.rawCode)
                }
    
            }
    
            variables.unique()
    
            def variableOutput = new StringBuilder()
            variables.each { variable ->
                variableOutput << "\n[VARIABLE]\n"
                variableOutput << variable << "\n"
                variableOutput << "[/VARIABLE]"
            }
    
            return variableOutput.toString()
        }
    
        def getLinkageDtoMainParagraph(String program, Map<String, Object> projectContext){
            // find Linkage Section variables to be used by the MainParagraph
    
            def complexVariables = []
    
            def project = projectContext.project as Map<String, Object>
            def cobolVariables = project.cobolFullVariables.findAll{
                it.program == program && "COBOLLinkage" in it.labels
            }
    
            cobolVariables.each { variable ->
    
                def dto = project.dtos.find{
                    it.name == variable.name && it.program == program
                }
    
                // so preciso do nome java das variaveis
                // a llm ja conhece os dtos pois mandei no contexto
                complexVariables.add(["javaName": dto.javaName, "code": variable.code])
            }
    
            complexVariables.unique()
    
            def variablesOutput = ""
            complexVariables.each{ variable ->
                variablesOutput += "\n[VARIABLE]\n"
                variablesOutput +=  variable.code
                variablesOutput += "\nEquivalent DTO: " + (variable.javaName as String)
                variablesOutput += "\n[/VARIABLE]"
            }
    
            return variablesOutput
        }
    
        def getLinkageDtoByParagraph(String program, String paragraphCode, Map<String, Object> projectContext){
            // find Linkage Section variables to be used by a certain Paragraph
    
            def complexVariables = []
    
            def project = projectContext.project as Map<String, Object>
            def cobolVariables = project.cobolVariables.findAll{
                it.program == program && it.label == "COBOLLinkage"
            }
    
            cobolVariables.each { variable ->
    
                if (!paragraphCode.contains(variable.name as String)) {
                    return
                }
    
                if (variable.name=='FILLER') {
                    return
                }
    
                def name = variable.name
                def code = variable.rawCode
                if (variable.parentName) {
                    def completa = project.cobolFullVariables.find{
                        it.program == program &&
                                "COBOLLinkage" in it.labels &&
                                (it.name==variable.parentName || variable.parentName in it.children)
                    }
                    name = completa.name
                    code = completa.code
                } else if (variable.childCount>0) {
                    def completa = project.cobolFullVariables.find{
                        it.program == program &&
                                "COBOLLinkage" in it.labels &&
                                (it.name==variable.name || variable.name in it.children)
                    }
                    name = completa.name
                    code = completa.code
                }
    
                def dto = project.dtos.find{
                    it.name == name && it.program == program
                }
    
                // so preciso do nome java das variaveis
                // a llm ja conhece os dtos pois mandei no contexto
                complexVariables.add(["javaName": dto.javaName, "code": code])
            }
    
            complexVariables.unique()
    
            def variablesOutput = ""
            complexVariables.each{ variable ->
                variablesOutput += "\n[VARIABLE]\n"
                variablesOutput +=  variable.code
                variablesOutput += "\nEquivalent DTO: " + (variable.javaName as String)
                variablesOutput += "\n[/VARIABLE]"
            }
    
            return variablesOutput
        }
    
        def getAllDtoClasses(String program, Map<String, Object> projectContext){
            // find All DTOs Classes used in the whole program
            // DTOs correspond to Linkage variables
            // Used in the context
    
            def project = projectContext.project as Map<String, Object>
            def output = ""
            def dtos = project.dtos.findAll{
                it.program == program
            }
            dtos.each { dto ->
                def dtoClass = project.dtosClasses[dto.name as String]
                output += "\n" + dtoClass
            }
    
            return output
        }
    
        def getAllPojoClasses(String program, Map<String, Object> projectContext){
            // find All Pojo Classes used in the whole program
            // Pojo correspond to File Section record and files for flat files
            // Used in the context
    
            def project = projectContext.project as Map<String, Object>
            def output = ""
            def dtos = project.pojos.findAll{
                it.program == program
            }
            dtos.each { dto ->
                def dtoClass = project.pojosClasses[dto.name as String]
                output += "\n" + dtoClass
            }
    
            return output
        }
    
        def getAllModelClasses(String program, Map<String, Object> projectContext){
            // find All Model Classes used in the whole program
            // models correspond to File Section record and files for vsam files
            // Used in the context
    
            def project = projectContext.project as Map<String, Object>
            def output = ""
            def dtos = project.models.findAll{
                it.program == program
            }
            dtos.each { dto ->
                def dtoClass = project.modelsClasses[dto.name as String]
                output += "\n```java\n" + dtoClass + "```"
                def repository = project.repositories[dto.name as String]
                output += "\n```java\n" + repository + "```"
            }
    
            return output
        }
    
    
        def getAllFiles(String program, Map<String, Object> projectContext){
            // Find all Files used in the whole program
            // Used in MainParagraph to be the parameters
            // OPEN, CLOSE, READ, DELETE statements use file-name
            // WRITE, REWRITE statements use record-name
    
            def project = projectContext.project as Map<String, Object>
            def files = project.fileComprehensiveDetails.findAll{
                it.program == program
            }
    
            def variablesOutput = ""
            files.each{ file ->
                variablesOutput += "\n[FILE]"
                variablesOutput += "\nFile definition name: " + file.fileControlName
                variablesOutput += "\nFile path: " + file.filePathJCL
                variablesOutput += "\nRecord name: " + file.recordStorageName
                variablesOutput += "\nRecord definition:\n" + file.fullRawCode
                if (file.eligibleVariable=='WS') {
                    variablesOutput += "\nEquivalent working storage record:\n" + file.rawCode
                }
                if (file.label == "COBOLVsamFile") {
                    variablesOutput += "\nRespective Model: " + file.domainJavaName
                } else {
                    variablesOutput += "\nRespective DTO:" + file.domainJavaName
                }
                variablesOutput += "\n[/FILE]"
            }
    
            return variablesOutput
        }
    
        def getFileDtoByParagraph(String program, String paragraphCode, Map<String, Object> projectContext){
            // Find all Files e File records used in a certain paragraph
            // OPEN, CLOSE, READ, DELETE statements always use file definition name
            // WRITE, REWRITE statements always use record-name
    
            def complexVariables = []
    
            // looking for file records
            def project = projectContext.project as Map<String, Object>
            def cobolVariables = project.cobolVariables.findAll{
                it.program == program && it.label == "COBOLFileRecordStorage"
            }
    
            cobolVariables.each { variable ->
    
                if (!paragraphCode.contains(variable.name as String)) {
                    return
                }
    
                def file = project.fileComprehensiveDetails.find {
                    it.program == program && it.fullRawCode.contains(variable.name)
                }
    
                if (!file){
                    println "Record ${variable.name} not found in fileComprehensiveDetails for program ${program}"
                    return
                }
    //            print "achei" + file.filePathJCL
    
                // LLM already knows the DTOs from the context
                complexVariables.add([
                        "domainJavaName": file.domainJavaName,
                        "fileControlName": file.fileControlName,
                        "filePathJCL": file.filePathJCL,
                        "recordStorageName": file.recordStorageName,
                        "fileRawCode": file.fullRawCode,
                        "wsRawCode": file.rawCode,
                        "label": file.label,
                        "eligibleVariable": file.eligibleVariable
                ])
            }
    
            // looking for files
            def files = project.fileComprehensiveDetails.findAll{
                it.program == program
            }
    
            files.each { file ->
    
                if (!paragraphCode.contains(file.fileControlName as String) && !paragraphCode.contains(file.recordStorageName as String)) {
                    return
                }
    
                complexVariables.add([
                        "domainJavaName": file.domainJavaName,
                        "fileControlName": file.fileControlName,
                        "filePathJCL": file.filePathJCL,
                        "recordStorageName": file.recordStorageName,
                        "fileRawCode": file.fullRawCode,
                        "wsRawCode": file.rawCode,
                        "label": file.label,
                        "eligibleVariable": file.eligibleVariable
                ])
    
            }
    
            complexVariables.unique()
    
            //        println complexVariables
    
            def variablesOutput = ""
            complexVariables.each{ variable ->
                variablesOutput += "\n[FILE]"
                variablesOutput += "\nFile definition name: " + variable.fileControlName
                variablesOutput += "\nFile path: " + (variable.filePathJCL as String)
                variablesOutput += "\nRecord name: " + variable.recordStorageName
                variablesOutput += "\nRecord definition:\n" + variable.fileRawCode
                if (variable.eligibleVariable=='WS') {
                    variablesOutput += "\nEquivalent working storage record:\n" + variable.wsRawCode
                }
                if (variable.label == "COBOLVsamFile") {
                    variablesOutput += "\nRespective Model : " + (variable.domainJavaName as String)
                } else {
                    variablesOutput += "\nRespective DTO: " + (variable.domainJavaName as String)
                }
                variablesOutput += "\n[/FILE]"
            }
            //        println variablesOutput
    
            return variablesOutput
        }
    
        String getPromptFile(){
    
            def promptFile = """Consider the class already include a FileUtils helper class on the classpath that include a sort of different methods to be used replacing tasks for Opening, Closing, Reading and Writing files.
    For any needs on that, please take advantage of the methods below:
    - To OPEN a file and keep it open: 
      public static BufferedReader openReader(String fileName, String pathVariable)
      public static BufferedWriter openWriter(String fileName, String pathVariable)
    - To CLOSE a file:
      public static void closeReader(BufferedReader reader)
      public static void closeWriter(BufferedWriter writer)
    - To READ the whole content of a File to a List
      public static <T> List<T> FileUtils.readResourceFile(Class<T> clazz, String fileName)
    - To READ a single line of content an parse it to a specific Model/DTO class:
      public static <T> void readLineByLine(Class<T> clazz, BufferedReader reader, Context context)
    - To WRITE the whole content of a List<T> of objects to a File:
      public static <T> void FileUtils.writeResourceFile(Class<T> clazz, String fileName)
    - To WRITE a single Model/DTO object to a line in the File:
      public static <T> void writeItem(Class<T> clazz, BufferedWriter writer, T item)
    
    T is a reference to a generic class in Java, in this case it is expecting a Model/DTO class that should hold a single line of content of a file.
    Any BufferReader or BufferWriter that you need to translate a paragraph into a Java Method that will not be closed at the end of it, should declare a variable
    outside of the method scope following the convention:
      readBuffer{PascalCaseNameOfFileName}
      writeBuffer{PascalCaseNameOFileName}
    
    Example:
      To a OPEN INPUT for the file named TRANSACTION-FILE -> readBufferTransactionFile
    
    Also, any paragraph that is reading/writing/closing the content without taking care of the opening of that should consider that already exist on the class scope some buffer declared following the example above. """
    
            return promptFile
        }
    
        String normalizeMethodName(String paragraphName){
            def initialNum = paragraphName.find(/^\d+/)
            def methodName = (paragraphName).replaceAll(/^\d+/, '').replaceAll(/\$/, '').split('-').collect { it.toLowerCase().capitalize() }.join('')
            methodName = methodName[0].toLowerCase() + methodName.substring(1) + (initialNum ? initialNum : "")
            return methodName
        }
    
        String normalizeClassName(String program) {
            def initialNum = program.find(/^\d+/)
            def name = (program).split('-').collect { it.toLowerCase().capitalize().replaceAll(/^\d+/, '') }.join('')
            name = name + (initialNum ? initialNum : "") + "Service"
            return name
        }
    
        def extractMethodFromCode(String methodName, String methodCode, Map<String, Object> projectContext){
    
            try {
                methodCode = JavaUtils.extractMethodFromCode(methodCode, methodName) as String
            } catch (ParseProblemException ex) {
                println "Error when tryng extract method from code (first try):\n${ex.getMessage()}"
                try {
                    methodCode = handlePrompt(projectContext, """
                        There's something wrong with the [JAVA CODE] syntax below. Based on the [EXCEPTION MESSAGE] and on your JAVA skills, please fix that, and return only ${methodName} method code for me!
    
                        [EXCEPTION MESSAGE]
                        ${ex.getMessage()}
    
                        [JAVA CODE]
                        ${methodCode}"""
                    )
    
                } catch (ParseProblemException ex2) {
                    println "Error when tryng extract method from code (second try):\n${ex2.getMessage()}"
                    methodCode = handlePrompt(projectContext, """
                        There's something wrong with the [JAVA CODE] syntax below. 
                        Based on the [EXCEPTION MESSAGE], [EXCEPTION STACKTRACE] and on your JAVA skills, please fix that, and return only ${methodName} method code for me!
                        [EXCEPTION MESSAGE]
                        ${ex2.getMessage()}
    
                        [EXCEPTION STACKTRACE]
                        ${Utils.getStackTraceAsString(ex2)}
    
                        [JAVA CODE]
                        ${methodCode}"""
                    )
                }
            }
    
            return methodCode
        }
    
    
        def extractMethodsFromCode(String methodCode){
    
            def codeList = JavaUtils.extractMethodsFromCode(methodCode, null) as Map<String, String>
            return codeList
    
        }
    
    
        def saveMethods(String program, String mainMethodName, Map<String, String> methods, Map<String, Object> projectContext){
    
            def project = projectContext.project as Map<String, Object>
            methods.each {methodName, methodCode ->
    
                def newName = methodName
                if (methodName != mainMethodName){
                    newName = "aux" + mainMethodName + methodName
                }
    
                Utils.anyCollectionSet(project, 'NewMethods.'+program+'.'+newName, methodCode)
            }
    
        }
    }
  serviceSummarized: |-
    @@@freemarker
    @@@evalEachBlock
    @@@extractMarkdownCode
    @@@optimizeImports
    @@@openllmthread
    @@@contextualize
    @@@repromptAllMethods2
    @@@closellmthread
    @@@optimizeImports@set:project.services[]
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.exception.*;
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.model.*;
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.repository.*;
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service.*;
    
    !!imports!!
    
    <#if recipe.vars.logFramework == 'Slf4j'>@Slf4j</#if>
    @Service
    public class ${fileNameWithoutExtension} {
        <#if recipe.vars.logFramework == 'Log4j'>private static final Logger log = LogManager.getLogger(${fileName?replace(".java", "")}.class);</#if>
    
        <#list project.paragraphs as para>
        <#if (project.serviceSummary?filter(f -> f.serviceName == fileNameWithoutExtension && f.paragraphs?seq_contains(para.paragraph)))?has_content >
            <#assign paragraph = para.paragraph>
            <#if !paragraph?contains("ABEND") && !paragraph?contains("EXIT") && blueprint[project.index].paragraphs?filter(p -> p.name = "${paragraph}")?has_content>
            <#noparse>
            @@@{
            @@@freemarker
            @@@freemarker
            @@@newPrompt
            @@@repromptAndReplacePoorMethods
            @@@extractMarkdownCode
            @@@withoutclass
            @@@mapPut("project.myMethods", </#noparse>"${paragraph}"<#noparse>)
            <#assign blueprintParagraph = blueprint[project.index].paragraphs?filter(p -> p.name = </#noparse>"${paragraph}"<#noparse>)?first>
            ${recipe.prompts.serviceMethod
                ?replace('!!paragraphName!!', blueprintParagraph.name)
                ?replace('!!endpoints!!', blueprintParagraph.calls?map(bp -> 'For CALL' + bp.paragraph + ' use the microservice ' + bp.microservice + ' endpoint ' + bp.endpoint)?join("\n"))
            }
            }@@@
            </#noparse>
            </#if>
        </#if>
        </#list>
    }
  sqlSummarization: |-
    @@@freemarker
    @@@prompt
    [COBOL_PARAGRAPHS]
    [COBOL_CONTEXT]
    <#list blueprint[project.index].paragraphs?filter(paragraph -> !paragraph.name?contains("ABEND") && !paragraph.name?contains("EXIT")) as bp>
    [PARAGRAPH: ${bp.name}]
    ${bp.code}
    [/PARAGRAPH: ${bp.name}]
    </#list>
    [/COBOL_CONTEXT]
    [/COBOL_PARAGRAPHS]

    You are a seasoned Java Spring Boot developer with a lot of experience migrating on using Spring Data and adjusting queries to fit well with the Spring repositories and the rest of behaviour. So, given the paragraphs above, analyze the content and generate a report that will be used as reference to generate some Java  Spring Boot Repositories methods.
    Given the paragraphs above, take note of every SQL query inside of it, and summarize the content on a JSON array where each item follows the template below:
    {
        "tableName": "",
        "originalQuery": "",
        "springQueryAnnotatedRepositoryMethod": ""
    }

    More details about the values of each field on the template above:
    tableName: the name of the main table being addressed by the current query
    originalQuery: a copy of the original query to be used as comment further
    springQueryAnnotatedRepositoryMethod: a piece of java spring boot java code containing only the @Query("") with the adjusted SQL query inside of that and the method it annotates to be used by the services that will originally use the original query through a JDBC piece of code. Don't forget to put the method on a new line after the @Query.
    Use MyEntity as a placeholder for the Entity class, so I can easily replace that further.

    Don't include anything more, neither clarifications or comments, just give me the translated piece of code I requested for.
  methodsSummarization: |-
    @@@freemarker
    @@@prompt
    @@@extractMarkdownCode
    @@@saveAsJsonList("project", "methodsSummary")
    [COBOL_PARAGRAPHS]
    [COBOL_CONTEXT]
    <#list blueprint[project.index].paragraphs?filter(paragraph -> !paragraph.name?contains("ABEND") && !paragraph.name?contains("EXIT")) as bp>
    [PARAGRAPH: ${bp.name}]
    ${bp.code}
    [/PARAGRAPH: ${bp.name}]
    </#list>
    [/COBOL_CONTEXT]
    [/COBOL_PARAGRAPHS]
    
    [DTOS]
    <#list project.dtoClasses as _cobolStorageName, _dtoCode>
      [DTO_CODE: ${_cobolStorageName}]
      ${_dtoCode}
      [/DTO_CODE: ${_cobolStorageName}]
    </#list>
    [/DTOS]
    
    Given the paragraphs above, retrieve the planned Java method signature for each of them, considering also the Dtos that was already created to take care of each COBOL variable.
    Format the plan in a JSON array, where each item should follow the template below:
    {
      "cobolParagraph": !!the original name of the paragraph in the Cobol code!!,
      "javaMethodSignature": !!just the equivalent Java method signature (including the return type, name and parameters)!!
    }
    
    IMPORTANT: return only the JSON array requested, nothing else!
  serviceSummarizationSimple: |-
    @@@freemarker    
    [
      {
          "serviceName": "MainService",
          "paragraphs": [
            <#assign bpNames = blueprint[project.index].paragraphs?filter(paragraph -> !paragraph.name?contains("ABEND") && !paragraph.name?contains("EXIT"))?map(it -> it.name)>
            "${bpNames?join('",\n"')}"
          ],
          "accessTo": [],
          "accessibleFrom": []
      }
    ]
  serviceSummarization: |-
    @@@freemarker
    @@@prompt
    [COBOL_PARAGRAPHS]
    [COBOL_CONTEXT]
    <#list blueprint[project.index].paragraphs?filter(paragraph -> !paragraph.name?contains("ABEND") && !paragraph.name?contains("EXIT")) as bp>
    [PARAGRAPH: ${bp.name}]
    ${bp.code}
    [/PARAGRAPH: ${bp.name}]
    </#list>
    [/COBOL_CONTEXT]
    [/COBOL_PARAGRAPHS]
    
    You are a business analyst and a very experienced agent on doing translation from COBOL Code to Java modern solution. So, given the paragraphs above, analyze the content and generate a report that will be used as reference to generate some Java Spring Boot Services classes.
    Format the result as a JSON array where each object follow the template below:
    {
        "serviceName": "",
        "paragraphs": [],
        "accessTo": [],
        "accessibleFrom": []
    }
    
    The content of each field needs to follow the rules below:
    serviceName: Specify a service name which best translate the main reason of the paragraphs included on it,
    paragraphs: List all the names of the paragraphs to be included on this service,
    accessTo: List all the names of services that the current service needs to connect with,
    accessibleFrom: List all the names of services may need to connect with the current service
    
    Ensure to group together paragraphs that relies on the same repositories or data if possible.
    Don't create more than 3 services. Balance the maintainability, readability and complexity of the paragraphs, when small and simple enough please create only one service.
    
    Order the services by accessibleFrom, prioritizing those which has more services depending on it.
    
    IMPORTANT: return only the JSON content created, don't include any other comments or explanations.
  service2: |-
    @@@freemarker
    @@@prompt@set:project.services[]
    [COBOL_PARAGRAPHS]
    [COBOL_CONTEXT]
    <#list blueprint[project.index].paragraphs?filter(paragraph -> !paragraph.name?contains("ABEND") && !paragraph.name?contains("EXIT")) as bp>
    [PARAGRAPH: ${bp.name}]
    ${bp.code}
    [/PARAGRAPH: ${bp.name}]
    </#list>
    [/COBOL_CONTEXT]
    [/COBOL_PARAGRAPHS]
    
    [EXCEPTION_CLASSES]
    <#if project.customExceptionClasses?has_content>
    ${project.customExceptionClasses?join("\n\n#######################\n\n")}
    </#if>
    [/EXCEPTION_CLASSES]
    
    [REPOSITORY]
    <#if project.repositories?has_content>
    <#list project.repositories as repo, repoCode>
    ${repoCode}
    </#list>
    </#if>
    [/REPOSITORY]
    
    [MODEL]
    <#if project.modelsClasses?has_content>
    <#list project.modelsClasses as modelName, modelCode>
    ${modelCode}
    </#list>
    </#if>
    [/MODEL]
    
    NEVER LEAVE ANY PIECE OF CODE WITHOUT BEING WELL TRASNLATED FOLLOWING MY RULES! DON'T RELY ON PLACEHOLDERS, TODOs, OR ANY KIND OF SKIPPING A GOOD CODE FROM BEING GENERATED!!!
    
    Based on the COBOL_PARAGRAPHS translate those logics on a JAVA Spring Boot 3 Service class taking advantage of the [EXCEPTION_CLASSES], [REPOSITORY] and [MODEL].
    
    If you translate a paragraph that process some file, consider the equivalent Java method to receive the content of the file as a Spring parameter.
    
    Use the best practices of a Spring Boot 3 solution for that service class. Ensure to use @Slf4j logging schema, and @Lombok annotations if needed.
    The class should be named MainService.
    
    Don't include anyother content, just the single class code I asked you for.
    Set local variables to any method that do some file reading based on the equivalent File Section and File Definition of the original COBOL code.
  serviceTest: |-
    @@@freemarker
    @@@prompt
    @@@optimizeImports
    
    <#list project.services as service>
    [SERVICE]
    ${service}
    [/SERVICE]
    </#list>
    
    Given the Java Spring Service class provided, generate a complete and functional Java Spring Boot Test Class using JUnit 5 (Jupiter) that performs comprehensive unit and integration tests. Ensure the test class:
    
    1. Covers a wide range of scenarios (valid inputs, invalid inputs, edge cases, error handling).
    2. Applies best practices for Spring Boot testing (@SpringBootTest, @MockBean, @Autowired, @Test, @BeforeEach, @BeforeAll).
    3. Uses meaningful and descriptive test method names (e.g., shouldReturnExpectedResult_whenValidInputIsGiven).
    4. Follows a clean, readable structure with clear separation between setup, execution, and verification steps.
    5. Contains no placeholders, TODOs, or incomplete sections; the code should be production-ready.
    6. Achieves 100% test coverage for the Service class.
    7. Uses in-memory or mocked data to ensure tests are isolated, repeatable, and fast.
    8. Returns only the content of the Java Spring Boot Test Class.
    
    Constraints:
    - Ensure tests are structured properly with clear and concise assertions.
    - Avoid redundant or unnecessary tests; focus on verifying correctness, performance, and robustness.
    - Use only native Java or Spring Boot Test dependencies.
    - Test all methods.
  serviceTest2: |-
    @@@freemarker
    @@@prompt
    @@@utils.optimizeImports
    
    [TEST SCENARIOS]
    <#list $api.files.testScenarios as testScenario>
    ${testScenario?values?join("\n")}
    </#list>
    [/TEST SCENARIOS]
    
    Services to be covered by the tests:
    [SERVICES CLASSES]
    <#list project.services as service>
    [SERVICE CLASS]
    ${service}
    [/SERVICE CLASS]
    
    [ORIGINAL COBOL]
    ${files_metadata.history[service?regexGroups('public class\s+(.*?)\s+')[0][1]])?regexGroups('\[COBOL_PARAGRAPHS\]([\s\S]+?)\[/COBOL_PARAGRAPHS\]')}
    [/ORIGINAL COBOL]
    </#list>
    [/SERVICES]
    
    Given the Java Spring Service class above do:
        1. Generate a Java Spring Test Class to assert the most of the content of the Service as possible.
        2. Return only the content of the class file, nothing more.
        3. Ensure to use the best Jupiter + Spring Boot Testing practices.
  taskletService: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker
    @@@newPrompt@set:project.taskletService
    <#list project.services as service>
    [SERVICE]
    ${service}
    [/SERVICE]
    </#list>
    
    Create the methods below:
    <#list project.jclProfile?keys as jclName>
      <#assign jcl = project.jclProfile[jclName]>
      <#list jcl?keys as stepName>
        <#if stepName != "type" && stepName != "cobolProgramNames">
          <#assign jclStep = jcl[stepName]>
          <#if jclStep.isProgramCall?? && jclStep.isProgramCall == true>
    Method name: ${stepName} - Parameter1: fileName (String) - Parameter2: contribution (StepContribution) - Parameter3: chunkContext (ChunkContext)
          </#if>
        </#if>
      </#list>
    </#list>
    
    Based on this Spring Boot Service create a TaskletService with the name TaskeletService as well.
    Please only take care of the TaskletService class and ensure to create the whole content without comments and without omitting any part of the needed code.
    Use @Slf4j whenever it needs to log something.
    
    1. Pure class, without any interface implementation.
    2. Generate just the methods you are asked for, nothing more.
    3. Follow the best practices of a tasklet method, like returning a RepeatStatus value.
    4. Connect the right method with the equivalent SERVICE method that expect to receive a fileContent as input.
    5. Every fileNames represent a file inside the resources folder, so implement the code needed to read the content whenever is needed.

  batchConfig: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker@set:project.batchConfig
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.config;
    
    import org.springframework.batch.core.Job;
    import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
    import org.springframework.batch.core.launch.JobLauncher;
    import org.springframework.batch.core.launch.support.TaskExecutorJobLauncher;
    import org.springframework.batch.core.repository.JobRepository;
    import org.springframework.batch.core.repository.support.JobRepositoryFactoryBean;
    import org.springframework.beans.factory.annotation.Qualifier;
    import org.springframework.context.annotation.Bean;
    import org.springframework.context.annotation.Configuration;
    import org.springframework.core.task.SimpleAsyncTaskExecutor;
    import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseBuilder;
    import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType;
    import org.springframework.jdbc.support.JdbcTransactionManager;
    
    import javax.sql.Datasource;
    
    @Configuration
    @EnableBatchProcessing
    public class BatchConfig {
        @Bean(name = "batchDataSource")
        public DataSource dataSource() {
            return new EmbeddedDatabaseBuilder().setType(EmbeddedDatabaseType.HSQL)
                        .addScript("/org/springframework/batch/core/schema-hsqldb.sql")
                        .generateUniqueName(true)
                        .build();
        }
    
        @Bean(name = "batchTransactionManager")
        public JdbcTransactionManager transactionManager(@Qualifier("batchDataSource") DataSource dataSource) {
            return new JdbcTransactionManager(dataSource);
        }
    
        @Bean
        public JobRepository jobRepository(@Qualifier("batchDataSource") DataSource dataSource, @Qualifier("batchTransactionManager") JdbcTransactionManager transactionManager) throws Exception {
            JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean();
            factory.setDataSource(dataSource);
            factory.setTransactionManager(transactionManager);
            factory.afterPropertiesSet();
    
            return factory.getObject();
        }
    
        @Bean(name = "asyncJobLauncher")
        public JobLauncher asyncJobLauncher(JobRepository jobRepository, Job job) throws Exception {
            TaskExecutorJobLauncher JobLauncher = new TaskExecutorJobLauncher();
            jobLauncher.setJobRepository(jobRepository);
            jobLauncher.setTaskExecutor(new SympleAsyncTaskExecutor());
            jobLauncher.afterPropertiesSet();
    
            return jobLauncher;
        }
    }
  batchStepsConfig: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker@set:project.batchStepsConfig
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.config;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service.TaskletService;    
    import org.springframework.batch.core.Job;
    import org.springframework.batch.core.Step;
    import org.springframework.batch.core.configuration.annotation.JobScope;
    import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
    import org.springframework.batch.core.job.builder.JobBuilder;
    import org.springframework.batch.core.repository.JobRepository;
    import org.springframework.batch.core.step.builder.StepBuilder;
    import org.springframework.batch.repeat.RepeatStatus;
    import org.springframework.beans.factory.annotation.Qualifier;
    import org.springframework.context.annotation.Bean;
    import org.springframework.context.annotation.Configuration;
    import org.springframework.jdbc.support.JdbcTransactionManager;
    
    <#if recipe.vars.logFramework == 'Slf4j'>import lombok.extern.slf4j.Slf4j;</#if>
    <#if recipe.vars.logFramework == 'Log4j'>import org.apache.logging.log4j.Logger;
    import org.apache.logging.log4j.LogManager;
    </#if>
    import lombok.RequiredArgsConstructor;
    
    
    @Configuration
    @EnableBatchProcessing
    @Slf4j
    @RequiredArgsConstructor
    public class BatchStepsConfig {
        <#list project.jclProfile as jclName, jcl>
            <#list jcl as stepName, jclStep>
                <#if stepName != "type" && stepName != "cobolProgramNames">
                    <#if jclStep.isProgramCall?? && jclStep.isProgramCall == true>
                        <#assign jclTargetProgram = jclStep.target>
                    </#if>
                </#if>
            </#list>
        </#list>
        <#assign parts = jclTargetProgram?split("-")>
        <#assign transformedParts = []>
        <#list parts as part>
            <#assign transformedParts = transformedParts + [ part?lower_case?cap_first?replace("^\\d+", "", "r") ]>
        </#list>
        <#assign className = transformedParts?join("") + "Service">
        <#assign classInstanceName = className?substring(0,1)?lower_case + className?substring(1)>
    
        private final ${className} ${classInstanceName};
    
        <#list project.jclProfile?keys as jobName>
            <#assign job = project.jclProfile[jobName]>
            <#if job.type == "JOB">
                <#-- Get all step keys excluding type and cobolProgramNames -->
                <#assign stepKeys = []>
                <#list job?keys as key>
                    <#if key != "type" && key != "cobolProgramNames">
                        <#assign stepKeys = stepKeys + [key]>
                    </#if>
                </#list>
                <#-- Create job bean with first step using start() -->
                <#if stepKeys?size gt 0>
                    <#assign firstStep = stepKeys[0]>
        @Bean
        public Job job${jobName}(JobRepository jobRepository<#list stepKeys as stepName>, Step ${jobName}_${stepName}</#list>){
            return new JobBuilder("job${jobName}", jobRepository)
                        .start(${jobName}_${firstStep})
                    <#-- Add next steps if they exist -->
                    <#if stepKeys?size gt 1>
                        <#list stepKeys as key>
                            <#if key_index gt 0>
                          .next(${jobName}_${key})
                            </#if>
                        </#list>
                    </#if>
                        .build();
        }
                    <#-- Create step beans for each step -->
                    <#list stepKeys as stepName>
                        <#assign step = job[stepName]>
    
        @Bean
        @JobScope
        Step ${jobName}_${stepName}(JobRepository jobRepository, @Qualifier("batchTransactionManager") JdbcTransactionManager jdbcTransactionManager) {
            return new StepBuilder("${jobName}_${stepName}", jobRepository)
                        .tasklet((contribution, chunkContext) -> {
                            log.info("Executing ${jobName}_${stepName}");
                        <#-- Handle input and output files -->
                        <#if step.inputFiles??>
                            <#assign inputParams = []>
                            <#list step.inputFiles as inputFileName, inputFileItem>
                                <#assign inputParams = inputParams + ['"' + inputFileItem + '"']>
                            </#list>
                        </#if>
                        <#if step.isProgramCall == true>
                            <#if step.outputFiles??>
                                <#assign outputParams = []>
                                <#list step.outputFiles as outputFileName, outputFileItem>
                                    <#assign outputParams = outputParams + ['"' + outputFileItem + '"']>
                                </#list>
                            </#if>
                            <#if (inputParams?? && inputParams?size > 0)  || (outputParams?? && outputParams?size > 0)>
                                <#assign mainParagraph = project.paragraphsFlow?filter(it -> it.program == jclTargetProgram)?first>
                                <#assign trimmed = mainParagraph.paragraph?replace("^\\d+", "", "r")>
                                <#assign parts = trimmed?split("-")>
                                <#assign transformedParts = []>
                                <#list parts as part>
                                    <#assign transformedParts = transformedParts + [ part?lower_case?cap_first ]>
                                </#list>
                                <#assign methodName = transformedParts?join("")>
                                <#assign methodName = methodName?substring(0, 1)?lower_case + methodName?substring(1)>
                            ${classInstanceName}.${methodName}(<#if inputParams??>${inputParams?join(", ")},</#if> <#if outputParams??>${outputParams?join(", ")},</#if> contribution, chunkContext);
                            </#if>
                        </#if>
    
                            return RepeatStatus.FINISHED;
                        }, jdbcTransactionManager)
                        .build();
        }
                    </#list>
                </#if>
            </#if>
        </#list>
    }
  batchStepsConfig2: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker@set:project.batchStepsConfig
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.config;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service.TaskletService;    
    import org.springframework.batch.core.Job;
    import org.springframework.batch.core.Step;
    import org.springframework.batch.core.configuration.annotation.JobScope;
    import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
    import org.springframework.batch.core.job.builder.JobBuilder;
    import org.springframework.batch.core.repository.JobRepository;
    import org.springframework.batch.core.step.builder.StepBuilder;
    import org.springframework.batch.repeat.RepeatStatus;
    import org.springframework.beans.factory.annotation.Qualifier;
    import org.springframework.context.annotation.Bean;
    import org.springframework.context.annotation.Configuration;
    import org.springframework.jdbc.support.JdbcTransactionManager;
    
    <#if recipe.vars.logFramework == 'Slf4j'>import lombok.extern.slf4j.Slf4j;</#if>
    <#if recipe.vars.logFramework == 'Log4j'>import org.apache.logging.log4j.Logger;
    import org.apache.logging.log4j.LogManager;
    </#if>
    import lombok.RequiredArgsConstructor;
    
    
    @Configuration
    @EnableBatchProcessing
    @Slf4j
    @RequiredArgsConstructor
    public class BatchStepsConfig {
        <#list project.jclProfile as jclName, jcl>
            <#list jcl as stepName, jclStep>
                <#if stepName != "type" && stepName != "cobolProgramNames">
                    <#if jclStep.isProgramCall?? && jclStep.isProgramCall == true>
                        <#assign jclTargetProgram = jclStep.target>
                    </#if>
                </#if>
            </#list>
        </#list>
        <#assign parts = jclTargetProgram?split("-")>
        <#assign transformedParts = []>
        <#list parts as part>
            <#assign transformedParts = transformedParts + [ part?lower_case?cap_first?replace("^\\d+", "", "r") ]>
        </#list>
        <#assign className = transformedParts?join("") + "Service">
        <#assign classInstanceName = className?substring(0,1)?lower_case + className?substring(1)>
    
        private final ${className} ${classInstanceName};
    
        <#list project.jclProfile?keys as jobName>
            <#assign job = project.jclProfile[jobName]>
            <#if job.type == "JOB">
                <#-- Get all step keys excluding type and cobolProgramNames -->
                <#assign stepKeys = []>
                <#list job?keys as key>
                    <#if key != "type" && key != "cobolProgramNames">
                        <#assign stepKeys = stepKeys + [key]>
                    </#if>
                </#list>
                <#-- Create job bean with first step using start() -->
                <#if stepKeys?size gt 0>
                    <#assign firstStep = stepKeys[0]>
        @Bean
        public Job job${jobName}(JobRepository jobRepository<#list stepKeys as stepName>, Step ${jobName}_${stepName}</#list>){
            return new JobBuilder("job${jobName}", jobRepository)
                        .start(${jobName}_${firstStep})
                    <#-- Add next steps if they exist -->
                    <#if stepKeys?size gt 1>
                        <#list stepKeys as key>
                            <#if key_index gt 0>
                          .next(${jobName}_${key})
                            </#if>
                        </#list>
                    </#if>
                        .build();
        }
                    <#-- Create step beans for each step -->
                    <#list stepKeys as stepName>
                        <#assign step = job[stepName]>
    
        @Bean
        @JobScope
        Step ${jobName}_${stepName}(JobRepository jobRepository, @Qualifier("batchTransactionManager") JdbcTransactionManager jdbcTransactionManager) {
            return new StepBuilder("${jobName}_${stepName}", jobRepository)
                        .tasklet((contribution, chunkContext) -> {
                            log.info("Executing ${jobName}_${stepName}");
                        <#-- Handle input and output files -->
                        <#if step.inputFiles??>
                            <#assign inputParams = []>
                            <#list step.inputFiles as inputFileName, inputFileItem>
                                <#assign inputParams = inputParams + ['"' + inputFileItem + '"']>
                            </#list>
                        </#if>
                        <#if step.isProgramCall == true>
                            <#if step.outputFiles??>
                                <#assign outputParams = []>
                                <#list step.outputFiles as outputFileName, outputFileItem>
                                    <#assign outputParams = outputParams + ['"' + outputFileItem + '"']>
                                </#list>
                            </#if>
                            <#if (inputParams?? && inputParams?size > 0)  || (outputParams?? && outputParams?size > 0)>
                                <#assign mainParagraph = project.paragraphsFlow?filter(it -> it.program == jclTargetProgram)?first>
                                <#assign trimmed = mainParagraph.paragraph?replace("^\\d+", "", "r")>
                                <#assign parts = trimmed?split("-")>
                                <#assign transformedParts = []>
                                <#list parts as part>
                                    <#assign transformedParts = transformedParts + [ part?lower_case?cap_first ]>
                                </#list>
                                <#assign methodName = transformedParts?join("")>
                                <#assign methodName = methodName?substring(0, 1)?lower_case + methodName?substring(1)>
                            ${classInstanceName}.${methodName}(<#if inputParams??>${inputParams?join(", ")},</#if> <#if outputParams??>${outputParams?join(", ")},</#if> contribution, chunkContext);
                            </#if>
                        </#if>
    
                            return RepeatStatus.FINISHED;
                        }, jdbcTransactionManager)
                        .build();
        }
                    </#list>
                </#if>
            </#if>
        </#list>
    }
  batchController: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker
    @@@prompt@set:project.controller@set:endpoints[]
    Consider the Spring Batch Job Configuration as reference for the values/jobs/parameters available to deal with.
    [BATCH_CONFIG]
    ${project.batchConfig}
    [/BATCH_CONFIG]
    
    and batchStepsConfig also
    
    [BATCH_STEPS_CONFIG]
    ${project.batchStepsConfig}
    [/BATCH_STEPS_CONFIG]
    
    [CLASS_TEMPLATE]
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.controller;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service.*;    
    !!imports!!
    
    @RestController
    public class ${fileName?replace(".java", "")} {
        !!classContent!!
    }
    [/CLASS_TEMPLATE]
    
    [ENDPOINT_TEMPLATE]
    @Retry(name = "myService", fallbackMethod = "fallback")
    @CircuitBreaker(name = "myService", fallbackMethod = "fallback")
    @GetMapping("/data")
    public ResponseEntity<String> getData() {
        String response = restTemplate.getForObject("http://external-service/api/data", String.class);
        return ResponseEntity.ok(response);
    }
    
    public ResponseEntity<String> fallback(Exception e) {
        return ResponseEntity.status(HttpStatus.SERVICE_UNAVAILABLE).body("Service unavailable - fallback");
    }
    [/ENDPOINT_TEMPLATE]
    
    Consider the JCL/CTC contents below as a reference to figure out which parameters are needed to execute the job. Make sure to consider only the step that triggers the Cobol Program,
    all other steps that uses utilities like IEFBR14, SORT, DYL280 can be totally disconsidered.
    
    Create a JAVA Spring Controller class to expose an endpoint /api/v1/startJob that will trigger the execution of a Spring Batch Job, receiving the same parameters that are used on the step that calls the Cobol Program
    0. ClassName: batchController
    1. Package package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.controller;
    2. Expose an endpoint that will start the JOB with the parameters needed (you can have a look inside the JCL/PRC/CTC files to list the dependencies)
    3. Retrieve only the content for the BatchController.java class, don't include anything else on your answer.
    4. Use @@Slf4j whenever it needs to log something.
    5. Use the [CLASS_TEMPLATE] and [ENDPOINT_TEMPLATE] to format the content.
  exception: |-
    @@@freemarker
    @@@prompt
    @@@extractMarkdownCode
    @@@splitInnerClasses@set:project.globalExceptionHandler
    @@@prompt
    
    [JCL_CONTEXT]
    <#list project.jclProfile?keys as jclName>
      <#assign jcl = project.jclProfile[jclName]>
      <#list jcl?keys as stepName>
        <#if stepName != "type" && stepName != "cobolProgramNames">
          <#assign jclStep = jcl[stepName]>
          <#if jclStep.isExceptionHandling?? && jclStep.isExceptionHandling == true>
            <#list $api.files.cobolPrograms.jclJobs + $api.files.cobolPrograms.jclProcs as jclItem>
              <#assign jclItems = $api.files.cobolPrograms.jclJobs + $api.files.cobolPrograms.jclProcs>
              <#assign res = jclItems?filter(jclItem -> jclItem.name == stepName)?first.raw_code?matches(r"(//(STEP\d+A)\s+[\s\S]+?)//STEP\d+\s+")>
              <#list res as m>
                <#if m?groups[2] == stepName>
    ######################## JCL: ${jclName} - STEP: ${stepName}
    
    ${m?groups[1]}
    
    
                </#if>
              </#list>
            </#list>
          </#if>
        </#if>
      </#list>
    </#list>
    [/JCL_CONTEXT]
    
    [COBOL_CONTEXT]
    <#list blueprint[project.index].paragraphs as bp>
    [PARAGRAPH: ${bp.name}]
    ${bp.code}
    [/PARAGRAPH: ${bp.name}]
    </#list>
    [/COBOL_CONTEXT]
    
    Generate a Java Class that will include the Global Exception Handler from Spring Boot and as inner classes one class for each ABEND (Abnoumous End) or Error Handling needs.
    The JCL_CONTEXT is your reference to figure out which exception classes needs to be generated for the BatchConfig usage, prefix the name of those exceptions with job, like "jobFileException".
    The COBOL_CONTEXT is your reference to figure out which exception classes needs to be generated for any further Business Service class, prefix them with "business", like "businessUpdatingException".
    0. ClassName: GlobalExceptionsHandler
    1. Package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.exception;
    2. Use @Slf4j whenever it needs to log something.
    3. This is not for a MVC application, it will be used by some Tasklets of a Spring Batch job, so don't rely on ResponseEntity returns.
  model: |-
    @@@freemarker
    @@@newPrompt@set:project.model
    @@@extractMarkdownCode
    @@@_parseAndApply("JAVA", "$..[?(@.name == 'classBodyDeclaration' && @..children[?(@.name == 'modifier' && @.text == '@Id')].length() > 0)]..[?(@.name == 'typeType')].text", "$[0]", "${@Utils.anyCollectionSet(#projectContext, 'project.modelIdType.' + #fileNameWithoutExtension, #result)}")
    @@@mapPut("project.modelsClasses", "${#project['models'].?[#this['file'] == #fileName].![#this['name']][0]}")
    [CONTEXT]
    ${project.models?filter(it -> it.file == fileName)?map(it -> it.code)?first}
    [/CONTEXT]
    
    Generate a Java Class following Spring Boot Data best practices for creating an @Entity file.
    0. ClassName: ${fileNameWithoutExtension}.java
    1. Package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.model;
    2. Retrieve ONLY the content of the Model.java class, nothing more!
    3. Use Lombok annotations to let the class be concise without being incomplete!
    4. If none of the primary key is defined on the DB2 structured, include an additional column called ID with a @GeneratedValue annotation, otherwise just map the field to the same primary key column.
    5. Use import jakarta.persistence.* instead of javax.persistence.*
  modelFile: |-
    @@@freemarker
    @@@newPrompt@set:project.model
    @@@extractMarkdownCode
    @@@_parseAndApply("JAVA", "$..[?(@.name == 'classBodyDeclaration' && @..children[?(@.name == 'modifier' && @.text == '@Id')].length() > 0)]..[?(@.name == 'typeType')].text", "$[0]", "${@Utils.anyCollectionSet(#projectContext, 'project.modelIdType.' + #fileNameWithoutExtension, #result)}")
    @@@mapPut("project.modelsClasses", "${#project['models'].?[#this['file'] == #fileName].![#this['name']][0]}")
    <#assign currentModel = project.models?filter(it -> it.file == fileName)?first>
    
    [CONTEXT]
    ${currentModel.code}
    [/CONTEXT]
    
    Generate a Java Class following Spring Boot Data best practices for creating an @Entity file.
    0. ClassName: ${fileNameWithoutExtension}.java
    1. Package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.db;
    2. Retrieve ONLY the content of the Model.java class, nothing more!
    3. Use Lombok annotations to let the class be concise without being incomplete!
    <#if currentModel.pks?? && (currentModel.pks?size>1)>
    4. Include @Id annotation for represent the primary key in the model for the follow attributes: <#list currentModel.pks as item>${item.name}<#if item?has_next>, </#if></#list>.
    <#else>
    4. Include an additional column called ID with a @GeneratedValue annotation, otherwise just map the field to the same primary key column.
    5. Do not add any annotation in the model class about the composited keys, only the annotation in the attribute that represent the primary key.
    </#if>
    6. Use import jakarta.persistence.* instead of javax.persistence.*
  modelFileDeterministic: |-
    @@@freemarker@set:project.model
    @@@saveFirstFieldAnnotatedWith("Id", "project.repository.IdType")
    @@@evalAndWriteFile("${'recipe.prompts.repository,' + #fileFolder.replace('/domain/db', '/repository').replace('\domain\db', '\repository') + '/' + #fileNameWithoutExtension + 'Repository.java'}")
    @@@mapPut("project.modelsClasses", "${#project['models'].?[#this['file'] == #fileName].![#this['name']][0]}")
    <#assign currentModel = project.models?filter(it -> it.file == fileName)?first>

    <#assign currentModel = project.models?filter(it -> it.file == fileName)?first>
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.db;

    import jakarta.persistence.Entity;
    import jakarta.persistence.Id;
    import jakarta.persistence.Column;
    import lombok.AllArgsConstructor;
    import lombok.Data;
    import lombok.NoArgsConstructor;

    @Entity
    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    public class ${fileNameWithoutExtension} {
        <#list currentModel.fields as field>
        <#if currentModel.pks?map(it -> it.name)?seq_contains(field.name)>

        @Id</#if>
        @Column(nullable = false<#if field.type == "String">, length = ${field.scale}<#elseif field.type == "BigDecimal">, precision = ${field.precision}, scale = ${field.scale}</#if>)
        private <#if field.type == "Integer" && (field.precision > 4)>Long<#else>${field.type}</#if> ${field.name?lower_case?split("-")?map(it2 -> it2?cap_first)?join("")?uncap_first};
        </#list>
    }
  repository: |-
    @@@freemarker
    @@@_mapPut("project.repositories", "${#fileNameWithoutExtension.replace('Repository', '')}")
    <#assign modelFileNameWithoutExtension = fileNameWithoutExtension?replace('Repository', '')>
    <#assign idType = project.modelIdType[modelFileNameWithoutExtension]>
    <#assign model = project.models?filter(it -> it.file == fileName?replace('Repository', ''))?first>
    <#assign isCompositeKey = (model.pks?size>1)>
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.repository;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.domain.db.${modelFileNameWithoutExtension};
    import java.sql.Date;
    <#if isCompositeKey>
    import java.io.Serializable;
    import org.springframework.data.jpa.repository.SimpleJpaRepository;

    public interface ${fileNameWithoutExtension} extends SimpleJpaRepository<${modelFileNameWithoutExtension}, Serializable> {
        <#assign capPks = model.pks?map(it -> {"type": it.type, "name": it.name?lower_case?split("-")?map(it2 -> it2?cap_first)?join("")})>
        Optional<${modelFileNameWithoutExtension}> findBy${capPks?map(it2 -> it2.name)?join("And")}(${capPks?map(it2 -> it2.type + " " + it2.name?uncap_first)?join(", ")});
    <#else>
    import org.springframework.data.jpa.repository.JpaRepository;
    
    public interface ${fileNameWithoutExtension} extends JpaRepository<${modelFileNameWithoutExtension}, ${idType}> {
    </#if>
        <#if project.sqlSummary?has_content>
        <#if project.sqlSummary?filter(it -> it.tableName == modelFileNameWithoutExtension)?has_content>
        <#list project.sqlSummary?filter(it -> it.tableName == modelFileNameWithoutExtension) as repoMethod>
        ${repoMethod.springQueryAnnotatedRepositoryMethod?replace('MyEntity', modelFileNameWithoutExtension)}
        </#list>
        </#if>
        </#if>
    }
  shellCommands: |-
    @@@skip("${!#project['isBatch']}")
    @@@freemarker
    @@@newPrompt
    Based on the [BATCH_CONFIG] below, which exposes a Spring Job to be used, create a full implementation of a Spring Shell Command to start the Job Execution. Don't forget to take care of any parameters as well.
    
    [BATCH_CONFIG]
    ${project.batchConfig}
    [/BATCH_CONFIG]
    
    [BATCH_STEPS_CONFIG]
    ${project.batchStepsConfig}
    [/BATCH_STEPS_CONFIG]
    
    [CONSTRAINTS]
    0. Package of the file: ${recipe.vars.groupId + '.' + project.projectNormalizedName}.shell;
    1. Generate just one class with the name ShellCommands.java
    2. Include the whole of that class, don't rely on placeholders and NEVER omit any piece of code.
    3. Ensure to use the @Slf4j as part of the solution.
  dataSourceConfig: |-
    @@@freemarker
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.config;
    
    import com.zaxxer.hikari.HikariDataSource;
    import jakarta.persistence.EntityManagerFactory;
    import org.springframework.context.annotation.Bean;
    import org.springframework.context.annotation.Configuration;
    import org.springframework.context.annotation.Primary;
    import org.springframework.orm.jpa.JpaTransactionManager;
    import org.springframework.transaction.annotation.EnableTransactionManagement;
    
    import javax.sql.DataSource;
    
    @configuration
    public class DataSourceConfig {
        @Primary
        @Bean(name = "dataSource")
        public DataSource h2DataSource() {
            HikariDataSource dataSource = new HikariDataSource();
            dataSource.setDriverClassName("org.h2.Driver");
            datasource.setJdbcUrl("jdbc:h2:mem:test");
            dataSource.setUsername("sa");
            dataSource.setPassword("password");
            return dataSource;
        }
    
        @Primary
        @Bean(name = "transactionManager")
        public JpaTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {
            return new JpaTransactionManager(entityManagerFactory);
        }
    }
  jclSummarization: |-
    @@@freemarker
    <#-- Parse the JCL into a structured format -->
    {
        <#list $api.files.cobolPrograms.jclJobs + $api.files.cobolPrograms.jclProcs as jclItem>
        <#assign jclCode = jclItem.raw_code>
        <#-- First get the job name from the JOB card -->
        <#assign jclJobs = jclCode?matches("//[A-Za-z0-9]+\\s+JOB[\\s\\S]*?(?=//[A-Za-z0-9]+\\s+JOB|$)")>
        <#assign jclProcs = jclCode?matches("//[A-Za-z0-9]+\\s+PROC[\\s\\S]*?(?=//[A-Za-z0-9]+\\s+PROC|$)")>
        <#if jclJobs?has_content>
            <#assign jclContents = jclJobs>
            <#assign jclType = "JOB">
        <#elseif jclProcs?has_content>
            <#assign jclContents = jclProcs>
            <#assign jclType = "PROC">
        </#if>
        <#list jclContents as jcl>
            <#-- Extract job name by getting first line and first word after // -->
            <#assign jclName = jcl?split("\n")[0]?trim?remove_beginning("//")?split(" ")[0]>
        "${jclName}": {
            "type": "${jclType}",
            <#-- Find all Cobol Programs in the JCL -->
            "cobolProgramNames": [
                <#assign programs = [] />
                <#if jclItem.cobolPrograms?? && jclItem.cobolPrograms?size gt 0>
                    <#list jclItem.cobolPrograms as program>
                        <#if program.name??>
                            <#assign programs = programs + [program.name]/>
                        </#if>
                    </#list>
                </#if>
                <#if programs?size gt 0>
                    <#list programs as programName>
                "${programName}"<#if programName?has_next>,</#if></#list>
                </#if>
            ],
            <#-- Find all EXEC statements and their associated DD statements -->
            <#assign steps = jcl?matches("//[A-Za-z0-9]+\\s+EXEC\\s+(PGM=)*[\\s\\S]*?(?=//[A-Za-z0-9]+\\s+EXEC|/\\*$|$)")>
            <#list steps as step>
            <#-- Get the step name from first line -->
            <#assign stepLine = step?split("\n")[0]?trim>
            <#assign stepName = stepLine?remove_beginning("//")?split(" ")[0]>
            <#-- Extract target program name -->
            <#assign execPart = stepLine?keep_after("EXEC")?trim>
            <#if execPart?contains("PGM=")>
                <#assign target = execPart?keep_after("PGM=")?trim?split(",")[0]?split(" ")[0]>
            <#else>
                <#assign target = execPart?split(",")[0]?split(" ")[0]>
            </#if>
            "${stepName}": {
                "target": "${target}",
                "isProgramCall": ${(programs?seq_contains(target))?string("true", "false")},
                "isExceptionHandling": false,
                "inputFiles": {
                    <#-- Find input DD statements (DISP=SHR) -->
                    <#assign inputDDs = step?matches("//[A-Za-z0-9]+\\s+DD\\s+DSN=[^,\\n]+[^\\n]*DISP=SHR[^\\n]*")>
                    <#list inputDDs as dd>
                        <#if !dd?contains("STEPLIB")>
                            <#-- Extract DD name and DSN -->
                            <#assign ddLine = dd?split("\n")[0]?trim>
                            <#assign ddName = ddLine?remove_beginning("//")?split(" ")[0]>
                            <#assign dsn = ddLine?substring(ddLine?index_of("DSN=") + 4)?split(",")[0]>
                        "${ddName}": "${dsn}"<#if dd?has_next>,</#if>
                        </#if>
                    </#list>
                },
                "outputFiles": {
                    <#-- Find output DD statements (DISP=(NEW...) -->
                    <#assign outputDDs = step?matches("//[A-Za-z0-9]+\\s+DD\\s+DSN=[^,\\n]+(?:[^\\n]*\\n//\\s+[^\\n]*)*DISP=\\(NEW[^\\n]*")>
                    <#list outputDDs as ddOutput>
                        <#-- Extract DD name and DSN -->
                        <#assign ddLine = ddOutput?split("\n")[0]?trim>
                        <#assign ddName = ddLine?remove_beginning("//")?split(" ")[0]>
                        <#assign dsn = ddLine?substring(ddLine?index_of("DSN=") + 4)?split(",")[0]>
                    "${ddName}": "${dsn}"<#if ddOutput?has_next>,</#if>
                    </#list>
                }
            }<#if step?has_next>,</#if>
            </#list>
        }<#if jcl?has_next>,</#if>
        </#list>
        </#list>
    }
  classDiagram: |-
    @@@default("Failed to generate a classDiagram!")
    @@@freemarker
    @@@prompt
    @@@extractMarkdownCode
    @@@plantuml("${#rootFolder + '/' + #project['projectNormalizedName'] + '/' + #filePath.replace('.uml', '.png')}")
    
    [JAVA_CLASSES]
    [JAVA_CLASS]
    ${project.javaFiles?join("\n\n[JAVA_CLASS]\n")}
    [/JAVA_CLASSES]
    
    Giving the Java classes I shared with you, and considering this is a Spring Boot Application, do:
    
    0. Consider that some of the dependencies between classes can be injected during the runtime, in that case using Spring Beans.
    1. Generate a class diagram for the whole content, and wire the classes to show the dependencies between them.
    2. Ensure to distribute the nodes on a way that the connections and labels are clearly visible and well suited.
    3. Explore more vertically the size instead of expanding too much horizontally the diagram.
    4. Make sure that PlantUML syntax is right an the script could be used to generate an image without any problems.
    
    Output format:
    - Return only the PlantUML diagram/script, don't include nothing more than this on your answer.
  # Remove the assumption to be using chat mode, for that we need to do it incrementally with freemarker and batch size of classes to be called each time, and someway to recall the dependencies left to be connected on the last part.
  flowDiagram: |-
    @@@default("Failed to generate a flowDiagram!")
    @@@freemarker
    @@@prompt
    @@@extractMarkdownCode
    @@@plantuml("${#rootFolder + '/' + #project['projectNormalizedName'] + '/' + #filePath.replace('.uml', '.png')}")
    
    [JAVA_CLASSES]
    [JAVA_CLASS]
    ${project.javaFiles?join("\n\n[JAVA_CLASS]\n")}
    [/JAVA_CLASSES]
    
    Giving the Java classes I shared with you, and considering this is a Spring Boot Application, do:
    
    0. Consider that some of the dependencies between classes can be injected during the runtime, in that case using Spring Beans.
    1. Understand the way each class interact to each other on the project.
    2. Generate a flow that first comprehends the configuration of the tool during the startup that stop on  a "user interaction" from that you expand other paths based on the existent ways to start the job/controller/shell commands or whatever entrypoints for the business logic that exists on the application.
    3. Format that flow using PlantUML syntax, don't include parameters of methods on the details, neither rely on class definitions, just need to connect the classes between each other using a concise but meaningful description for the label of each connection for the purpose or reason why they are being wired up.
    4. Ensure to retrieve the whole script without placeholders or anything left to be generated.
    5. Ensure to distribute the nodes on a way that the connections and labels are clearly visible and well suited.
    
    Output format:
    - Return only the PlantUML diagram/script, don't include nothing more than this on your answer.
  fakeDiagram: |-
    @@@prompt
    @@@utils.extractMarkdownCode
    @@@plantuml("${#rootFolder + '/' + #project['projectNormalizedName'] + '/' + #filePath}")
    Generate a PlantUML content to the Human common lifecyle.
    Return only the PlantUML script, don't include anything more.
  dataMeshService: |-
    @@@freemarker
    @@@prompt@set:project.datameshService
    You are a Java Spring Boot specialist and your main experience is about handling multiple Data Sources seamlessly with the convetional Spring Data structures that may exist.
    Please improve the [TEMPLATE] class below to be able to handle other Updates and Save methods that may exist over the [REPOSITORIES] classes I'll also include to you.
    The purpose of the class I'm asking for is to expose methods that can handle updates/saves methods switching between Kafka or Spring Data Repository based on the "mesh.target" configured value, so the services and other classes can easily consume it without knowing about different DataSources.
    Please do not include any additional comments or explanations, just return the whole class content you created following my instructions and nothing more.
    IMPORTANT: if you can't find any usable method on the REPOSITORIES that I gave to you, you are free to return the initial TEMPLATE class as your final content.
    
    [REPOSITORIES]
    <#if project.repositories?has_content>
    ${project.repositories?join("\n\n##############")}
    </#if>
    [/REPOSITORIES]
    
    [TEMPLATE]    
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.service;
    
    import ${recipe.vars.groupId + '.' + project.projectNormalizedName}.kafka.KafkaProducer;
    import com.fasterxml.jackson.core.JsonProcessingException;
    import com.fasterxml.jackson.databind.ObjectMapper;
    import lombok.RequiredArgsConstructor;
    import org.springframework.beans.factory.annotation.Value;
    import org.springframework.data.jpa.repository.JpaRepository;
    import org.springframework.stereotype.Service;
    
    @Service
    @RequiredArgsConstructor
    public class DataMeshService {
        @Value(<#noparse>"${mesh.target}"</#noparse>)
        private String target;
    
        @Value(<#noparse>"${mesh.topic}"</#noparse>)
    
        private final KafkaProducer kafkaProducer;
    
        public <E, I> E save(JpaRepository<E, I> repository, E entity) throw JsonProcessingException {
            if (target.equalsIgnoreCase("database")) {
                return saveToDatabase(repository, entity);
            } else if (target.equalsIgnoreCase("kafka")) {
                sendToTopic(entity);
                return null;
            } else {
                throw new IllegalStateException("Unsupported target: " + target);
            }
        }
    
        public <E, I> E saveToDatabase(JpaRepository<E, I> repository, E entity) {
            return repository.save(entity);
        }
    
        public void sendToTopic(Object obj) throws JsonProcessingException {
            String serializedData = new ObjectMapper().writeValueAsString(obj);
            kafkaProducer.send(topic, serializedData);
        }
    }
  kafkaProducer: |-
    @@@freemarker
    package ${recipe.vars.groupId + '.' + project.projectNormalizedName}.kafka;
    
    import lombok.RequiredArgsConstructor;
    <#if recipe.vars.logFramework == 'Slf4j'>import lombok.extern.slf4j.Slf4j;</#if>
    <#if recipe.vars.logFramework == 'Log4j'>import org.apache.logging.log4j.Logger;
    import org.apache.logging.log4j.LogManager;
    </#if>
    import org.springframework.kafka.core.KafkaTemplate;
    import org.springframework.stereotype.Component;
    
    <#if recipe.vars.logFramework == 'Slf4j'>@Slf4j</#if>
    @Component
    @RequiredArgsConstructor
    public class KafkaProducer {
        <#if recipe.vars.logFramework == 'Log4j'>private static final Logger log = LogManager.getLogger(KafkaProducer.class);</#if>
        private final KafkaTemplate<String, String> kafkaTemplate;
    
        public void send(String topic, String message) {
            log.info("Kafka: sending message='{}' to topic='{}'", message, topic);
            kafkaTemplate.send(topic, message);
        }
    }
transforms:
  accumulateImportsAndJava: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedList
    import org.springframework.context.ApplicationContext
    
    import java.nio.file.Path
    
    class AccumulateImportsAndJava implements ITransform {
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def project = projectContext.project as Map<String, Object>
            def strFullFilePath = projectContext.fullFilePath?.toString()
            def fileName = project.fileName as String
    
            Set<String> importLines = []
            if (content != null && !content.isEmpty()) {
                content.eachLine { line ->
                    def trimmedLine = line.trim()
                    if (trimmedLine.startsWith("import")) {
                        importLines << line
                    }
                }
                List<String> uniqueImportLines = new ConcurrentLinkedList<>(importLines)
                def listOfImports = (project.get('imports') ?: []) as List<String>
                listOfImports.addAll(uniqueImportLines)
                project.put('imports', listOfImports)
            }
    
            if (!content.startsWith("// Skipped/Empty File")) {
                if (strFullFilePath.contains('java') && !strFullFilePath.contains('diagrams')) {
                    if (project.javaFiles == null) {
                        project.javaFiles = new ConcurrentLinkedList<>()
                    }
                    def javaFileContent = "############# File Name: ${fileName}\n${content ?: ''}\n\n".toString()
                    project.javaFiles.add(javaFileContent)
                    println "Accumulating java files: ${strFullFilePath}"
                } else {
                    println "Isn't a java file: ${strFullFilePath}"
                }
            }
    
            return content
        }
    }
  #checkAndFixEachMethodTransform: CheckAndFixEachMethodTransform.groovy
  contextualize: |-
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedList
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import org.springframework.context.ApplicationContext
    
    class ContextualizeTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def superService = applicationContext.getBean(SuperService.class)
            def scriptService = applicationContext.getBean(ScriptService.class)
    
            def recipePrompts = projectContext.recipe.prompts
            def serviceContextualizePrompt = scriptService.autoEval(recipePrompts.serviceContextualize, new ConcurrentLinkedList<>())
    
            def attempts = 0
            def exception = null
            while (attempts++ < 3) {
                try {                    
                    System.out.println("Contextualizing...".toString())
                    scriptService.handlePrompt(projectContext, "THE CONTENT BELOW IS THE CURRENT STATE OF THE METHODS WE NEED TO ADJUST\n\n" + content + "\n\n JUST AKNOWLEDGE YOU RECEIVED AND UNDERSTOOD")
                    scriptService.handlePrompt(projectContext, "THE CONTENT BELOW REFER TO THE COBOL ORIGINAL CODE WE ARE TRANSLATING OR OTHER PIECES OF JAVA CLASSES YOU NEED TO USE TO COMPLETE THE ADJUSTMENTS\n\n" + serviceContextualizePrompt + "\n\n JUST AKNOWLEDGE YOU RECEIVED AND UNDERSTOOD")
                    System.out.println("Contextualized!".toString())
                    exception = null
                    break
                } catch (Exception ex) {
                    exception = ex
                    System.out.println("Exception during the attempt ${attempts} of 3. Waiting 1 minute before retrying!".toString())
                    Thread.sleep(60000)
                }
            }
    
            if (exception != null) {
                throw exception
            }
    
            return content
        }
    }
  analyzeAndFix: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import org.springframework.context.ApplicationContext
    
    class AnalyzeAndFixTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def superService = applicationContext.getBean(SuperService.class)
            def scriptService = applicationContext.getBean(ScriptService.class)
            var prompt = "Being a Java Spring Boot specialist, and a seasoned COBOL to JAVA translator, analyze the methods below and if the original code looks good enough just answer with an OK message(just these 2 characters), otherwise complete the implementation if there are some placeholders or piece of code taht are still pending to be done, keep the signature of the methods and return the whole new code to replace that same template of the original and most recent constraints you are aware about.\n${content}".toString()
            def tokens = (prompt =~/w+[\\p{P}\\p{S}]/).size()
            System.out.println("AnalyzeAndFix - Prompt size: ${content.length()} - approx. tokens: ${tokens} - piece: ${content.take(500).replace('\n', '\\n')}${content.length() > 500 ? '...' : ''}")
    
            def attempts = 0
            def newContent = "FAILED DUE TO LLM PROBLEMS!"
            def exception = null
            while (attempts++ < 3) {
                try {
                    newContent = scriptService.handlePrompt(projectContext, prompt)
                    if (newContent.startsWith("OK")) {
                        return content
                    }
                    exception = null
                    break
                } catch (Exception ex) {
                    exception = ex
                    System.out.println("Exception during the attempt ${attempts} of 3. Waiting 1 minute before retrying!".toString())
                    Thread.sleep(60000)
                }
            }
    
            if (exception != null) {
                throw exception
            }
    
            return newContent
        }
    }
  newPrompt: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.utils.Utils
    import org.springframework.context.ApplicationContext

    class NewPromptTransform implements ITransform {

        private static final String CONSTANT_USE_LLM_THREAD = "UseLLMThread";
        private static final String CONSTANT_LLM_THREAD_KEY = "LLMThreadKey";

        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def superService = applicationContext.getBean(SuperService.class)
            def scriptService = applicationContext.getBean(ScriptService.class)
            def tokens = (content =~ /w+[\\p{P}\\p{S}]/).size()
            System.out.println("NewPrompt - Prompt size: ${content.length()} - approx. tokens: ${tokens} - piece: ${content.take(500).replace('\n', '\\n')}${content.length() > 500 ? '...' : ''}")
            def attempts = 0
            def newContent = "FAILED DUE TO LLM PROBLEMS!"
            def exception = null
            def retryProcessed = 0
            def CURRENT_THREAD_CONTEXT = Utils.castOrDefault(projectContext.get("CURRENT_THREAD_CONTEXT"), StringBuilder.class, new StringBuilder());

            while (attempts++ < 3) {
                try {
                    newContent = superService.BCF(projectContext, content)
                    if (Utils.castOrDefault(projectContext.get(CONSTANT_USE_LLM_THREAD), Boolean.class, Boolean.FALSE)) {
                        CURRENT_THREAD_CONTEXT.append(newContent)
                        CURRENT_THREAD_CONTEXT.append("\n")
                        projectContext.put("CURRENT_THREAD_CONTEXT", CURRENT_THREAD_CONTEXT)
                    }
                    exception = null
                    break
                } catch (Exception exceptionValidation) {
                    try {
                        String cause = exceptionValidation.getCause()?.toString()?.toUpperCase()
                        if (cause.contains("TIMEOUT") && retryProcessed <= 3) {
                            if (projectContext.containsKey(CONSTANT_LLM_THREAD_KEY)) {
                                projectContext.remove(CONSTANT_LLM_THREAD_KEY)
                            }

                            final String contextThreadLLM = "@@@openllmthread\n@@@prompt\n" + CURRENT_THREAD_CONTEXT.toString()
                            scriptService.autoEvalStringTransforms(contextThreadLLM)
                            content = CURRENT_THREAD_CONTEXT.toString()
                            retryProcessed++
                            attempts = 0
                        }
                    } catch (Exception ex) {
                        exception = ex
                        System.out.println("Exception during the attempt ${attempts} of 3. Waiting 1 minute before retrying!".toString())
                        Thread.sleep(60000)
                    }
                }
            }


            if (exception != null) {
                throw exception
            }
            return newContent
        }
    }
  newPromptService: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import org.springframework.context.ApplicationContext
    
    class NewPromptServiceTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def superService = applicationContext.getBean(SuperService.class)
            def scriptService = applicationContext.getBean(ScriptService.class)
            def tokens = (prompt =~/w+[\\p{P}\\p{S}]/).size()
            System.out.println("NewPromptService - Prompt size: ${content.length()} - approx. tokens: ${tokens} - piece: ${content.take(500).replace('\n', '\\n')}${content.length() > 500 ? '...' : ''}")
    
            def attempts = 0
            def newContent = "FAILED DUE TO LLM PROBLEMS!"
            def exception = null
            while (attempts++ < 3) {
                try {
                    newContent = scriptService.autoEval(projectContext.serviceMethodsContext, [])
                    System.out.println("serviceMethodsContext answer:\n${newContent}".toString())
                    exception = null
                    break
                } catch (Exception ex) {
                    exception = ex
                    System.out.println("Exception during the attempt ${attempts} of 3. Waiting 1 minute before retrying!".toString())
                    Thread.sleep(60000)
                }
            }
    
            if (exception != null) {
                throw exception
            }
    
            return content
        }
    }
  evalAndWriteFile: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.utils.Utils
    import org.springframework.context.ApplicationContext
    import com.jayway.jsonpath.JsonPath
    import com.jayway.jsonpath.PathNotFoundException
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedHashMap
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedList
    import com.capco.brsp.synthesisengine.utils.FileUtils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    
    class EvalAndWriteFileTransform implements ITransform {
        Object anyCollectionGet(Object target, String path) {
            try {
                return JsonPath.read(target, path)
            } catch (PathNotFoundException pnfe) {
                return null
            }
        }
    
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def scriptService = applicationContext.getBean(ScriptService.class)
            def params = Utils.splitParams(transformParams)
            def templateReference = scriptService.autoEval(params.removeFirst() as String)
            def evaluatedPath = scriptService.autoEval(params.removeFirst() as String)
    
            def relativeFilePath = FileUtils.pathJoin(projectContext.project.name, evaluatedPath).toString().trim()
            def fullFilePath = FileUtils.absolutePathJoin(projectContext.rootFolder, relativeFilePath)
    
            def filesMetaData = projectContext.files_metadata
            if (filesMetaData == null) {
                filesMetaData = new ConcurrentLinkedHashMap<>()
                projectContext.files_metadata = filesMetaData
            }
    
            def tempFile = filesMetaData.get(relativeFilePath)
            if (tempFile == null) {
                tempFile = new ConcurrentLinkedHashMap<>()
                filesMetaData.put(relativeFilePath, tempFile)
            }
    
            def tempHistory = tempFile.history
            if (tempHistory == null) {
                tempHistory = new ConcurrentLinkedList<String>()
                tempFile.history = tempHistory
            }
    
            String templateContent = anyCollectionGet(projectContext, templateReference) as String
            String evaluatedContent = scriptService.autoEval(templateContent, tempHistory)
    
            SuperUtils.WGB(fullFilePath, evaluatedContent, false)
    
            return content
        }
    }
  regexReplace: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import org.springframework.context.ApplicationContext
    
    class RegexReplaceTransform implements ITransform {
        def replaceUsingRegex(originalContent, placeholder, sourceContentForRegex, regexPattern, regexReplacer) {
            def pattern = ~regexPattern
            def matcher = (sourceContentForRegex =~ pattern)
            if (matcher.find()) {
                def result = originalContent.replace(placeholder, matcher.groupCount() > 0 ? matcher.replaceAll(regexReplacer) : placeholder)
                return result
            }
            return originalContent
        }
    
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            System.out.println("Trying to regexReplace")
            def matcher = content =~ /"([^"\\]*(\\.[^"\\]*)*)"/
            if (matcher) {
                def placeholder = matcher[0][1]
                def contentSource = matcher[1][1]
                def regexPattern = matcher[2][1]
                def regexReplacer = matcher[3][1]
                return replaceUsingRegex(content, placeholder, contentSource, regexPattern, regexReplacer)
            }
            System.out.println("Failed to match params on the RegexReplaceTransform")
    
            return content
        }
    }
  saveFirstFieldAnnotatedWith: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import org.springframework.context.ApplicationContext
    import com.github.javaparser.JavaParser
    import com.github.javaparser.ast.CompilationUnit
    import com.github.javaparser.ast.body.FieldDeclaration
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    
    class SaveFirstFieldAnnotatedWithTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            try {
                def annotation = transformParams.split(",")[0].trim()
                def path = transformParams.split(",")[1].trim()
    
                System.out.println("Annotation: ${annotation} - Path: ${path}".toString())
    
                String fieldType = "Object"
                try {
                    JavaParser javaParser = new JavaParser()
                    CompilationUnit cu = javaParser.parse(content).getResult().get()
                    FieldDeclaration fieldDeclaration = cu.findAll(FieldDeclaration.class).stream()
                        .filter(field -> field.getAnnotations().stream().anyMatch(ann -> ann.getNameAsString().equalsIgnoreCase(annotation)))
                        .findFirst().orElse(null)
                    fieldType = fieldDeclaration.getVariable(0).getType()
                } finally {
                    Utils.anyCollectionSet(projectContext, path, fieldType)
                }
    
                return fieldType
            } catch (Exception ex) {
                System.out.println("SaveFirstFieldAnnotatedWithTransform - Path: ${annotation} - FieldType: ${fieldType}".toString())
                ex.printStackTrace()
            } finally {
                return content
            }
        }
    }
  renameFileAsClass: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import org.springframework.context.ApplicationContext
    import com.github.javaparser.JavaParser
    import com.github.javaparser.ast.CompilationUnit
    import com.github.javaparser.ast.body.ClassOrInterfaceDeclaration
    import com.github.javaparser.ast.body.FieldDeclaration
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.FileUtils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    import java.io.File
    
    class RenameFileAsClassTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            try {
                def filePath = transformParams.trim()
                def file = new File(filePath)
                def fileName = file.name
                def extension = fileName.tokenize('.').last()
    
                System.out.println("File Path: ${filePath} - File Name: ${fileName} - Extension: ${extension}".toString())
    
                try {
                    JavaParser javaParser = new JavaParser()
                    CompilationUnit cu = javaParser.parse(content).getResult().get()
                    ClassOrInterfaceDeclaration classDeclaration = cu.findAll(ClassOrInterfaceDeclaration.class).stream().findFirst().orElse(null)
                    String oldFileName = "${fileName}.${extension}"
                    String newFileName = "${classDeclaration.getName().getIdentifier()}.${extension}"
                    String newFilePath = filePath.replace(oldFileName, newFileName)
    
                    var oldRelativeFilePath = FileUtils.pathJoin(project.projectNormalizedName, filePath)
                    var oldFullFilePath = FileUtils.absolutePathJoin(context.rootFolder, oldRelativeFilePath)
    
                    var newRelativeFilePath = FileUtils.pathJoin(project.projectNormalizedName, newFilePath)
                    var newFullFilePath = FileUtils.absolutePathJoin(context.rootFolder, newRelativeFilePath)
                    FileUtils.writeFile(newFullFilePath, content, false)
                } catch (Exception ignored) {
                    System.out.println("Failed to rename File as Class: " + ignored.getMessage())
                }
            } finally {
                return content
            }
        }
    }
  optimizeImports: |-
    import org.springframework.context.ApplicationContext
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    
    class OptimizeImportsTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            try {
                return Utils.optimizeImports(content)
            } catch (Exception ex) {
                ex.printStackTrace()
                return content
            }
        }
    }
  splitInnerClasses: |-
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.utils.FileUtils
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    import com.github.javaparser.JavaParser
    import com.github.javaparser.ast.body.ClassOrInterfaceDeclaration
    import org.springframework.context.ApplicationContext
    
    import java.nio.file.Path
    
    class SplitInnerClasses implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            JavaParser javaParser = new JavaParser()
    
            def mainPackage = "package exception;"
            def innerClasses = [:]
            def classDefinition = new StringBuilder()
            try {
                var compilationUnit = javaParser.parse(content).getResult().get()
                if (compilationUnit.getPackageDeclaration().isPresent()) {
                    mainPackage = compilationUnit.getPackageDeclaration().get().toString()
                }
    
                classDefinition.append(mainPackage).append("\n")
                classDefinition.append(mainPackage.replace(";", ".*;").replace("package", "import")).append("\n")
                classDefinition.append(compilationUnit.getImports().join("")).append("\n")
                classDefinition.append(compilationUnit.getAllComments().join("")).append("\n")
    
                compilationUnit.findFirst(ClassOrInterfaceDeclaration.class).ifPresent(classOrInterface -> {
    
                    if (classOrInterface.getComment().isPresent()) {
                        classDefinition.append(classOrInterface.getComment().get().toString()).append("\n")
                    }
                    classDefinition.append(classOrInterface.getAnnotations().join("\n")).append("\n")
                    classDefinition.append(classOrInterface.getModifiers().join(" ")).append(" ")
                    classDefinition.append(classOrInterface.getNameAsString()).append(" ")
                    classDefinition.append(classOrInterface.getTypeParameters().join(", ")).append(" ")
                    var extendsValues = classOrInterface.getExtendedTypes()
                    if (!extendsValues.isEmpty()) {
                        classDefinition.append(" extends ").append(extendsValues.join(", ")).append(" ")
                    }

                    var implementsValues = classOrInterface.getImplementedTypes()
                    if (!implementsValues.isEmpty()) {
                        classDefinition.append(" implements ").append(implementsValues.join(", ")).append(" ")
                    }
    
                    classDefinition.append("{\n")
    
                    classOrInterface.getMembers().forEach(member -> {
                        if (member instanceof ClassOrInterfaceDeclaration) {
                            ClassOrInterfaceDeclaration classMember = member as ClassOrInterfaceDeclaration
                            innerClasses.put(classMember.getNameAsString(), mainPackage + "\n\n" + classMember.toString())
                        } else {
                            classDefinition.append(indent(member.toString(), 4))
                        }
                    })

                    classDefinition.append("\n}")
                })
            } catch (Exception ex) {
                System.out.println("Failed to SplitInnerClasses: " + ex.getMessage())
                return content
            }
    
            final Path filePath = FileUtils.absolutePathJoin(projectContext.rootFolder, projectContext.project.projectNormalizedName, projectContext.filePath)
            def folderPath = filePath.getParent()
            innerClasses.each { it ->
                {
                    def className = it.key as String
                    def classContent = it.value as String
                    var newFilePath = FileUtils.absolutePathJoin(folderPath, className + ".java")
                    FileUtils.writeFile(newFilePath, classContent, false)
                    Utils.anyCollectionSet(projectContext, 'project.customExceptionClasses[]', classContent)
                }
            }
    
            return """
            Considering the [CUSTOM_EXCEPTION_CLASSES] below, refactor the [ORIGINAL_GLOBAL_EXCEPTION_HANDLER] class for a Spring Boot 3 Application.
            Pay attention that the exceptions are divided in JOB (for Spring Batch Step beans usage) and BUSINESS exceptions (for Service beans usage).
            Return only the content of the new class you are going to create, nothing more, neither a single comment or explanation sentence.
    
            [CUSTOM_EXCEPTION_CLASSES]
            [CUSTOM_EXCEPTION_CLASS]
            ${innerClasses.values().join("\n\n[CUSTOM_EXCEPTION_CLASS]\n")}
            [/CUSTOM_EXCEPTION_CLASS]
            [/CUSTOM_EXCEPTION_CLASSES]
    
            [ORIGINAL_GLOBAL_EXCEPTION_HANDLER]
            ${classDefinition}
            [/ORIGINAL_GLOBAL_EXCEPTION_HANDLER]
            """.toString()
        }
    
        private static String indent(String text, int spaces) {
            String indent = " ".repeat(spaces)
            return text.lines()
                    .map(line -> indent + line)
                    .reduce((line1, line2) -> line1 + "\n" + line2)
                    .orElse("")
        }
    }
  saveAsJsonList: |-
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedHashMap
    import org.springframework.context.ApplicationContext
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.JsonUtils
    import com.capco.brsp.synthesisengine.utils.SuperUtils

    class SaveAsJsonList implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            try {
                def superService = applicationContext.getBean(SuperService.class)
                def scriptService = applicationContext.getBean(ScriptService.class)

                var mapPath = transformParams.split(",")[0].trim()
                var mapKey = transformParams.split(",")[1].trim()

                mapKey = scriptService.evalFreemarker(mapKey)
                println "Setting '${mapKey}' in map '${mapPath}' with: '${content.take(500).replace('\n', '\\n')}${content.length() > 500 ? '...' : ''}'"
                var map = Utils.anyCollectionGetOrSet(projectContext, mapPath, new ConcurrentLinkedHashMap<String, String>())
                var json = JsonUtils.readAsList(content)
                map.put(mapKey, json)
            } catch (Exception ex) {
                ex.printStackTrace()
            }
            return content
        }
    }
  mapPut: |-
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.utils.ConcurrentLinkedHashMap
    import org.springframework.context.ApplicationContext
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    
    class MapPutTransform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            try {
                def superService = applicationContext.getBean(SuperService.class)
                def scriptService = applicationContext.getBean(ScriptService.class)
    
                var mapPath = transformParams.split(",")[0].trim()
                var mapKey = transformParams.split(",")[1].trim()
    
                mapKey = scriptService.evalFreemarker(mapKey)
                println "Setting '${mapKey}' in map '${mapPath}' with: '${content.take(500).replace('\n', '\\n')}${content.length() > 500 ? '...' : ''}'"
                var map = Utils.anyCollectionGetOrSet(projectContext, mapPath, new ConcurrentLinkedHashMap<String, String>())
                Utils.anyCollectionSet(map, mapKey, content)
            } catch (Exception ex) {
                ex.printStackTrace()
            }
            return content
        }
    }
  repromptAllMethods2: |-
    import com.capco.brsp.synthesisengine.dto.TransformDto
    import com.capco.brsp.synthesisengine.service.ITransform
    import com.capco.brsp.synthesisengine.service.ScriptService
    import com.capco.brsp.synthesisengine.service.SuperService
    import com.capco.brsp.synthesisengine.utils.FileUtils
    import com.capco.brsp.synthesisengine.utils.Utils
    import com.capco.brsp.synthesisengine.utils.JavaUtils
    import com.capco.brsp.synthesisengine.utils.SuperUtils
    import org.springframework.context.ApplicationContext
    
    class RepromptAllMethods2Transform implements ITransform {
        @Override
        String execute(ApplicationContext applicationContext, Map<String, Object> projectContext, String content, String transformParams) {
            def superService = applicationContext.getBean(SuperService.class)
            def scriptService = applicationContext.getBean(ScriptService.class)
            def extractedMarkdown = (String) Utils.extractMarkdownCode(content)
            def listAllMethods = JavaUtils.listAllMethods(extractedMarkdown)
            def newContent = content
    
    
            def relativeFilePath = FileUtils.pathJoin(projectContext.project.projectNormalizedName, projectContext.filePath as String)
            def filesMetadata = projectContext.get("files_metadata") as ConcurrentLinkedHashMap<String, Object>
            def fileHistory = filesMetadata.get(relativeFilePath.toString()).history as List<TransformDto>
    
            int i = 1
            System.out.println("Start Reprompting All Methods!")
            for (String method : listAllMethods) {
                System.out.println("Reprompting method ${i} of ${listAllMethods.size()} named as '${method}'".toString())
                String repromptText = """
                              First of all, check if the [ORIGINAL METHOD CONTENT] seems to be incomplete. If so, do the [TASK] below, otherwise just return a OK message!
    
                              [TASK]
                              1. Improve the current method to close any gaps considering the rest of the class and the original COBOL code you received before.
                              2. Most of the current gaps are already mentioned within the comments.
                              3. Create just one METHOD with the same signature as the original to replace it!
                              4. Do your best to fix the gaps on this method turning the translated code on a full implementation of the original COBOL paragraph.
                              5. Don't include anything else to your answer instead of the code method to replace the original one.
                              6. You aren't allowed to create more methods, neither classes, your job is just to complete the code of the current method.
    
                              [ORIGINAL METHOD CONTENT]
                              ${method}
                            """.toString()
    
                def repromptingStart = TransformDto.builder()
                        .name("Reprompting Start: " + method)
                        .content(repromptText)
                        .build()
    
                def attempts = 0
                def newMethodContent = method
                def exception = null
                while (attempts++ < 3) {
                    try {
                        newMethodContent = scriptService.handlePrompt(projectContext, repromptText)
                        newMethodContent = (String) Utils.extractMarkdownCode(newMethodContent)
                        def repromptingEnd = TransformDto.builder()
                                .name("Reprompting End: " + method)
                                .content(repromptText)
                                .build()
                        fileHistory.add(repromptingStart)
                        fileHistory.add(repromptingEnd)
                        if (newMethodContent != "OK") {
                            newContent = newContent.replace(method, newMethodContent)
                        }
                        exception = null
                        break
                    } catch (Exception ex) {
                        exception = ex
                        System.out.println("Exception during the attempt ${attempts} of 3. Waiting 1 minute before retrying!".toString())
                        Thread.sleep(60000)
                    }
                }
    
                if (exception != null) {
                    throw exception
                }
                i++
            }
            System.out.println("Finished Reprompting All Methods!")
    
            return newContent
        }
    }
release-notes:
  2025-03-20:
    - SUMMARY:
        We are expecting that the recipe will start working until the end again, now including the new jclProfile (more stable and with additional information needed for Spring Batch)
        and also some improvements on the DTO structure like skipping the generation of single field classes.
    - jclProfile:
        Previously we were using some prompts to address the creation of that file, but as it was giving too many unstable results, we managed now to create the same asset deterministically.
        Also, this new version includes the input and output files that before was being created by the stepsInputs template.
    - stepsInputs:
        It was responsible to gather information about the input and output file names for each JCL step with the help of LLM.
        Now it is deprecated, as the current version of the jclProfile is already including that information.
    - BatchStepsConfig:
        Previously we were considering just a single input, which means that the Step would never consider more than that to call the taskletService method connecting with the business logic.
        Now, we are considering any number inputs and also relying on the new jclProfile structure, so we changed a lot the template to use that.
    - TaskletService:
        Adjusted to rely on the new jclProfile format, so we will be able to start testing the recipe again using the new jclProfile structure.
    - exception:
        Adjusted to rely on the new jclProfile format, so we will be able to start testing the recipe again using the new jclProfile structure.
    - dtosCypherQuery -> cobolVariablesClassificationCypherQuery: |-
        1. Improvements in cypher query DTO:
        - indicate when the variable is complex
        - show with raw code's variable only raw code of the immediately child if there is
        2. Improvements in DTO creation:
        - fix the Dto names
        - eliminating the instructions to import the dependents DTOs
        - improve the instructions to use dependents DTOs
        3. This also help us to simplify the executor logic and how we can easy contextualize LLM prompts inside the service templates.
    - dtosJolt -> cobolVariablesClassificationJolt:
        Just to have a meaningful name.
    - executor:
        1. Other small adjustments made on the executor to take advantage of the cobolVariablesClassificationCypherQuery and cobolVariablesClassificationJolt changes.
        2. Fixed the circular dependencies and calls.microservice null problems.
        3. Removing duplicate domains inside the monolith domain field.
  2025-03-23:
    - saveJsonAsList:
        New transformAction function to help with summarization tasks at the middle of the execution
    - methodsSummarization:
        Template to plan the methods signature/integration before starting to translate the code
    - serviceMethod:
        Now including the methods already generated before that should be called by it based on the perform statements.
    - dto:
        Differentiate DTOs in normal objects and files. The second has some guidance to prepare FixedWidth annotations on it,
        so it should be easier to use serialization/deserialization libs.
  2025-03-24:
    - serviceMethod / serviceSummarized / methodsSummary:
        A new approach to contextualize the methods and guarantee the dependency order.
        Removed the dataMesh reference.
    - batchStepsConfig:
        Fixed the package.
    - executor:
        Fixed an issue with the beforeEachProject event.